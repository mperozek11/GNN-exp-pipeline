config:
  aggregation: mean
  batch_size: 64
  class_weights: false
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.5
  epochs: 100
  hidden_units:
  - 32
  - 32
  - 32
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.1
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: false
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-04 17:44:51.467967'
fold_0_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/43/fold_0_optim_dict.pt
fold_0_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/43/fold_0_state_dict.pt
fold_1_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/43/fold_1_optim_dict.pt
fold_1_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/43/fold_1_state_dict.pt
fold_2_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/43/fold_2_optim_dict.pt
fold_2_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/43/fold_2_state_dict.pt
fold_3_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/43/fold_3_optim_dict.pt
fold_3_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/43/fold_3_state_dict.pt
fold_4_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/43/fold_4_optim_dict.pt
fold_4_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/43/fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 19.363150119781494
  - 17.92459750175476
  - 18.31398193538189
  - 16.535649344325066
  - 17.41507288813591
  - 16.20781508088112
  - 16.29055967926979
  - 16.898773282766342
  - 16.41336327791214
  - 16.18688726425171
  - 16.63750246167183
  - 16.071734130382538
  - 16.160152226686478
  - 16.06321409344673
  - 16.33506891131401
  - 16.6902694106102
  - 16.36046177148819
  - 16.823269367218018
  - 19.507693976163864
  - 17.325179934501648
  - 16.67319944500923
  - 16.56443339586258
  - 16.487621128559113
  - 16.51509541273117
  - 17.02326875925064
  - 16.233361542224884
  - 16.94535893201828
  - 16.496237218379974
  - 16.70428442955017
  - 15.99313572049141
  - 16.492228895425797
  - 16.336535841226578
  - 16.903602182865143
  - 16.624585583806038
  - 16.775170773267746
  - 16.421647608280182
  - 16.779557287693024
  - 16.127696752548218
  - 16.04555344581604
  - 17.198780119419098
  - 16.473963230848312
  - 16.218238681554794
  - 16.017754912376404
  - 16.781070679426193
  - 16.321943372488022
  - 16.033181071281433
  - 16.349839448928833
  - 16.007078900933266
  - 16.39177691936493
  - 16.154774487018585
  - 16.280467003583908
  - 16.410756647586823
  - 16.27557122707367
  - 16.040753811597824
  - 16.047420144081116
  - 16.37581956386566
  - 16.549014449119568
  - 16.3407841026783
  - 16.085794806480408
  - 16.47967028617859
  - 17.250551611185074
  - 16.120008766651154
  - 16.513879418373108
  - 15.90861713886261
  - 16.796656131744385
  - 16.57782155275345
  - 16.333681672811508
  - 16.85009491443634
  - 16.82805371284485
  - 16.24457249045372
  - 16.542734503746033
  - 16.772056847810745
  - 16.259802132844925
  - 17.129522144794464
  - 15.997710525989532
  - 15.814757406711578
  - 15.923102080821991
  - 16.395825028419495
  - 16.270991683006287
  - 16.4312005341053
  - 16.327370569109917
  - 16.38210627436638
  - 16.202051401138306
  - 16.194879710674286
  - 16.38315337896347
  - 16.853748589754105
  - 16.06579402089119
  - 16.29974666237831
  - 16.585195422172546
  - 16.675346940755844
  - 16.084665060043335
  - 16.420669227838516
  - 16.65160509943962
  - 16.12645661830902
  - 16.183710128068924
  - 16.109467804431915
  - 16.491974711418152
  - 16.358374565839767
  - 16.477726757526398
  - 16.30680301785469
  validation_losses:
  - 0.4168704152107239
  - 0.40739527344703674
  - 0.41021788120269775
  - 0.41474854946136475
  - 0.4290105104446411
  - 0.41680118441581726
  - 0.40726369619369507
  - 0.4231990575790405
  - 0.4168398678302765
  - 0.47963017225265503
  - 0.4120064079761505
  - 0.4204460382461548
  - 0.4276629388332367
  - 0.41522732377052307
  - 0.45432043075561523
  - 1.1607446670532227
  - 0.41500774025917053
  - 0.4166436195373535
  - 0.44609305262565613
  - 3.886094093322754
  - 486.05340576171875
  - 7856993.5
  - 4882811904.0
  - 239628189696.0
  - 0.42206066846847534
  - 0.45261308550834656
  - 28.560657501220703
  - 146958.71875
  - 721005.4375
  - 9286848.0
  - 293556.875
  - 82115736.0
  - 111575728.0
  - 120800416.0
  - 114251496.0
  - 117222784.0
  - 110864512.0
  - 111381872.0
  - 113325968.0
  - 108699704.0
  - 118022584.0
  - 117050456.0
  - 122482600.0
  - 123456168.0
  - 123734040.0
  - 115045352.0
  - 119796056.0
  - 106471840.0
  - 118481224.0
  - 111325264.0
  - 120710752.0
  - 118759528.0
  - 113215824.0
  - 108699632.0
  - 111442264.0
  - 114816328.0
  - 110468320.0
  - 109731952.0
  - 119222352.0
  - 123456168.0
  - 112985392.0
  - 108699704.0
  - 107668584.0
  - 115106304.0
  - 116012064.0
  - 124249544.0
  - 103493752.0
  - 107898752.0
  - 107319976.0
  - 110525848.0
  - 100869688.0
  - 121907784.0
  - 107376176.0
  - 115329088.0
  - 106580328.0
  - 117444624.0
  - 122249288.0
  - 105832112.0
  - 113325984.0
  - 98289968.0
  - 112245888.0
  - 116071288.0
  - 116135472.0
  - 118418664.0
  - 112872832.0
  - 120651512.0
  - 120018448.0
  - 105671288.0
  - 113955064.0
  - 113215816.0
  - 131688008.0
  - 109165864.0
  - 115500160.0
  - 118240520.0
  - 117680064.0
  - 113838584.0
  - 123170696.0
  - 110588264.0
  - 105671280.0
  - 109834320.0
loss_records_fold1:
  train_losses:
  - 16.18432241678238
  - 16.824932366609573
  - 17.126470506191254
  - 16.297759532928467
  - 16.175546422600746
  - 16.781065553426743
  - 16.41835206747055
  - 16.09113922715187
  - 16.518368661403656
  - 16.222900569438934
  - 16.704948037862778
  - 16.804948151111603
  - 16.354832381010056
  - 16.242998361587524
  - 16.233178049325943
  - 16.37934246659279
  - 16.37738010287285
  - 16.324632734060287
  - 16.304547548294067
  - 16.299903601408005
  - 15.936919271945953
  - 16.214094638824463
  - 16.472977697849274
  - 16.30999168753624
  - 16.1763696372509
  - 16.286540806293488
  - 16.316621363162994
  - 16.468412578105927
  - 17.80104473233223
  - 17.46590554714203
  - 16.04191881418228
  - 16.51596975326538
  - 16.69157961010933
  - 16.14070615172386
  - 16.449522733688354
  - 16.60467430949211
  - 16.424616783857346
  - 16.722348541021347
  - 16.366353750228882
  - 17.291729897260666
  - 16.21965879201889
  - 15.866338342428207
  - 16.30972620844841
  - 16.469955503940582
  - 16.261242032051086
  - 16.767001003026962
  - 15.857214391231537
  - 16.29369482398033
  - 16.77545538544655
  - 16.112229079008102
  - 16.358819544315338
  - 16.37453955411911
  - 16.3009472489357
  - 16.9529320448637
  - 17.022108152508736
  - 16.644853815436363
  - 16.431124478578568
  - 16.400051325559616
  - 16.152606546878815
  - 16.26667445898056
  - 16.481510892510414
  - 16.317910701036453
  - 16.02594256401062
  - 16.36165553331375
  - 16.29141728579998
  - 16.536593690514565
  - 16.24545857310295
  - 16.556220322847366
  - 16.393989980220795
  - 16.677725225687027
  - 16.37219886481762
  - 16.221279829740524
  - 16.397904127836227
  - 16.341154247522354
  - 16.235448569059372
  - 16.52497497200966
  - 16.51151430606842
  - 16.297394782304764
  - 16.239868611097336
  - 16.08554658293724
  - 16.49367880821228
  - 16.294830232858658
  - 16.503851413726807
  - 16.49820077419281
  - 16.150413021445274
  - 16.452806740999222
  - 16.44206491112709
  - 16.274959087371826
  - 15.902571469545364
  - 16.538699880242348
  - 16.267482727766037
  - 16.457054048776627
  - 16.334237694740295
  - 16.488586127758026
  - 16.58733142912388
  - 16.556504279375076
  - 16.335652738809586
  - 16.93654564023018
  - 16.32031488418579
  - 15.928366363048553
  validation_losses:
  - 118865056.0
  - 119038928.0
  - 111189736.0
  - 115251984.0
  - 114456704.0
  - 127299008.0
  - 114687176.0
  - 113655392.0
  - 122822688.0
  - 115081712.0
  - 103846360.0
  - 125635216.0
  - 123969144.0
  - 108435856.0
  - 103681464.0
  - 111940872.0
  - 118521776.0
  - 113831160.0
  - 125401000.0
  - 125924224.0
  - 115828648.0
  - 112908440.0
  - 109290104.0
  - 114225928.0
  - 118126816.0
  - 117269816.0
  - 106261104.0
  - 100696480.0
  - 109420432.0
  - 107974120.0
  - 116350472.0
  - 111991248.0
  - 115828648.0
  - 112390304.0
  - 112793736.0
  - 115890088.0
  - 116524264.0
  - 117148496.0
  - 118811856.0
  - 112908432.0
  - 107926792.0
  - 112734680.0
  - 115655664.0
  - 110211760.0
  - 104078256.0
  - 118234152.0
  - 111708072.0
  - 116749672.0
  - 121335888.0
  - 115315368.0
  - 115778264.0
  - 118585792.0
  - 117836800.0
  - 102070720.0
  - 113135712.0
  - 120534760.0
  - 116524264.0
  - 114050984.0
  - 111826904.0
  - 111475824.0
  - 117269816.0
  - 110502576.0
  - 111475824.0
  - 114336096.0
  - 110093400.0
  - 116112080.0
  - 117269816.0
  - 120014704.0
  - 118521776.0
  - 105169672.0
  - 114798928.0
  - 116981536.0
  - 112390296.0
  - 111248272.0
  - 114456680.0
  - 105225656.0
  - 105629112.0
  - 110502576.0
  - 112278976.0
  - 107055888.0
  - 119784496.0
  - 108209800.0
  - 105335960.0
  - 117148496.0
  - 117836800.0
  - 107579920.0
  - 110211760.0
  - 122020704.0
  - 112166872.0
  - 116000952.0
  - 103107464.0
  - 100522816.0
  - 113201168.0
  - 107749312.0
  - 113135720.0
  - 106948120.0
  - 112044392.0
  - 113991000.0
  - 111299568.0
  - 117611384.0
loss_records_fold2:
  train_losses:
  - 16.169958859682083
  - 16.364199459552765
  - 16.42557367682457
  - 17.223224371671677
  - 17.171109974384308
  - 16.236336320638657
  - 16.53616926074028
  - 16.480289429426193
  - 16.03681954741478
  - 16.2931669652462
  - 15.91266918182373
  - 15.776638343930244
  - 16.69228321313858
  - 16.32914811372757
  - 16.34579446911812
  - 16.346545726060867
  - 16.279924541711807
  - 16.47236853837967
  - 16.14306554198265
  - 16.70905050635338
  - 16.08054345846176
  - 16.574149906635284
  - 16.47669330239296
  - 16.093832105398178
  - 16.18013423681259
  - 16.22453424334526
  - 16.2147256731987
  - 16.388197630643845
  - 16.33364599943161
  - 16.127681583166122
  - 16.80667120218277
  - 16.637974619865417
  - 16.422551840543747
  - 16.568673074245453
  - 16.253360837697983
  - 16.379876673221588
  - 16.368779063224792
  - 16.345314234495163
  - 16.593959659337997
  - 16.239998131990433
  - 16.82907584309578
  - 16.428438127040863
  - 16.25617429614067
  - 16.507218539714813
  - 16.37906128168106
  - 16.560208827257156
  - 16.282045409083366
  - 16.947006404399872
  - 16.474950551986694
  - 16.22613126039505
  - 16.5681089758873
  - 16.407545119524002
  - 16.47878009080887
  - 16.09408062696457
  - 16.490496456623077
  - 16.284961938858032
  - 16.357858568429947
  - 16.131980076432228
  - 16.24612531065941
  - 16.480338096618652
  - 16.28607326745987
  - 16.68707650899887
  - 16.41360679268837
  - 16.29907563328743
  - 16.56425729393959
  - 16.394067019224167
  - 16.615297317504883
  - 16.324921011924744
  - 16.561973243951797
  - 16.702049404382706
  - 16.514038011431694
  - 16.444500416517258
  - 16.511372327804565
  - 17.099540323019028
  - 15.999038681387901
  - 16.92180410027504
  - 16.681630849838257
  - 16.588685408234596
  - 16.387799978256226
  - 16.198546320199966
  - 16.555801033973694
  - 16.712473422288895
  - 16.131101563572884
  - 16.668535202741623
  - 16.497597455978394
  - 16.119010001420975
  - 16.406977117061615
  - 16.535251140594482
  - 16.909058034420013
  - 16.932347685098648
  - 16.48406144976616
  - 16.260952085256577
  - 16.276374965906143
  - 16.05937148630619
  - 16.412658244371414
  - 15.89458492398262
  - 16.88050800561905
  - 16.10335785150528
  - 16.07184475660324
  - 16.46394070982933
  validation_losses:
  - 109271560.0
  - 108268512.0
  - 107886032.0
  - 106883712.0
  - 121265600.0
  - 108560312.0
  - 110547952.0
  - 108207088.0
  - 112988256.0
  - 110826664.0
  - 113770024.0
  - 115552528.0
  - 114542264.0
  - 108990768.0
  - 100118000.0
  - 109328496.0
  - 118711976.0
  - 110993728.0
  - 115552536.0
  - 116831992.0
  - 109491664.0
  - 118711976.0
  - 106047800.0
  - 113107040.0
  - 111379672.0
  - 110386280.0
  - 112379080.0
  - 109106104.0
  - 108829696.0
  - 107275112.0
  - 101282248.0
  - 95943416.0
  - 106165920.0
  - 95550688.0
  - 113159560.0
  - 100890376.0
  - 103997880.0
  - 104556624.0
  - 104992312.0
  - 115552536.0
  - 101997848.0
  - 115656000.0
  - 111221768.0
  - 104054168.0
  - 103997888.0
  - 99048600.0
  - 108322616.0
  - 114608192.0
  - 111881584.0
  - 114713608.0
  - 118553760.0
  - 118385768.0
  - 116048256.0
  - 113998008.0
  - 116383888.0
  - 110826680.0
  - 115218904.0
  - 106114488.0
  - 119373936.0
  - 123996072.0
  - 114276912.0
  - 111379672.0
  - 113668368.0
  - 103440496.0
  - 106224336.0
  - 110333600.0
  - 89174240.0
  - 117487208.0
  - 116993808.0
  - 110499104.0
  - 101282248.0
  - 110601984.0
  - 124712480.0
  - 109222088.0
  - 117714576.0
  - 107275112.0
  - 113159560.0
  - 110275984.0
  - 111768016.0
  - 116263808.0
  - 112933904.0
  - 105833008.0
  - 111992536.0
  - 104886288.0
  - 112379080.0
  - 114440088.0
  - 102720080.0
  - 113216504.0
  - 109550168.0
  - 110826592.0
  - 110547936.0
  - 111768016.0
  - 116383880.0
  - 99109464.0
  - 112379064.0
  - 118053072.0
  - 105109240.0
  - 112503120.0
  - 113107040.0
  - 101880408.0
loss_records_fold3:
  train_losses:
  - 17.651293098926544
  - 16.374203726649284
  - 16.08332911133766
  - 16.564161270856857
  - 16.46969974040985
  - 16.702964335680008
  - 16.930265635252
  - 16.809555739164352
  - 30.20735999941826
  - 24.57624903321266
  - 58.99323570728302
  - 28.368660748004913
  - 22.821119755506516
  - 37.76378111541271
  - 22.852278143167496
  - 24.50820818543434
  - 25.526328653097153
  - 38.738382041454315
  - 17.423931777477264
  - 16.44115573167801
  - 16.81143882870674
  - 21.66557866334915
  - 16.81533581018448
  - 16.30161565542221
  - 16.070219725370407
  - 16.641436994075775
  - 16.527918606996536
  - 16.79707944393158
  - 16.308007448911667
  - 16.635335594415665
  - 16.53358829021454
  - 16.363851487636566
  - 16.47728458046913
  - 15.999023377895355
  - 16.474538177251816
  - 16.535288244485855
  - 16.52468168735504
  - 16.239915907382965
  - 16.234331488609314
  - 16.527682662010193
  - 16.221583634614944
  - 16.3368039727211
  - 16.580653727054596
  - 16.748089373111725
  - 16.243776738643646
  - 16.338150829076767
  - 16.623171895742416
  - 16.258237838745117
  - 16.15051245689392
  - 16.574733316898346
  - 16.802510172128677
  - 16.347572445869446
  - 16.565640717744827
  - 16.454087615013123
  - 16.584695369005203
  - 16.312075465917587
  - 16.45991477370262
  - 16.330232858657837
  - 16.269499272108078
  - 16.54512056708336
  - 16.578265607357025
  - 16.27429100871086
  - 16.330034852027893
  - 16.334948390722275
  - 16.77203333377838
  - 16.452846080064774
  - 16.559856057167053
  - 16.214582711458206
  - 16.345274567604065
  - 16.423804998397827
  - 16.401954412460327
  - 16.129077792167664
  - 16.307685375213623
  - 16.537717461586
  - 16.14371222257614
  - 16.326227992773056
  - 16.494486212730408
  - 16.326359391212463
  - 16.110545679926872
  - 16.751331359148026
  - 16.13384947180748
  - 16.553328901529312
  - 16.80020961165428
  - 16.93938273191452
  - 16.170551866292953
  - 16.407205492258072
  - 16.549411684274673
  - 16.45526060461998
  - 16.446118593215942
  - 16.025100260972977
  - 16.96816372871399
  - 16.641830772161484
  - 16.229081511497498
  - 16.396419674158096
  - 16.296969890594482
  - 16.290986597537994
  - 15.89727208018303
  - 16.658758133649826
  - 16.140898376703262
  - 16.953025609254837
  validation_losses:
  - 127223592.0
  - 120219232.0
  - 129547424.0
  - 119439728.0
  - 125680696.0
  - 137076784.0
  - 132431848.0
  - 2349656.25
  - 1.0622005462646484
  - 0.40657564997673035
  - 1.229069709777832
  - 0.4203413724899292
  - 0.4210249185562134
  - 0.4090757966041565
  - 0.40798643231391907
  - 0.41632193326950073
  - 0.42961418628692627
  - 0.4334045648574829
  - 0.41403475403785706
  - 0.41290199756622314
  - 0.41772544384002686
  - 109.13642120361328
  - 684.6300048828125
  - 0.41201847791671753
  - 0.4237539768218994
  - 3.322456476777185e+17
  - 6.513830579168241e+19
  - 7.322193287127761e+19
  - 9.115975259490825e+19
  - 7.405498445313186e+19
  - 6.7368933409463206e+19
  - 8.357395799209096e+19
  - 8.811491462652677e+19
  - 7.719389663638585e+19
  - 8.380066849364535e+19
  - 7.2947037372147565e+19
  - 9.146042064659336e+19
  - 7.560153112048252e+19
  - 8.027495691583278e+19
  - 8.066237203690291e+19
  - 1.0747965415240604e+20
  - 1.115527817833627e+20
  - 1.2895922073142873e+20
  - 1.010015867282475e+20
  - 1.1510699270256722e+20
  - 6.844968736886935e+19
  - 9.352319242123136e+19
  - 1.2305895106571298e+20
  - 1.2934632798924308e+20
  - 1.1490648576212599e+20
  - 1.2183627654344003e+20
  - 1.1995585657324542e+20
  - 1.093086873471649e+20
  - 1.037562679761054e+20
  - 1.0650083371698776e+20
  - 1.2659536748873358e+20
  - 1.1314961571452132e+20
  - 1.196237336929129e+20
  - 1.1310143951303868e+20
  - 9.757784825684138e+19
  - 1.0153369757953294e+20
  - 1.1811466717792987e+20
  - 1.2011766070438894e+20
  - 1.0891544041642105e+20
  - 1.2324015058197047e+20
  - 1.398462770064109e+20
  - 1.289147652772945e+20
  - 1.0882631840192004e+20
  - 1.234146738636241e+20
  - 1.067417850931451e+20
  - 9.13605058259541e+19
  - 1.2347731963812826e+20
  - 1.3083048396878722e+20
  - 1.2995567733335654e+20
  - 1.2614994213418199e+20
  - 1.1790438777814096e+20
  - 9.907892791936025e+19
  - 1.446514506830478e+20
  - 1.4779362621681304e+20
  - 1.1863420841228658e+20
  - 1.2860932094709832e+20
  - 1.2615417305492567e+20
  - 1.451395370887571e+20
  - 1.1428676582433935e+20
  - 1.2624325108896157e+20
  - 1.2467224248691615e+20
  - 1.2780904360784481e+20
  - 1.2442521301048046e+20
  - 1.3565380398532893e+20
  - 1.1387701742308583e+20
  - 9.4562354054782e+19
  - 1.095977005755956e+20
  - 1.2133684317773208e+20
  - 9.104461173724755e+19
  - 1.053966249755379e+20
  - 8.183433708290284e+19
  - 1.3008027399101612e+20
  - 1.3980365993571831e+20
  - 1.0102450055057034e+20
  - 1.3482651384440422e+20
loss_records_fold4:
  train_losses:
  - 17.275581657886505
  - 16.783997029066086
  - 16.33159425854683
  - 16.504176765680313
  - 16.668151021003723
  - 16.742448568344116
  - 16.682259172201157
  - 16.51898729801178
  - 16.51080021262169
  - 16.486422896385193
  - 16.34449777007103
  - 16.62186497449875
  - 16.829269111156464
  - 16.179952085018158
  - 16.61575549840927
  - 16.093508929014206
  - 16.479116797447205
  - 16.396947592496872
  - 16.174006938934326
  - 16.442753493785858
  - 16.299025624990463
  - 16.192213267087936
  - 16.2150801718235
  - 16.248343527317047
  - 16.285235941410065
  - 16.595472365617752
  - 16.492693409323692
  - 16.58743679523468
  - 16.36570617556572
  - 16.287872314453125
  - 16.260602444410324
  - 16.617164134979248
  - 16.74303102493286
  - 16.410669028759003
  - 16.386513590812683
  - 15.995890691876411
  - 16.827155858278275
  - 16.175183564424515
  - 16.275626718997955
  - 16.169049978256226
  - 16.538572371006012
  - 16.428739190101624
  - 16.56943467259407
  - 16.39592233300209
  - 16.48786386847496
  - 15.913868308067322
  - 16.118823915719986
  - 16.678639322519302
  - 16.63881129026413
  - 16.506837993860245
  - 16.49364373087883
  - 16.438460111618042
  - 15.983084708452225
  - 16.17254701256752
  - 16.42153638601303
  - 16.602595806121826
  - 16.594105124473572
  - 16.685324877500534
  - 16.356331259012222
  - 16.53818690776825
  - 16.539985358715057
  - 16.251130253076553
  - 16.406487077474594
  - 16.350693255662918
  - 16.174552500247955
  - 16.370513200759888
  - 16.214592218399048
  - 16.406063497066498
  - 16.139110177755356
  - 17.093487054109573
  - 16.061506032943726
  - 16.91671973466873
  - 16.481526970863342
  - 16.159182399511337
  - 16.246783673763275
  - 16.464752465486526
  - 16.277065858244896
  - 16.273458182811737
  - 16.870504289865494
  - 16.284711241722107
  - 16.497077465057373
  - 16.60764715075493
  - 16.549512833356857
  - 16.10887187719345
  - 16.252051204442978
  - 16.42369481921196
  - 16.63794308900833
  - 16.312744140625
  - 16.32387325167656
  - 16.23585683107376
  - 16.373706698417664
  - 15.898935377597809
  - 16.108480542898178
  - 16.114935159683228
  - 16.835615426301956
  - 16.323097229003906
  - 16.603340715169907
  - 15.96435359120369
  - 17.074272841215134
  - 16.202569752931595
  validation_losses:
  - 5.983045738905888e+19
  - 7.4460625078944e+19
  - 7.798346033433831e+19
  - 7.481248639201837e+19
  - 5.747375976803729e+19
  - 7.982888065039755e+19
  - 6.384195959230195e+19
  - 7.1961540702125425e+19
  - 6.345866983885924e+19
  - 6.854286878030011e+19
  - 6.166960609079329e+19
  - 6.36060351833068e+19
  - 7.693651415846303e+19
  - 7.341587352827776e+19
  - 7.69450991452527e+19
  - 7.879296477517211e+19
  - 6.323920731795515e+19
  - 6.419613427784116e+19
  - 7.76628339475858e+19
  - 5.961628571810765e+19
  - 8.437716443032086e+19
  - 5.949305685291303e+19
  - 6.340918741756281e+19
  - 6.918186975399143e+19
  - 7.034257580092293e+19
  - 7.724504591731e+19
  - 5.4419470397703455e+19
  - 6.46493045922988e+19
  - 8.476226617892615e+19
  - 8.408564431537884e+19
  - 6.595383995428294e+19
  - 6.547995044271148e+19
  - 5.102712518229361e+19
  - 7.13021811711342e+19
  - 6.8923941918301225e+19
  - 7.1623484857049416e+19
  - 7.765497024042395e+19
  - 8.310270730842617e+19
  - 7.439228823225447e+19
  - 7.036113115915328e+19
  - 6.828572379688888e+19
  - 6.339515764919239e+19
  - 5.770152580075435e+19
  - 6.333269659264169e+19
  - 7.784486029658738e+19
  - 4.226835838082535e+19
  - 6.441441372423376e+19
  - 7.1102725363809124e+19
  - 6.864765663647367e+19
  - 6.515408598256425e+19
  - 8.38415615301056e+19
  - 8.547516313009704e+19
  - 6.984152835214541e+19
  - 5.577104286712385e+19
  - 6.323316000400238e+19
  - 7.535196836925643e+19
  - 7.536778374451036e+19
  - 8.107861195480682e+19
  - 7.3098822753338786e+19
  - 8.098932281453838e+19
  - 6.34816276416472e+19
  - 8.345215849201245e+19
  - 8.370867015672608e+19
  - 7.149726092218073e+19
  - 8.681140400937973e+19
  - 8.529403398258373e+19
  - 9.681554365116475e+19
  - 6.3150309603826205e+19
  - 9.682363605674518e+19
  - 9.272345164365221e+19
  - 8.054071327431275e+19
  - 8.577928804633988e+19
  - 8.724618609137444e+19
  - 9.212515898846767e+19
  - 9.951381555447123e+19
  - 1.0176503482601701e+20
  - 7.952121970475978e+19
  - 9.012383671968281e+19
  - 9.626004398853325e+19
  - 9.927950522854565e+19
  - 1.0724154391429487e+20
  - 8.962920602076499e+19
  - 9.973649744542145e+19
  - 1.0513588239008059e+20
  - 1.0597613797212003e+20
  - 9.406509332405053e+19
  - 1.0364018593649132e+20
  - 9.57016328191114e+19
  - 1.0694173787972593e+20
  - 8.989245549273363e+19
  - 9.893719647249341e+19
  - 1.0555635322872817e+20
  - 9.860857443718372e+19
  - 1.0251272032509074e+20
  - 1.1865317278884246e+20
  - 1.0279608646180117e+20
  - 1.0566777333904048e+20
  - 9.502214342923885e+19
  - 9.810025701752334e+19
  - 9.526663963088414e+19
training fold messages:
  fold 0 training message: completed 100 epochs without stopping early
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: completed 100 epochs without stopping early
  fold 3 training message: completed 100 epochs without stopping early
  fold 4 training message: completed 100 epochs without stopping early
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.8576329331046312, 0.8593481989708405, 0.8593481989708405,
    0.8591065292096219]'
  fold_eval_f1: '[0.0, 0.0, 0.0, 0.0, 0.0]'
  mean_eval_accuracy: 0.858613758672113
  mean_f1_accuracy: 0.0
  total_train_time: '0:10:37.427253'
