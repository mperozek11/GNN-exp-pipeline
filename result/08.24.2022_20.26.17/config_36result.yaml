config:
  aggregation: mean
  batch_size: 32
  class_weights: true
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.5
  epochs: 100
  hidden_units:
  - 32
  - 32
  - 32
  - 32
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.01
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: true
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-24 21:14:25.535353'
fold_0_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_36fold_0_optim_dict.pt
fold_0_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_36fold_0_state_dict.pt
fold_1_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_36fold_1_optim_dict.pt
fold_1_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_36fold_1_state_dict.pt
fold_2_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_36fold_2_optim_dict.pt
fold_2_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_36fold_2_state_dict.pt
fold_3_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_36fold_3_optim_dict.pt
fold_3_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_36fold_3_state_dict.pt
fold_4_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_36fold_4_optim_dict.pt
fold_4_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_36fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 6.60474257171154
  - 6.568005380034447
  - 6.409089133143425
  - 6.217920288443565
  - 6.315137723088265
  - 6.420250862836838
  - 6.204086270928383
  - 6.138704246282578
  - 6.335503086447716
  - 6.198981052637101
  - 6.063662898540497
  - 6.246734908223153
  - 6.239332455396653
  - 6.130253234505654
  - 6.003466263413429
  - 6.284946069121361
  - 6.158191388845444
  - 6.089572679996491
  - 6.16302302479744
  - 5.957344865798951
  - 6.04293087720871
  - 6.112653601169587
  - 6.094330224394799
  - 5.944193264842034
  - 5.895866432785988
  - 6.078378745913506
  - 6.098085796833039
  - 6.0625117987394335
  - 6.0709094464778905
  validation_losses:
  - 0.40102866291999817
  - 0.4160082936286926
  - 0.39575740694999695
  - 0.4206666052341461
  - 0.41501283645629883
  - 0.39890071749687195
  - 0.39450326561927795
  - 0.38480302691459656
  - 0.43967995047569275
  - 0.5675032138824463
  - 0.398786723613739
  - 0.39903566241264343
  - 0.427793025970459
  - 0.4137105345726013
  - 0.38997358083724976
  - 0.40407228469848633
  - 0.3833240270614624
  - 0.3878823518753052
  - 0.3988133668899536
  - 0.3911251723766327
  - 0.3941231667995453
  - 0.38229429721832275
  - 0.41308462619781494
  - 0.393756240606308
  - 0.3897991478443146
  - 0.39048540592193604
  - 0.38879910111427307
  - 0.3931252062320709
  - 0.39369136095046997
loss_records_fold1:
  train_losses:
  - 5.896518576145173
  - 6.045898005366325
  - 5.979026612639427
  - 6.001959380507469
  - 5.9504201292991645
  - 5.937464720010758
  - 6.002467209100724
  - 5.88562513589859
  - 5.8045235812664036
  - 5.867376816272736
  - 5.847907313704491
  - 5.92073898613453
  - 5.966183638572693
  - 5.817860734462738
  - 5.934150156378746
  - 6.0243783593177795
  - 5.984071671962738
  - 5.762771505117417
  - 5.8983702003955845
  - 5.874253126978875
  - 5.857572713494301
  - 5.934146481752396
  - 5.900174939632416
  - 5.91075907945633
  - 5.821027916669846
  - 5.837227612733841
  - 5.940092781186104
  - 5.827313622832299
  - 5.9098706454038625
  - 5.905332323908806
  - 5.849220326542855
  - 5.831310442090035
  - 5.992319077253342
  - 5.865878543257714
  - 5.885917648673058
  - 5.867545783519745
  - 5.793514654040337
  - 5.821881529688835
  - 6.005291095376015
  - 5.892327627539635
  - 5.805406850576401
  - 5.847553876042366
  - 5.909514975547791
  - 5.824445509910584
  - 5.852868676185608
  - 5.862285107374191
  - 5.865826708078385
  - 5.871255490183831
  - 6.101884755492211
  - 5.859042635560036
  - 5.750243225693703
  - 5.795195969939233
  - 5.960074147582055
  - 5.789785730838776
  - 6.0133319228887565
  - 5.990019655227662
  - 5.912219083309174
  - 5.91970397233963
  - 5.911245813965798
  - 5.8537541985511785
  - 5.972477638721466
  - 5.9911111608147625
  - 5.90126093029976
  - 5.824454405903817
  - 5.854274347424507
  - 5.983739036321641
  - 5.963689494132996
  - 5.812325233221054
  - 5.929413712024689
  - 5.931359848380089
  - 5.851402446627617
  - 5.906071156263351
  - 5.89240857064724
  - 6.032146015763283
  - 5.765704533457757
  - 5.961847856640816
  - 5.822322747111321
  - 5.785148644447327
  - 5.754241380095483
  - 5.883914348483086
  - 5.87522013783455
  - 5.858474069833756
  - 5.815749993920327
  - 5.7228969722986225
  - 5.906355804204941
  - 5.837145134806633
  - 5.815860936045647
  - 5.694909289479256
  - 5.971552082896233
  - 6.136344605684281
  - 5.941216120123864
  - 5.8894774436950685
  - 5.853446519374848
  - 5.8609930843114855
  - 5.91159775853157
  - 5.860732227563858
  - 5.901823750138283
  - 5.866436728835106
  - 5.855196622014046
  - 5.931066378951073
  validation_losses:
  - 0.41795435547828674
  - 0.3900463581085205
  - 0.3948952257633209
  - 0.3936782777309418
  - 0.39239105582237244
  - 0.39865583181381226
  - 0.39603716135025024
  - 0.4100324213504791
  - 0.3811151087284088
  - 0.3989180028438568
  - 0.40923455357551575
  - 0.4203619956970215
  - 0.3879951536655426
  - 0.48912864923477173
  - 0.40450426936149597
  - 0.3985011875629425
  - 0.4002160131931305
  - 0.40183475613594055
  - 0.39440813660621643
  - 0.40714213252067566
  - 0.4758836328983307
  - 0.4099271595478058
  - 0.42703625559806824
  - 0.44278955459594727
  - 0.43831127882003784
  - 2.5035061836242676
  - 0.39062264561653137
  - 0.4269968271255493
  - 0.4708441495895386
  - 0.5323368310928345
  - 0.40871813893318176
  - 0.5272411704063416
  - 0.4689168334007263
  - 0.43424755334854126
  - 0.41949641704559326
  - 0.4523678421974182
  - 0.4230298697948456
  - 0.4216070771217346
  - 0.40655964612960815
  - 0.40089085698127747
  - 0.4209301769733429
  - 0.42686811089515686
  - 0.4250389039516449
  - 0.4091673791408539
  - 0.4549373686313629
  - 0.6112903356552124
  - 0.4268624484539032
  - 0.3928680121898651
  - 0.3947514295578003
  - 0.4014695882797241
  - 0.4276456832885742
  - 0.4985071122646332
  - 0.5225282907485962
  - 0.6781907677650452
  - 0.41927680373191833
  - 0.652793288230896
  - 0.43238723278045654
  - 0.4092807173728943
  - 0.4283847510814667
  - 0.4419264793395996
  - 0.46676918864250183
  - 0.4214688539505005
  - 0.408657431602478
  - 0.4350128769874573
  - 0.40103569626808167
  - 0.5297887921333313
  - 0.5030162334442139
  - 0.40405505895614624
  - 0.4160192906856537
  - 0.6642300486564636
  - 0.4690035879611969
  - 0.46768832206726074
  - 0.5454587936401367
  - 0.40160879492759705
  - 0.41771620512008667
  - 0.41060563921928406
  - 0.4257187843322754
  - 0.4246940016746521
  - 0.7118675708770752
  - 0.48243218660354614
  - 0.45401838421821594
  - 0.4165676236152649
  - 0.40743061900138855
  - 0.40164676308631897
  - 0.4276753067970276
  - 0.4235216975212097
  - 0.48656144738197327
  - 0.3904086649417877
  - 0.39177176356315613
  - 0.3963593542575836
  - 0.42703309655189514
  - 0.39563286304473877
  - 0.3870146572589874
  - 0.3945639133453369
  - 0.41903379559516907
  - 0.39895573258399963
  - 0.40232595801353455
  - 0.42572715878486633
  - 0.44090887904167175
  - 0.612929105758667
loss_records_fold2:
  train_losses:
  - 5.900737136602402
  - 5.819820761680603
  - 5.710719645023346
  - 5.928740251064301
  - 5.7560951799154285
  - 5.851838111877441
  - 5.9498176097869875
  - 5.946104255318642
  - 5.8801689684391025
  - 5.817339310050011
  - 5.85874097943306
  - 5.769998401403427
  - 5.891898933053017
  - 5.829218915104867
  - 5.976482790708542
  - 5.958849623799324
  - 5.857125270366669
  - 5.966290244460106
  - 5.853852170705796
  - 5.857514750957489
  - 5.742858341336251
  - 5.767767074704171
  - 5.787104809284211
  - 5.706901681423187
  - 5.8812756717205055
  - 5.766332530975342
  - 6.02262559235096
  - 5.900830766558648
  - 5.966755309700966
  - 5.9728811353445055
  - 5.874572390317917
  - 5.836752107739449
  - 5.849867436289788
  - 5.867711734771729
  - 5.911519548296929
  - 5.752215939760209
  - 5.841124361753464
  - 5.858198916912079
  - 5.758833983540535
  - 5.8940549999475484
  - 5.914296314120293
  - 5.895325075089932
  - 5.832764449715615
  - 5.734772005677224
  - 5.736731696128846
  - 5.692342904210091
  - 5.811854496598244
  - 5.853966698050499
  - 5.95494613647461
  - 5.755133253335953
  - 5.78869803249836
  - 5.772386506199837
  - 5.838832345604897
  - 5.764403089880943
  - 5.740013518929482
  - 5.729898580908776
  - 5.761432081460953
  - 5.8073059022426605
  - 5.723226648569107
  - 5.74241710305214
  - 5.759984412789345
  - 5.865270563960076
  - 5.900920647382737
  - 5.854016372561455
  - 5.69549669623375
  - 5.869976907968521
  - 5.846026042103768
  - 5.848824974894524
  - 5.815592870116234
  - 5.81523227095604
  - 5.91829739511013
  - 5.728565585613251
  - 5.844160872697831
  - 5.848526194691658
  - 5.831162542104721
  - 5.706371036171913
  - 5.742468377947808
  - 5.732047513127327
  - 5.858845692873001
  - 5.9340061962604524
  - 5.801029360294343
  - 5.883070105314255
  - 5.7135359138250355
  - 5.687490236759186
  - 5.8166069269180305
  - 5.763237330317498
  - 5.927594384551049
  - 5.776211768388748
  - 6.062492173910141
  - 5.857818287611008
  - 5.893606010079385
  - 5.777965500950813
  - 5.803366646170616
  - 5.760765694081783
  - 5.759420511126518
  - 5.859973731637002
  - 5.918178856372833
  - 5.854725536704064
  - 5.736311611533165
  - 5.752412244677544
  validation_losses:
  - 0.41630786657333374
  - 0.7937659025192261
  - 0.4782513380050659
  - 0.4262741506099701
  - 0.40263402462005615
  - 0.3945511281490326
  - 0.3875482976436615
  - 0.3963968753814697
  - 0.3867182731628418
  - 0.4416923224925995
  - 0.895675539970398
  - 0.4847138524055481
  - 0.41299477219581604
  - 31.459993362426758
  - 1.638353943824768
  - 2.2417142391204834
  - 2.108203887939453
  - 1.9900527000427246
  - 0.4417421221733093
  - 0.4011165201663971
  - 0.4228380620479584
  - 1.1149046421051025
  - 7.631917476654053
  - 0.40012237429618835
  - 4.648569583892822
  - 19.543874740600586
  - 0.3891311585903168
  - 0.3919961452484131
  - 0.38966357707977295
  - 0.41329026222229004
  - 0.3937992453575134
  - 0.42094898223876953
  - 0.38289040327072144
  - 0.39550551772117615
  - 0.7556862235069275
  - 0.38820767402648926
  - 1.271140217781067
  - 1.0778162479400635
  - 0.383137971162796
  - 0.4219091832637787
  - 1.366556167602539
  - 0.46682828664779663
  - 0.41345471143722534
  - 2.5939836502075195
  - 1.3016384840011597
  - 0.4837685227394104
  - 4.981566905975342
  - 2.0103092193603516
  - 0.8414554595947266
  - 1.3357205390930176
  - 0.4032371938228607
  - 0.5933923125267029
  - 0.596024751663208
  - 0.554533839225769
  - 0.5550863146781921
  - 1.3278675079345703
  - 1.4286867380142212
  - 0.40617674589157104
  - 1.6953768730163574
  - 1.1972407102584839
  - 1.0032963752746582
  - 0.8251022100448608
  - 0.954384446144104
  - 0.8155916929244995
  - 0.6708511114120483
  - 0.38940584659576416
  - 0.4095744788646698
  - 0.49686679244041443
  - 0.39405563473701477
  - 0.3885204493999481
  - 0.41649380326271057
  - 1.295295000076294
  - 0.5955004692077637
  - 1.272963047027588
  - 1.5933482646942139
  - 0.421557754278183
  - 2.982818126678467
  - 2.5615792274475098
  - 0.6297586560249329
  - 3.555389404296875
  - 1.918184518814087
  - 1.7464576959609985
  - 4.006716728210449
  - 6.866466045379639
  - 0.4240918457508087
  - 0.4198647737503052
  - 0.467871755361557
  - 0.475019246339798
  - 0.7627756595611572
  - 0.3893440365791321
  - 0.4768226742744446
  - 1.1087645292282104
  - 0.8298991322517395
  - 1.6897262334823608
  - 0.8372157216072083
  - 0.7490416169166565
  - 2.94250226020813
  - 4.726470947265625
  - 3.015378475189209
  - 1.3382630348205566
loss_records_fold3:
  train_losses:
  - 5.821123096346856
  - 5.682342019677162
  - 5.8435268104076385
  - 5.957309937477112
  - 5.842376017570496
  - 5.743203827738762
  - 5.794017523527145
  - 5.714921987056733
  - 5.776212781667709
  - 5.9101476013660434
  - 5.776747515797616
  - 5.815447193384171
  - 5.977379724383354
  - 5.7652463823556905
  - 6.107253307104111
  - 6.01921168267727
  - 5.960508415102959
  - 5.900329074263573
  - 5.841453203558922
  - 5.836352461576462
  - 5.969492745399475
  - 5.977792397141457
  - 5.837870040535927
  - 5.795269474387169
  - 5.827665609121323
  - 5.846438556909561
  - 5.851121404767037
  - 5.994882035255433
  - 5.862420856952667
  - 5.818911150097847
  - 5.701039791107178
  - 5.868262043595315
  - 5.78548980653286
  - 5.93414671421051
  - 5.8295909270644195
  - 5.8587519228458405
  - 5.83108344078064
  - 5.759041872620583
  - 5.852888470888138
  - 5.809141483902931
  - 5.756685766577721
  - 5.842686271667481
  - 5.923773536086083
  - 5.888842210173607
  - 5.7678865641355515
  - 5.868405824899674
  - 5.7636373281478885
  - 5.774838811159134
  - 5.8114454537630085
  - 5.892390266060829
  - 5.742667841911317
  - 5.984617674350739
  - 5.963793233036995
  - 5.788707107305527
  - 5.956049597263337
  - 5.912209451198578
  - 5.871330425143242
  - 5.869482693076134
  - 6.051369920372963
  - 5.849880459904671
  - 5.863868156075478
  - 5.765237304568291
  - 5.761136159300804
  - 5.90677254498005
  - 5.763167780637741
  - 5.777598723769188
  - 5.846067675948143
  - 5.831497356295586
  - 5.795608606934548
  - 5.741771924495698
  - 6.004415193200112
  - 5.914314311742783
  - 5.825556808710099
  - 5.777792349457741
  - 5.978582331538201
  - 5.882088974118233
  - 5.982836836576462
  - 5.87822302877903
  - 5.875905695557595
  - 5.974124166369439
  - 6.002733075618744
  - 5.9954252481460575
  - 5.785702976584435
  - 5.934032300114632
  - 5.877202862501145
  - 5.84581136405468
  - 5.767324733734132
  - 5.759550020098686
  - 5.809886732697487
  - 5.913103711605072
  - 5.791497328877449
  - 5.84229860007763
  - 5.882668912410736
  - 5.792833244800568
  - 5.980895844101906
  - 5.85619607269764
  - 5.7417359203100204
  - 5.738586524128914
  - 5.877255943417549
  - 5.904829463362694
  validation_losses:
  - 6.697625160217285
  - 14.693036079406738
  - 3.5725064277648926
  - 3.2973575592041016
  - 1.5188593864440918
  - 4.889235019683838
  - 3.700551748275757
  - 6.830621242523193
  - 1.9303584098815918
  - 3.09464955329895
  - 5.471958160400391
  - 4.502804279327393
  - 0.40658387541770935
  - 6.232085227966309
  - 1.9869868755340576
  - 2.218698024749756
  - 1.5046330690383911
  - 1.1276698112487793
  - 1.1762514114379883
  - 1.0149743556976318
  - 1.067569375038147
  - 1.1809419393539429
  - 0.43099936842918396
  - 0.4037611186504364
  - 0.5224930644035339
  - 0.6143567562103271
  - 0.40997159481048584
  - 0.9662627577781677
  - 0.41941922903060913
  - 0.7408844232559204
  - 0.6270832419395447
  - 1.4494861364364624
  - 1.8029723167419434
  - 1.8197599649429321
  - 1.5279814004898071
  - 1.5485954284667969
  - 0.6630464792251587
  - 0.4110051393508911
  - 1.1211003065109253
  - 1.0168185234069824
  - 0.76972496509552
  - 2.0896284580230713
  - 1.7957239151000977
  - 0.6620846390724182
  - 1.6677907705307007
  - 2.9336211681365967
  - 0.6653162240982056
  - 1.8178342580795288
  - 2.8148515224456787
  - 1.0506627559661865
  - 1.1455217599868774
  - 1.3485037088394165
  - 1.4786204099655151
  - 12.317862510681152
  - 1.51075279712677
  - 1.0778042078018188
  - 1.0325645208358765
  - 0.6515012383460999
  - 1.0689783096313477
  - 1.0722113847732544
  - 1.7353172302246094
  - 1.8019044399261475
  - 1.2628904581069946
  - 1.062673568725586
  - 0.7537118792533875
  - 1.7827081680297852
  - 3.690399646759033
  - 2.962283134460449
  - 1.9761037826538086
  - 2.6440396308898926
  - 5.321239471435547
  - 2.994410991668701
  - 1.3462977409362793
  - 3.8359460830688477
  - 10.971023559570312
  - 2.699897289276123
  - 1.283732295036316
  - 0.8150819540023804
  - 0.9354597926139832
  - 0.5085659027099609
  - 0.47465944290161133
  - 0.5203614234924316
  - 3.2255141735076904
  - 0.9289027452468872
  - 0.4219300150871277
  - 1.756054162979126
  - 1.5642154216766357
  - 0.7133198380470276
  - 0.6366252899169922
  - 0.5061725974082947
  - 0.48099613189697266
  - 0.5508555173873901
  - 0.47125256061553955
  - 0.5535486936569214
  - 0.5091719627380371
  - 0.8763934373855591
  - 0.9412255883216858
  - 2.1881566047668457
  - 1.427258014678955
  - 1.3888084888458252
loss_records_fold4:
  train_losses:
  - 5.962010315060616
  - 5.937088894844056
  - 5.782231828570366
  - 5.827389308810234
  - 5.824212434887887
  - 5.84244159758091
  - 5.8658423840999605
  - 5.878763800859452
  - 5.872683817148209
  - 5.813448759913445
  - 5.851852080225945
  - 5.96088015139103
  - 5.910282585024834
  - 5.834470328688622
  - 5.871080529689789
  - 5.9221681475639345
  - 5.889344859123231
  - 5.983980572223664
  - 5.982443621754647
  - 5.993876680731773
  - 5.924510020017625
  - 5.783687707781792
  - 5.753291356563569
  - 5.855136564373971
  - 5.827738565206528
  - 5.847137892246247
  - 5.869193100929261
  - 5.845143440365792
  - 5.835633480548859
  - 5.944134360551835
  - 5.742938500642777
  - 5.928207099437714
  - 5.886589089035988
  - 5.9500212371349335
  - 5.857009479403496
  - 6.0371208697557455
  - 5.878964740037919
  - 5.937891739606858
  - 5.937446823716164
  - 5.818378388881683
  - 5.887423685193062
  - 5.892404279112816
  - 5.7293863743543625
  - 5.759265571832657
  - 5.8571798563003545
  - 5.939659842848778
  - 5.884596997499466
  - 5.777713054418564
  - 5.909886452555657
  - 5.846341940760613
  - 5.78233605325222
  - 6.013671004772187
  - 5.76594557762146
  - 5.807171666622162
  - 5.875038313865662
  - 5.838460645079613
  - 5.832030305266381
  - 5.984502065181733
  - 6.057369583845139
  - 5.865061357617378
  - 5.686731907725335
  - 5.843762478232384
  - 5.910703858733178
  - 5.822742402553558
  - 5.744791716337204
  - 5.833910727500916
  - 5.77764245569706
  - 5.839493897557259
  - 5.898147210478783
  - 5.907712596654893
  - 5.825766611099244
  - 5.828268676996231
  - 5.916964623332024
  - 5.845823994278908
  - 5.881297928094864
  - 5.916949731111527
  - 5.751269873976708
  - 5.9173920333385475
  - 5.877952411770821
  - 5.854663166403771
  - 5.746912184357644
  - 5.777192249894142
  - 5.8029365897178655
  - 5.792440757155418
  - 5.9687032312154775
  - 5.889302763342858
  - 5.877548840641976
  - 5.841639882326127
  - 5.845069792866707
  - 5.852922952175141
  - 5.789515718817711
  - 5.85703501701355
  - 5.813953334093094
  - 5.8177213996648796
  - 5.810651031136513
  - 5.855593582987786
  - 5.926024320721627
  - 5.863721346855164
  - 5.7588903397321705
  - 5.779925009608269
  validation_losses:
  - 0.580268144607544
  - 0.7384097576141357
  - 0.3874528110027313
  - 1.198326826095581
  - 0.9852969646453857
  - 0.8048717975616455
  - 0.9973639845848083
  - 0.9980397820472717
  - 0.47058871388435364
  - 0.5417283177375793
  - 0.5117309093475342
  - 0.4814000129699707
  - 0.4346645474433899
  - 0.42447492480278015
  - 0.6940138936042786
  - 0.6020231246948242
  - 0.43419697880744934
  - 0.5124788284301758
  - 0.48057064414024353
  - 0.5134478807449341
  - 0.6414759159088135
  - 0.4540918171405792
  - 0.4144439697265625
  - 0.426928848028183
  - 0.5176493525505066
  - 0.44539520144462585
  - 0.40544983744621277
  - 0.3906552791595459
  - 0.42895078659057617
  - 0.5509307384490967
  - 0.41600531339645386
  - 0.4762887954711914
  - 0.4584081172943115
  - 0.47883328795433044
  - 0.4724150598049164
  - 0.4256655275821686
  - 0.43894749879837036
  - 0.4046853184700012
  - 0.4569278061389923
  - 0.4387859106063843
  - 0.5015498995780945
  - 0.5258350372314453
  - 0.41709962487220764
  - 0.4795629680156708
  - 0.4500928521156311
  - 0.4058905243873596
  - 0.41743507981300354
  - 0.42602136731147766
  - 0.40980419516563416
  - 0.4997497797012329
  - 0.4207131266593933
  - 0.44763100147247314
  - 0.526118814945221
  - 0.4404880106449127
  - 0.6152510643005371
  - 0.655642569065094
  - 0.5261947512626648
  - 0.38901013135910034
  - 0.3806594908237457
  - 0.39142969250679016
  - 0.3964526653289795
  - 0.5202471017837524
  - 0.49708908796310425
  - 0.4149928092956543
  - 0.4534238278865814
  - 0.4013734459877014
  - 0.5273133516311646
  - 0.4672006368637085
  - 0.5612713098526001
  - 0.4578990638256073
  - 0.42861849069595337
  - 0.40449658036231995
  - 0.38648849725723267
  - 0.4643431007862091
  - 0.4002833366394043
  - 0.5347549915313721
  - 0.41183769702911377
  - 0.47509169578552246
  - 0.4330993592739105
  - 0.38446345925331116
  - 0.5527209639549255
  - 0.5048062801361084
  - 0.46842658519744873
  - 0.498185932636261
  - 1.4273123741149902
  - 0.44671931862831116
  - 0.4243117570877075
  - 0.47007113695144653
  - 0.4668090045452118
  - 0.5151013731956482
  - 0.6041004061698914
  - 0.5330985188484192
  - 0.9750857949256897
  - 0.4211989641189575
  - 0.4321150779724121
  - 0.47029292583465576
  - 0.4256812036037445
  - 0.4116639196872711
  - 0.847647488117218
  - 0.45484113693237305
training fold messages:
  fold 0 training message: stopped training due to stagnating improvement on validation
    loss after 29 epochs
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: completed 100 epochs without stopping early
  fold 3 training message: completed 100 epochs without stopping early
  fold 4 training message: completed 100 epochs without stopping early
training_metrics:
  fold_eval_accs: '[0.855917667238422, 0.8542024013722127, 0.8507718696397941, 0.855917667238422,
    0.8556701030927835]'
  fold_eval_f1: '[0.0, 0.06593406593406592, 0.1212121212121212, 0.0, 0.0]'
  mean_eval_accuracy: 0.8544959417163269
  mean_f1_accuracy: 0.03742923742923743
  total_train_time: '0:46:22.671368'
