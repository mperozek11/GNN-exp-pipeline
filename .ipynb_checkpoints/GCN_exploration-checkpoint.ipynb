{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ecc87a-262b-48a1-be0c-bdeca3eed868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import GCNConv\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "from torch_geometric.nn import GINConv, global_add_pool, global_mean_pool\n",
    "from torch.nn import Sequential, Linear, ReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dfac366-b68a-48e6-b2d5-d57053332852",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Users/maxperozek/GNN-research'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38c4495-aa55-40d1-b4d4-934534d6cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTargetData(Data):\n",
    "    def __cat_dim__(self, key, value, *args, **kwargs):\n",
    "        if key == 'y':\n",
    "            return None\n",
    "        else:\n",
    "            return super().__cat_dim__(key, value, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18327f74-58d4-4a57-960b-e4716f2a2a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WICO(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [f'{root}/GNN-exp-pipeline/data/full_wico.pt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['processed_wico.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        # download_url(url, self.raw_dir)\n",
    "        pass\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = torch.load(self.raw_file_names[0])\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2aa7549-bb22-41d3-a720-5f0c2073e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "wico = WICO('test-wico', pre_filter=lambda data: data.y != 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8ac07f-4271-4a95-8a60-cc33b0cedcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wico.data.y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f53720e-435d-4d5a-9476-ab886604155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch norm\n",
    "m = BatchNorm1d(3, affine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d4b973-19f7-4e57-8ebc-e61278c30f70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wico.data.x = m(wico.data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb53cfb-9135-497c-b4c6-a0d0caa9d41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0997, -0.0968,  0.0868],\n",
       "        [-0.1299,  0.7427,  0.4153],\n",
       "        [-0.1432,  1.1625,  2.0575],\n",
       "        ...,\n",
       "        [-0.1601, -0.9363, -0.2417],\n",
       "        [-0.1597, -1.7759, -0.8986],\n",
       "        [ 0.6019, -2.6154, -1.2270]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wico.data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "300da427-66c3-4881-a066-10740bb2e097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e1b1324-a253-409c-bc0a-e138ad7f9bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wico.data.y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b3f3ed1-0ae8-4ec3-90ef-89ee942a39d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec82419-a2c6-490f-bcce-654ec931ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = len([v for v in y if v == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da7f6269-df68-4b3c-bcab-a0db94a0529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = len([v for v in y if v == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "440ac7e0-d882-4d0c-85d8-64e95b6e196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24f68e31-5f79-4641-b7ba-37dd24d501ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = [(1-real/total)-eps, (1-fake/total)+eps]\n",
    "weights = [(1-real/total), (1-fake/total)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b546fdca-d2ca-46cb-8660-c946c47140d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1413864104323953, 0.8586135895676047]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9042b36b-c402-424b-83d8-553a3487626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_news_idx = np.where(wico.data.y == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abcc05fb-4f0c-4736-a763-0320230e53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_news_idx = np.where(wico.data.y == 0)[0][:412]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c932f980-6a81-4d40-a5f2-cea44a7173ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = np.concatenate((fake_news_idx, real_news_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5637bb4c-80f0-4cc6-ad1f-38554b2c68ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wico = wico[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56ba7335-3171-4bcc-8747-bed9218988dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WICO(2914)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbfe4c40-ff80-4ff9-9ad5-bcbe2e22fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(wico)\n",
    "y = [data.y.numpy()[0] for data in wico]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ccbf5d0-0995-46b7-8bcc-7122b349ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, valid_idx = train_test_split(np.arange(l), test_size=0.2, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "643fee4a-93a1-4dde-a0db-376aec59971c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2331"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a205951-b6a0-4b62-822b-9fe4096ec9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "735c9c87-09bd-49de-9ea9-fa40f670702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = DataLoader(wico[train_idx], batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(wico[valid_idx], batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b94251bc-e1de-4a9a-b000-d9df6bcf497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim_features, dim_target, config):\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.dropout = config['dropout']\n",
    "        self.embeddings_dim = [config['hidden_units'][0]] + config['hidden_units']\n",
    "        self.no_layers = len(self.embeddings_dim)\n",
    "        self.first_h = []\n",
    "        self.nns = []\n",
    "        self.convs = []\n",
    "        self.linears = []\n",
    "\n",
    "        train_eps = config['train_eps']\n",
    "        if config['aggregation'] == 'sum':\n",
    "            self.pooling = global_add_pool\n",
    "        elif config['aggregation'] == 'mean':\n",
    "            self.pooling = global_mean_pool\n",
    "\n",
    "        for layer, out_emb_dim in enumerate(self.embeddings_dim):\n",
    "\n",
    "            if layer == 0:\n",
    "                self.first_h = Sequential(Linear(dim_features, out_emb_dim), BatchNorm1d(out_emb_dim), ReLU(),\n",
    "                                    Linear(out_emb_dim, out_emb_dim), BatchNorm1d(out_emb_dim), ReLU())\n",
    "                self.linears.append(Linear(out_emb_dim, dim_target))\n",
    "            else:\n",
    "                input_emb_dim = self.embeddings_dim[layer-1]\n",
    "                self.nns.append(Sequential(Linear(input_emb_dim, out_emb_dim), BatchNorm1d(out_emb_dim), ReLU(),\n",
    "                                      Linear(out_emb_dim, out_emb_dim), BatchNorm1d(out_emb_dim), ReLU()))\n",
    "                self.convs.append(GINConv(self.nns[-1], train_eps=train_eps))  # Eq. 4.2\n",
    "\n",
    "                self.linears.append(Linear(out_emb_dim, dim_target))\n",
    "\n",
    "        self.nns = torch.nn.ModuleList(self.nns)\n",
    "        self.convs = torch.nn.ModuleList(self.convs)\n",
    "        self.linears = torch.nn.ModuleList(self.linears)  # has got one more for initial input\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        out = 0\n",
    "\n",
    "        for layer in range(self.no_layers):\n",
    "            if layer == 0:\n",
    "                x = self.first_h(x)\n",
    "                out += F.dropout(self.pooling(self.linears[layer](x), batch), p=self.dropout)\n",
    "            else:\n",
    "                # Layer l (\"convolution\" layer)\n",
    "                x = self.convs[layer-1](x, edge_index)\n",
    "                out += F.dropout(self.linears[layer](self.pooling(x, batch)), p=self.dropout, training=self.training)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "727ca50d-b86f-4f61-be73-45c3d92d368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, input_dim, targets):\n",
    "        super(GCN, self).__init__()\n",
    "        # torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(input_dim, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.mlp = Linear(hidden_channels, targets)\n",
    "        self.mlp = Sequential(Linear(hidden_channels, hidden_channels), BatchNorm1d(hidden_channels), ReLU(), Linear(hidden_channels, hidden_channels), BatchNorm1d(hidden_channels), ReLU(), Linear(hidden_channels, targets))\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Convolution layers \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # x = x.relu()\n",
    "        # x = self.conv3(x, edge_index)\n",
    "        # x = x.relu()\n",
    "        # x = self.conv4(x, edge_index)\n",
    "        \n",
    "    \n",
    "        # pooling\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.mlp(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e74255e6-404b-4a79-bbfb-479c81d43b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/maxperozek/GNN-research/HGP-SL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db5768dc-6783-4217-baa5-a2a5d61d2bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/maxperozek/GNN-research/HGP-SL',\n",
       " '/Users/maxperozek/GNN-research/GNN-exp-pipeline',\n",
       " '/Users/maxperozek/opt/anaconda3/envs/comp_gr_thy/lib/python39.zip',\n",
       " '/Users/maxperozek/opt/anaconda3/envs/comp_gr_thy/lib/python3.9',\n",
       " '/Users/maxperozek/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/Users/maxperozek/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f7321a4-8c3d-4a48-aeb4-f231a47e4edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a4f27a6-4f9e-45b0-a459-814af972f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    seed = 777\n",
    "    batch_size = 128\n",
    "    lr = 0.001\n",
    "    weight_decay = 0.001\n",
    "    nhid = 128\n",
    "    sample_neighbor = True\n",
    "    sparse_attention = True\n",
    "    structure_learning = True\n",
    "    pooling_ratio = 0.5\n",
    "    dropout_ratio = 0.0\n",
    "    lamb = 1.0\n",
    "    device = 'cpu'\n",
    "    epochs = 1000\n",
    "    patience = 100\n",
    "    num_features = 3\n",
    "    num_classes = 2\n",
    "\n",
    "args=Args()\n",
    "\n",
    "model = Model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2571cfdf-e4aa-4ec2-b6fb-6c45a6edfac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=32, input_dim=3, targets=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2eb7d9-059c-4174-a246-0f49a7edc942",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'hidden_units':[32,32,32],\n",
    "    'train_eps': False,\n",
    "    'aggregation':'sum',\n",
    "    'dropout':0.0\n",
    "         }\n",
    "model = GIN(3, 2,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4462e60b-4be5-4d59-82cb-921ab02a2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=torch.Tensor(weights))\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24aa7ec2-f94c-4701-85d4-b6119483890d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b9122b69ee4b1fb24cf85fb1c6cc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "coalesce() got an unexpected keyword argument 'fill_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# model_out = model(batch.x.float(), batch.edge_index, batch.batch)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(batch\u001b[38;5;241m.\u001b[39my, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(model_out, torch\u001b[38;5;241m.\u001b[39mTensor(y))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/GNN-research/HGP-SL/models.py:39\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     36\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index, edge_attr))\n\u001b[0;32m---> 39\u001b[0m x, edge_index, edge_attr, batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m x1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([gmp(x, batch), gap(x, batch)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index, edge_attr))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/GNN-research/HGP-SL/layers.py:203\u001b[0m, in \u001b[0;36mHGPSLPool.forward\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m    201\u001b[0m hop_data \u001b[38;5;241m=\u001b[39m Data(x\u001b[38;5;241m=\u001b[39moriginal_x, edge_index\u001b[38;5;241m=\u001b[39medge_index, edge_attr\u001b[38;5;241m=\u001b[39medge_attr)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_hop \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 203\u001b[0m     hop_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbor_augment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhop_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m hop_edge_index \u001b[38;5;241m=\u001b[39m hop_data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m    205\u001b[0m hop_edge_attr \u001b[38;5;241m=\u001b[39m hop_data\u001b[38;5;241m.\u001b[39medge_attr\n",
      "File \u001b[0;32m~/GNN-research/HGP-SL/layers.py:31\u001b[0m, in \u001b[0;36mTwoHopNeighborhood.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     29\u001b[0m value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(edge_attr\u001b[38;5;241m.\u001b[39msize())[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m     30\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_attr, value], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m data\u001b[38;5;241m.\u001b[39medge_index, edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43mcoalesce\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m edge_attr[edge_attr \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m fill] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     33\u001b[0m data\u001b[38;5;241m.\u001b[39medge_attr \u001b[38;5;241m=\u001b[39m edge_attr\n",
      "\u001b[0;31mTypeError\u001b[0m: coalesce() got an unexpected keyword argument 'fill_value'"
     ]
    }
   ],
   "source": [
    "for e in tqdm_notebook(range(epochs)):\n",
    "    \n",
    "    model.train()\n",
    "    loss_sum = []\n",
    "    batches = 0\n",
    "    for _, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # model_out = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "        model_out = model(batch)\n",
    "        y = keras.utils.to_categorical(batch.y, 2)\n",
    "        loss = loss_fn(model_out, torch.Tensor(y))\n",
    "        loss_sum.append(float(loss.detach()))\n",
    "        batches += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if e % 5 == 0:\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                # out = model(data.x.float(), data.edge_index, data.batch)\n",
    "                out = model(data)\n",
    "                # print(f'out {out}')\n",
    "                # print(f'argmax {torch.argmax(out, dim=1).numpy()}')\n",
    "                cor_list = (torch.argmax(out, dim=1).numpy() == data.y.numpy())\n",
    "                # print(f'bools {cor_list}')\n",
    "                # print(f'labels {data.y}')\n",
    "                correct += cor_list.sum()\n",
    "                f1 = f1_score(data.y.numpy(), torch.argmax(out, dim=1).numpy())\n",
    "\n",
    "        print(f'\\neval acc: {correct / len(test_loader.dataset)} \\n f1 score: {f1}\\n')\n",
    "        \n",
    "    print(f'epoch {e} loss: {sum(loss_sum)/batches}')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "8404c404-1190-4c25-8ec8-c81cda87ecdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6791, -0.6866, -0.3721, -0.5100, -0.0794])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens = torch.Tensor(-1 * np.random.random(5,))\n",
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "b2786983-215a-488d-bdb1-6353643a0368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "0f205e24-e554-4ccf-b175-f7d3635a179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WICO(2914)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "f3b06dea-b09a-4666-bb77-e9e5328aebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "misinfo_size = []\n",
    "misinfo_nedges = []\n",
    "for w in [g for g in wico if g.y == 1]:\n",
    "    misinfo_size.append(w.x.shape[0])\n",
    "    misinfo_nedges.append(len(w.edge_index.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "f96b653c-0333-4bbc-93fe-03efbd4ba41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg nodes misinfo: 46.29126213592233\n",
      "avg edges misinfo: 142.3131067961165\n"
     ]
    }
   ],
   "source": [
    "print(f'avg nodes misinfo: {sum(misinfo_size)/len(misinfo_size)}')\n",
    "print(f'avg edges misinfo: {sum(misinfo_nedges)/len(misinfo_nedges)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "64efc17f-f457-4f90-9f46-59ce1f2100ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "realinfo_size = []\n",
    "realinfo_nedges = []\n",
    "for w in [g for g in wico if g.y == 0]:\n",
    "    realinfo_size.append(w.x.shape[0])\n",
    "    realinfo_nedges.append(len(w.edge_index.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "ef6138d1-9b08-4a2d-b133-1cd1d8959ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg nodes misinfo: 62.80815347721823\n",
      "avg edges misinfo: 132.29056754596323\n"
     ]
    }
   ],
   "source": [
    "print(f'avg nodes misinfo: {sum(realinfo_size)/len(realinfo_size)}')\n",
    "print(f'avg edges misinfo: {sum(realinfo_nedges)/len(realinfo_nedges)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e094ab-5c85-4f53-8406-46136556f02f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
