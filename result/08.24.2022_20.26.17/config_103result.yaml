config:
  aggregation: mean
  batch_size: 256
  class_weights: true
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.5
  epochs: 100
  hidden_units:
  - 64
  - 64
  - 64
  - 64
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.01
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: true
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-24 22:42:37.078497'
fold_0_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_103fold_0_optim_dict.pt
fold_0_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_103fold_0_state_dict.pt
fold_1_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_103fold_1_optim_dict.pt
fold_1_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_103fold_1_state_dict.pt
fold_2_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_103fold_2_optim_dict.pt
fold_2_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_103fold_2_state_dict.pt
fold_3_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_103fold_3_optim_dict.pt
fold_3_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_103fold_3_state_dict.pt
fold_4_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_103fold_4_optim_dict.pt
fold_4_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_103fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 1.1417464673519135
  - 0.9157946765422822
  - 0.9424284756183625
  - 0.83420529961586
  - 0.9759453356266022
  - 0.8653705060482025
  - 0.8522698760032654
  - 0.7962540745735169
  - 0.8101898550987244
  - 0.8020412504673005
  - 0.812625253200531
  - 0.8320958197116852
  - 0.8186047852039338
  - 0.9336749494075776
  - 0.8626281678676606
  - 0.8155847549438477
  - 0.8647737443447113
  - 0.7765082597732544
  - 0.8299055397510529
  - 0.8261910200119019
  - 0.8357410192489625
  validation_losses:
  - 0.41895583271980286
  - 0.44606760144233704
  - 0.4058082699775696
  - 0.40704435110092163
  - 0.39558738470077515
  - 0.42555704712867737
  - 0.3950366675853729
  - 0.38984787464141846
  - 0.40705978870391846
  - 0.3967348039150238
  - 0.3835445046424866
  - 0.40837955474853516
  - 0.38877421617507935
  - 0.3951234519481659
  - 0.4074150323867798
  - 0.40653109550476074
  - 0.38421884179115295
  - 0.3864744007587433
  - 0.39370259642601013
  - 0.40020665526390076
  - 0.39561015367507935
loss_records_fold1:
  train_losses:
  - 0.8473092317581177
  - 0.8022020518779756
  - 0.8757762491703034
  - 0.791942459344864
  - 0.8218066215515137
  - 0.7980508804321289
  - 0.8179424405097961
  - 0.8684396266937257
  - 0.8330447435379029
  - 0.8235710382461549
  - 0.7893503963947297
  validation_losses:
  - 0.39155834913253784
  - 0.3939498960971832
  - 0.395484060049057
  - 0.4002326428890228
  - 0.39303919672966003
  - 0.397887647151947
  - 0.4019804894924164
  - 0.3936985433101654
  - 0.39237114787101746
  - 0.3958701491355896
  - 0.39630094170570374
loss_records_fold2:
  train_losses:
  - 0.8072460055351258
  - 0.8368407189846039
  - 0.8415102124214173
  - 0.827360099554062
  - 0.7895908117294312
  - 0.7704419732093811
  - 0.8470904707908631
  - 0.778981900215149
  - 0.806541919708252
  - 0.7954939484596253
  - 0.8052445590496063
  - 0.8409826576709748
  - 0.83886678814888
  validation_losses:
  - 0.39563503861427307
  - 0.3886512219905853
  - 0.4016284942626953
  - 0.4092385172843933
  - 0.3996141254901886
  - 0.3930600881576538
  - 0.4236701428890228
  - 0.39429518580436707
  - 0.4042431712150574
  - 0.3862862288951874
  - 0.3837684094905853
  - 0.39090096950531006
  - 0.3975033462047577
loss_records_fold3:
  train_losses:
  - 0.8110849499702454
  - 0.80275177359581
  - 0.7830079317092896
  - 0.8020667314529419
  - 0.770750117301941
  - 0.8370493352413177
  - 0.8391831874847413
  - 0.8006023705005646
  - 0.8221021354198457
  - 0.8276157438755036
  - 0.7951700568199158
  validation_losses:
  - 0.39150893688201904
  - 0.4035325348377228
  - 0.37588080763816833
  - 0.38038554787635803
  - 0.38164931535720825
  - 0.3864283561706543
  - 0.3910646140575409
  - 0.3788646459579468
  - 0.3855871558189392
  - 0.38751429319381714
  - 0.3910144567489624
loss_records_fold4:
  train_losses:
  - 0.8442455232143402
  - 0.7596645206212997
  - 0.9667638301849366
  - 0.8997673571109772
  - 0.812177711725235
  - 0.8078479886054993
  - 0.7900099754333496
  - 0.779884558916092
  - 0.789806991815567
  - 0.7772342205047608
  - 0.8092826664447785
  - 1.6121936440467834
  - 0.9470430314540863
  - 0.8648690283298492
  - 0.8072603702545167
  - 0.8155054390430451
  - 0.8269879519939423
  - 0.7894542634487153
  - 0.8065028846263886
  - 0.7903264522552491
  - 0.7855227649211884
  - 0.8020643949508668
  - 0.8380280613899231
  validation_losses:
  - 0.379289448261261
  - 0.3927540183067322
  - 0.38421449065208435
  - 0.3849049508571625
  - 0.4264582395553589
  - 0.39676833152770996
  - 0.39897027611732483
  - 0.40978196263313293
  - 0.3822067379951477
  - 0.3911183774471283
  - 0.41077128052711487
  - 0.41886526346206665
  - 0.4088282287120819
  - 0.3841404914855957
  - 0.4328281879425049
  - 0.3937477469444275
  - 0.40624162554740906
  - 0.3807498812675476
  - 0.3882109820842743
  - 0.38735443353652954
  - 0.391703724861145
  - 0.39710769057273865
  - 0.4003581702709198
training fold messages:
  fold 0 training message: stopped training due to stagnating improvement on validation
    loss after 21 epochs
  fold 1 training message: stopped training due to stagnating improvement on validation
    loss after 11 epochs
  fold 2 training message: stopped training due to stagnating improvement on validation
    loss after 13 epochs
  fold 3 training message: stopped training due to stagnating improvement on validation
    loss after 11 epochs
  fold 4 training message: stopped training due to stagnating improvement on validation
    loss after 23 epochs
training_metrics:
  fold_eval_accs: '[0.8542024013722127, 0.8576329331046312, 0.8593481989708405, 0.8593481989708405,
    0.8591065292096219]'
  fold_eval_f1: '[0.0, 0.0, 0.0, 0.0, 0.0]'
  mean_eval_accuracy: 0.8579276523256294
  mean_f1_accuracy: 0.0
  total_train_time: '0:06:48.685441'
