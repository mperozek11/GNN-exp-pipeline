config:
  aggregation: mean
  batch_size: 64
  class_weights: false
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.0
  epochs: 100
  hidden_units:
  - 32
  - 32
  - 32
  - 32
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.01
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: false
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-22 17:11:53.846942'
fold_0_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_49fold_0_optim_dict.pt
fold_0_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_49fold_0_state_dict.pt
fold_1_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_49fold_1_optim_dict.pt
fold_1_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_49fold_1_state_dict.pt
fold_2_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_49fold_2_optim_dict.pt
fold_2_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_49fold_2_state_dict.pt
fold_3_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_49fold_3_optim_dict.pt
fold_3_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_49fold_3_state_dict.pt
fold_4_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_49fold_4_optim_dict.pt
fold_4_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_49fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 3.1806926608085635
  - 2.9062583595514297
  - 2.9673706591129303
  - 2.915435290336609
  - 2.8917579233646395
  - 2.9146605610847476
  - 2.9732626736164094
  - 2.861234846711159
  - 2.825913849473
  - 2.8191128551959994
  - 2.820551806688309
  - 2.86865850687027
  - 2.883793288469315
  - 2.899994194507599
  - 2.8076544135808947
  - 2.8803068310022355
  - 2.9088082283735277
  - 2.863564068078995
  - 2.9057972192764283
  - 2.82911930680275
  - 2.8724942177534105
  - 2.8742161929607395
  - 2.8222697377204895
  - 2.89646135866642
  - 2.9204493641853335
  - 2.8860873669385914
  - 2.8560231536626817
  - 2.902597373723984
  - 2.94394750893116
  - 2.856426727771759
  - 2.798870134353638
  - 2.8151057183742525
  - 2.811523559689522
  - 2.829544073343277
  - 2.817662769556046
  - 2.847860872745514
  - 2.7915123581886294
  - 2.8085616022348407
  - 2.79169953763485
  - 2.771936109662056
  - 2.798059630393982
  - 2.793240797519684
  - 2.767234069108963
  - 2.7559155225753784
  - 2.7846979171037676
  - 2.86243037879467
  - 2.8022451341152195
  - 2.7908557593822483
  - 2.782812768220902
  - 2.7839600503444673
  - 2.794353410601616
  - 2.766239929199219
  - 2.8262806087732315
  - 2.8346034765243533
  - 2.7866681635379793
  - 2.869908383488655
  - 2.7544248282909396
  - 2.7387686342000963
  - 2.7361440747976307
  - 2.767365032434464
  - 2.776940628886223
  - 2.756494864821434
  - 2.73825723528862
  - 2.7946674823760986
  - 2.7570034980773928
  - 2.787415474653244
  - 2.8095460891723634
  - 2.7654450833797455
  - 2.755311793088913
  - 2.7305983841419224
  - 2.8068774193525314
  - 2.761522924900055
  - 2.7644599199295046
  - 2.786490657925606
  - 2.8008243381977085
  - 2.7795077085494997
  - 2.875118610262871
  - 2.7955285757780075
  - 2.7861289948225023
  - 2.768480691313744
  - 2.754908707737923
  - 2.778453999757767
  - 2.7604715883731843
  - 2.762937325239182
  - 2.781432726979256
  - 2.7440241098403932
  - 2.7122704684734344
  - 2.7188140839338306
  - 2.7741712957620623
  - 2.7481608331203464
  - 2.760190722346306
  - 2.7349411845207214
  - 2.735495385527611
  - 2.718556594848633
  - 2.7302284598350526
  - 2.749579456448555
  - 2.761088788509369
  - 2.696643978357315
  - 2.6993175566196443
  - 2.7234002292156223
  validation_losses:
  - 0.4254266619682312
  - 0.405909925699234
  - 0.40220117568969727
  - 0.43103906512260437
  - 0.41138142347335815
  - 0.44769519567489624
  - 0.3911285698413849
  - 0.380056768655777
  - 0.38845568895339966
  - 0.38169148564338684
  - 0.4078122079372406
  - 0.38127148151397705
  - 0.3843806982040405
  - 0.4023691415786743
  - 0.3888617753982544
  - 0.41765856742858887
  - 0.38223201036453247
  - 0.3917582035064697
  - 0.39239391684532166
  - 0.40852105617523193
  - 0.4317600131034851
  - 0.61529541015625
  - 0.4203878343105316
  - 0.39218980073928833
  - 0.7119733095169067
  - 1.8101170063018799
  - 0.380696177482605
  - 0.3944798707962036
  - 0.4005829095840454
  - 0.385642409324646
  - 0.40303006768226624
  - 0.4019086956977844
  - 0.38083598017692566
  - 0.5410577654838562
  - 0.4738229513168335
  - 0.3926462233066559
  - 0.39038515090942383
  - 1.0292876958847046
  - 0.41428273916244507
  - 0.37697482109069824
  - 0.48528775572776794
  - 0.4789828658103943
  - 0.41425731778144836
  - 1.3841849565505981
  - 0.3990508019924164
  - 0.42727354168891907
  - 0.46515533328056335
  - 0.44454655051231384
  - 0.5492575168609619
  - 0.5010355114936829
  - 0.44811955094337463
  - 0.860904335975647
  - 0.41835352778434753
  - 0.38039204478263855
  - 1.8840608596801758
  - 0.3823670446872711
  - 0.4899463355541229
  - 0.4223634898662567
  - 0.7293468117713928
  - 0.9401634931564331
  - 0.3753916025161743
  - 0.6633517742156982
  - 0.6507652997970581
  - 0.685602068901062
  - 0.3874959349632263
  - 0.416936457157135
  - 0.4193285405635834
  - 0.49989908933639526
  - 1.0296330451965332
  - 0.9355010390281677
  - 1.2374902963638306
  - 0.8500641584396362
  - 0.9183904528617859
  - 0.9980338215827942
  - 0.5203357338905334
  - 0.9282284379005432
  - 0.5521969795227051
  - 0.4490038752555847
  - 0.7769330739974976
  - 0.395515114068985
  - 0.37304040789604187
  - 0.3973943293094635
  - 0.700904905796051
  - 0.4949435591697693
  - 0.45586106181144714
  - 1.1602624654769897
  - 0.4949660897254944
  - 1.5259549617767334
  - 0.44568249583244324
  - 0.46760323643684387
  - 0.5254674553871155
  - 2.176595687866211
  - 1.3557707071304321
  - 0.5159560441970825
  - 0.44283267855644226
  - 0.796619176864624
  - 0.6226049661636353
  - 0.5864841341972351
  - 0.8250950574874878
  - 1.1821955442428589
loss_records_fold1:
  train_losses:
  - 2.7613075584173203
  - 2.7895823359489444
  - 2.7677557528018952
  - 2.749885591864586
  - 2.7919200122356416
  - 2.7651967465877534
  - 2.716001436114311
  - 2.747045460343361
  - 2.693150642514229
  - 2.7649194270372393
  - 2.7345378369092943
  - 2.764606788754463
  - 2.754357534646988
  - 2.7551045268774033
  - 2.7252707302570345
  - 2.6950856775045398
  - 2.7132041215896607
  - 2.744103139638901
  - 2.776507115364075
  - 2.734725069999695
  - 2.7207561492919923
  - 2.7525520831346513
  - 2.6735723793506625
  - 2.7505605071783066
  - 2.7385846734046937
  - 2.6635316371917725
  - 2.6938258826732637
  - 2.786405766010285
  - 2.6955310583114627
  - 2.774588480591774
  - 2.7569661885499954
  - 2.714654022455216
  - 2.7311375081539158
  - 2.7286224603652958
  - 2.698868289589882
  - 2.7495865762233738
  - 2.715793988108635
  - 2.728844404220581
  - 2.6797149360179904
  - 2.718998318910599
  - 2.726876947283745
  - 2.6892297953367237
  - 2.7204546093940736
  - 2.7325181007385257
  - 2.688992014527321
  - 2.727676692605019
  - 2.672717195749283
  - 2.7181323707103733
  - 2.7410443276166916
  - 2.7548536300659183
  - 2.7127607405185703
  - 2.7387248605489733
  - 2.6647713392972947
  - 2.665314602851868
  - 2.710635167360306
  - 2.697233933210373
  - 2.696326416730881
  - 2.6781911849975586
  - 2.704884344339371
  - 2.75039741396904
  - 2.7179092645645144
  - 2.688553082942963
  - 2.7023357152938843
  - 2.6929051995277407
  - 2.6841612815856934
  - 2.6713351756334305
  - 2.667304188013077
  - 2.6970102936029434
  - 2.673254790902138
  - 2.7242431640625
  - 2.6717101424932483
  - 2.7035310298204425
  - 2.7066983550786974
  - 2.692294842004776
  - 2.7245912462472917
  - 2.708060270547867
  - 2.707810488343239
  - 2.628287523984909
  - 2.6819238454103473
  - 2.7088780760765077
  - 2.7638136535882953
  - 2.7591511338949206
  - 2.7702340692281724
  - 2.727866950631142
  - 2.7242471456527713
  - 2.7839549601078035
  - 2.767932778596878
  - 2.722171276807785
  - 2.686012101173401
  - 2.7364577591419224
  - 2.7144960165023804
  - 2.718138921260834
  - 2.7139779895544054
  - 2.7012200087308886
  - 2.839074394106865
  - 2.708756971359253
  - 2.7242973148822784
  - 2.7298038929700854
  - 2.6875556260347366
  - 2.7224951505661013
  validation_losses:
  - 0.4660702347755432
  - 0.6807554960250854
  - 0.40401947498321533
  - 0.3885343074798584
  - 0.3863126039505005
  - 0.43585631251335144
  - 0.4235702157020569
  - 0.7225143313407898
  - 0.38174939155578613
  - 0.41321444511413574
  - 0.5232800841331482
  - 0.4600028395652771
  - 0.579244077205658
  - 0.45873260498046875
  - 0.4106500744819641
  - 0.53330397605896
  - 0.5554247498512268
  - 0.6880483031272888
  - 0.37338054180145264
  - 0.4132447838783264
  - 0.526512086391449
  - 0.4441791772842407
  - 0.41358682513237
  - 0.6751892566680908
  - 0.41188308596611023
  - 0.6646939516067505
  - 0.5479989647865295
  - 0.5428309440612793
  - 1.0400265455245972
  - 1.5358514785766602
  - 0.6102039813995361
  - 0.5136064291000366
  - 0.48229730129241943
  - 0.4067859649658203
  - 0.5479636788368225
  - 0.5009276270866394
  - 0.5900425910949707
  - 0.5781747698783875
  - 0.6154438853263855
  - 0.6566537022590637
  - 0.5317679047584534
  - 0.6236626505851746
  - 0.6248529553413391
  - 0.8331524133682251
  - 0.564055323600769
  - 0.5700916051864624
  - 0.47206372022628784
  - 0.544141411781311
  - 0.6469472050666809
  - 0.4220183193683624
  - 0.4917590022087097
  - 0.6270136833190918
  - 0.7111775875091553
  - 0.8095002770423889
  - 0.557385265827179
  - 0.446512371301651
  - 0.6508996486663818
  - 0.6401981711387634
  - 0.4572562873363495
  - 0.39918914437294006
  - 0.45728978514671326
  - 0.6183846592903137
  - 0.50503009557724
  - 0.864142894744873
  - 0.4795718789100647
  - 0.4526914954185486
  - 0.7637522220611572
  - 0.6111266016960144
  - 0.5778581500053406
  - 0.7096621990203857
  - 0.6921690106391907
  - 0.5890458822250366
  - 0.6832807660102844
  - 0.7593863606452942
  - 0.3866497278213501
  - 1.1368963718414307
  - 0.6860554814338684
  - 0.6500476598739624
  - 0.8190247416496277
  - 0.9300899505615234
  - 0.3895856738090515
  - 0.47562938928604126
  - 0.3875948190689087
  - 0.3821018636226654
  - 0.3789365291595459
  - 0.392734557390213
  - 0.3848284184932709
  - 0.3823874592781067
  - 0.38611289858818054
  - 0.41055113077163696
  - 0.38992220163345337
  - 0.37509408593177795
  - 0.38252267241477966
  - 0.3841645121574402
  - 0.4124027192592621
  - 0.3892119228839874
  - 0.39068302512168884
  - 0.3817910850048065
  - 0.43138793110847473
  - 0.48601794242858887
loss_records_fold2:
  train_losses:
  - 2.710185319185257
  - 2.7169910579919816
  - 2.6843874841928486
  - 2.6920832246541977
  - 2.655900511145592
  - 2.6626121282577517
  - 2.679292225837708
  - 2.656290912628174
  - 2.6821290194988254
  - 2.6456714242696764
  - 2.653035491704941
  - 2.6766410887241365
  - 2.7070856720209124
  - 2.6250427961349487
  - 2.683617150783539
  - 2.711026567220688
  - 2.6948619902133943
  - 2.667872667312622
  - 2.667955553531647
  - 2.7179995328187943
  - 2.6784092575311664
  - 2.6090309500694278
  - 2.7096322715282444
  - 2.6342711418867113
  - 2.7188899487257006
  - 2.7326820343732834
  - 2.597514507174492
  - 2.7002584815025332
  - 2.6761249601840973
  - 2.7173520982265473
  - 2.6652859449386597
  - 2.6662191390991214
  - 2.656152606010437
  - 2.6324381768703464
  - 2.695897728204727
  - 2.70364605486393
  - 2.6691113740205767
  - 2.6760980546474458
  - 2.6531006485223774
  - 2.6329598248004915
  - 2.671672284603119
  - 2.63970884680748
  - 2.6013861894607544
  - 2.6165097236633303
  - 2.6518204629421236
  - 2.628758001327515
  - 2.6638932436704637
  - 2.605599445104599
  - 2.6338838905096056
  - 2.6299335181713106
  - 2.6390401780605317
  - 2.5653587490320207
  - 2.6101611971855165
  - 2.691340094804764
  - 2.662127995491028
  - 2.701322203874588
  - 2.6780786097049716
  - 2.6114538580179216
  - 2.5986025035381317
  - 2.660735562443733
  - 2.6618118405342104
  - 2.608781298995018
  - 2.6514828979969027
  - 2.6005067974328995
  - 2.627388742566109
  - 2.6654574424028397
  - 2.6078120678663255
  - 2.635648894309998
  - 2.681986752152443
  - 2.6306696057319643
  - 2.620752066373825
  - 2.635627630352974
  - 2.6513753652572634
  - 2.6546122550964357
  - 2.6006716877222065
  - 2.625686687231064
  - 2.591937774419785
  - 2.6186489284038545
  - 2.702631184458733
  - 2.671946603059769
  - 2.7611588656902315
  - 2.6574259221553804
  - 2.742126625776291
  - 2.654442843794823
  - 2.6672588467597964
  - 2.742108562588692
  - 2.645703959465027
  - 2.667252165079117
  - 2.6423542588949207
  - 2.592624068260193
  - 2.580430412292481
  - 2.6054232865571976
  - 2.61184424161911
  - 2.6705045729875567
  - 2.6824780702590942
  - 2.6421913444995884
  - 2.6754820704460145
  - 2.6260304361581803
  - 2.6398255437612534
  - 2.663282510638237
  validation_losses:
  - 0.45652979612350464
  - 0.42448899149894714
  - 0.46321943402290344
  - 0.4543404281139374
  - 0.4018038809299469
  - 0.43366748094558716
  - 0.42444509267807007
  - 0.4389321804046631
  - 0.5039916634559631
  - 0.554415762424469
  - 0.40095335245132446
  - 0.48878005146980286
  - 0.4906274378299713
  - 0.5225661396980286
  - 0.38397425413131714
  - 0.4015899896621704
  - 0.38057056069374084
  - 0.4027489125728607
  - 0.43870601058006287
  - 0.4092485308647156
  - 0.387334406375885
  - 0.4352947771549225
  - 0.4999668300151825
  - 0.39347806572914124
  - 0.4783592224121094
  - 0.42581355571746826
  - 0.539716362953186
  - 0.48004716634750366
  - 0.6300546526908875
  - 0.3873150944709778
  - 0.4148448705673218
  - 0.5397672653198242
  - 0.6259087920188904
  - 0.7766183614730835
  - 0.44948869943618774
  - 0.5329735279083252
  - 1.0052176713943481
  - 0.46770644187927246
  - 0.44527530670166016
  - 0.5076560378074646
  - 0.5068678855895996
  - 0.7989013195037842
  - 0.6805061101913452
  - 1.0083820819854736
  - 0.4545171856880188
  - 0.6282998919487
  - 0.7741098403930664
  - 0.4668963551521301
  - 0.4786008596420288
  - 0.5922507047653198
  - 0.3866235017776489
  - 0.5497217774391174
  - 0.7551658153533936
  - 0.3774998188018799
  - 0.6135780811309814
  - 0.5100940465927124
  - 0.47116905450820923
  - 0.468777596950531
  - 0.45662593841552734
  - 0.5040240287780762
  - 0.9892294406890869
  - 0.5634287595748901
  - 0.9786633849143982
  - 0.6142284870147705
  - 0.5013676285743713
  - 0.5086323618888855
  - 0.5945293307304382
  - 0.5585111379623413
  - 1.096205711364746
  - 0.6136845350265503
  - 0.9980563521385193
  - 0.6122368574142456
  - 0.3816075921058655
  - 0.6339341998100281
  - 0.8662698268890381
  - 1.109955906867981
  - 0.8972576260566711
  - 0.515761137008667
  - 0.41796064376831055
  - 0.49348652362823486
  - 0.41584885120391846
  - 0.49658361077308655
  - 0.45986059308052063
  - 0.44519221782684326
  - 1.0677191019058228
  - 1.6860500574111938
  - 0.9417133331298828
  - 0.65434730052948
  - 0.5730850100517273
  - 0.42592853307724
  - 1.8469841480255127
  - 0.6607072353363037
  - 1.3190252780914307
  - 1.4010756015777588
  - 1.516019582748413
  - 0.5676407814025879
  - 0.4095005691051483
  - 0.4363595247268677
  - 0.6278653740882874
  - 0.4844522178173065
loss_records_fold3:
  train_losses:
  - 2.655392521619797
  - 2.7176289558410645
  - 2.6569469183683396
  - 2.677401140332222
  - 2.6690133899450306
  - 2.734375792741776
  - 2.6918883085250855
  - 2.6510199457406998
  - 2.6454402416944505
  - 2.7328286439180376
  - 2.6706340938806536
  - 2.617645999789238
  - 2.711791676282883
  - 2.657947823405266
  - 2.679582303762436
  - 2.692142826318741
  - 2.7234258592128757
  - 2.707342001795769
  - 2.6531483590602876
  - 2.675228402018547
  - 2.627212455868721
  - 2.61033687889576
  - 2.665702858567238
  - 2.6689158529043198
  - 2.5996763437986377
  - 2.6274905800819397
  - 2.6576530396938325
  - 2.622394171357155
  - 2.5782112687826158
  - 2.698339891433716
  - 2.6655376434326175
  - 2.6629107624292376
  - 2.625958189368248
  - 2.685308650135994
  - 2.610417476296425
  - 2.6417606413364414
  - 2.6174569696187975
  - 2.6305775165557863
  - 2.634133607149124
  - 2.5785653680562977
  - 2.6052730679512024
  - 2.614856979250908
  - 2.672902038693428
  - 2.6412216782569886
  - 2.6909362435340882
  - 2.6168599724769592
  - 2.6758000493049625
  - 2.6646230906248096
  - 2.588687700033188
  - 2.608455604314804
  - 2.586504036188126
  - 2.5797811299562454
  - 2.6743871986866
  - 2.6214809060096744
  - 2.585737788677216
  - 2.603209757804871
  - 2.6315422654151917
  - 2.713836741447449
  - 2.756251648068428
  - 2.708181378245354
  - 2.660118111968041
  - 2.597948017716408
  - 2.6140163064002992
  - 2.61473049223423
  - 2.6018005460500717
  - 2.569935837388039
  - 2.6542649626731873
  - 2.591183042526245
  - 2.6067117333412173
  - 2.7297725915908817
  - 2.6769340306520464
  - 2.6159687578678135
  - 2.5814756184816363
  - 2.577528926730156
  - 2.638662475347519
  - 2.737089002132416
  - 2.705484449863434
  - 2.7097032725811006
  - 2.6718236744403843
  - 2.6660175263881687
  - 2.7147896885871887
  validation_losses:
  - 2.2674007415771484
  - 0.6556003093719482
  - 0.5542077422142029
  - 0.5504884719848633
  - 0.492875874042511
  - 0.4320010244846344
  - 0.48990365862846375
  - 0.4857797622680664
  - 0.5003499984741211
  - 0.3772204518318176
  - 0.47535771131515503
  - 0.5397539138793945
  - 0.5716496109962463
  - 0.42056187987327576
  - 0.5861355662345886
  - 0.5365166068077087
  - 0.4447716772556305
  - 0.5012728571891785
  - 0.46483686566352844
  - 0.6996498703956604
  - 0.6252251267433167
  - 0.5426340699195862
  - 0.6373932361602783
  - 0.6647475957870483
  - 2.461912155151367
  - 0.45653286576271057
  - 0.5400389432907104
  - 0.4067746102809906
  - 1.1722558736801147
  - 1.5827542543411255
  - 1.2865108251571655
  - 2.294304609298706
  - 4.4494524002075195
  - 9.830232620239258
  - 0.7783233523368835
  - 0.5078978538513184
  - 0.5110122561454773
  - 2.2162396907806396
  - 1.9536813497543335
  - 1.2284528017044067
  - 0.6818958520889282
  - 0.5229822397232056
  - 0.5249606966972351
  - 13.717580795288086
  - 81.143310546875
  - 33.35068893432617
  - 18.429805755615234
  - 1.8235818147659302
  - 3.258253335952759
  - 0.43165263533592224
  - 1.6180557012557983
  - 1.2685365676879883
  - 3.8966684341430664
  - 17.147232055664062
  - 3.5790481567382812
  - 0.549419641494751
  - 0.8043766617774963
  - 0.4947746992111206
  - 0.41641169786453247
  - 0.35214757919311523
  - 0.5083526372909546
  - 1.699661374092102
  - 2.7707877159118652
  - 3.557560443878174
  - 7.6399126052856445
  - 1.06841242313385
  - 9.802799224853516
  - 1.7005237340927124
  - 3.1144943237304688
  - 0.8599684238433838
  - 0.4686301350593567
  - 0.49950870871543884
  - 0.44039514660835266
  - 0.4091952443122864
  - 23.895753860473633
  - 0.36274099349975586
  - 0.35905763506889343
  - 0.35728582739830017
  - 0.3509080111980438
  - 0.35371801257133484
  - 0.3576817214488983
loss_records_fold4:
  train_losses:
  - 2.761502954363823
  - 2.6917772114276888
  - 2.705420482158661
  - 2.7115362703800203
  - 2.698078963160515
  - 2.627393299341202
  - 2.6292744487524033
  - 2.6281394720077516
  - 2.6175775289535523
  - 2.657529389858246
  - 2.615033006668091
  - 2.6046620070934297
  - 2.610173162817955
  - 2.6103902012109756
  - 2.675870567560196
  - 2.6888974756002426
  - 2.6692343026399614
  - 2.6173338472843173
  - 2.6113945066928865
  - 2.6435453534126285
  - 2.6789500236511232
  - 2.6457327157258987
  - 2.608248743414879
  - 2.6105364650487903
  - 2.5950726300477984
  - 2.673938059806824
  - 2.68928901553154
  - 2.611676496267319
  - 2.60504222214222
  - 2.613696536421776
  - 2.649116331338883
  - 2.5951269775629044
  - 2.6451271146535875
  - 2.6271172910928726
  - 2.585165724158287
  - 2.5906637102365497
  - 2.65274216234684
  - 2.5921231091022494
  - 2.5842854470014576
  - 2.636544400453568
  - 2.608503994345665
  - 2.6542901277542117
  - 2.6018194377422335
  - 2.6408369272947314
  - 2.641770350933075
  - 2.603019639849663
  - 2.603409466147423
  - 2.59723120033741
  - 2.5703951209783558
  - 2.6174285620450974
  - 2.676850134134293
  - 2.5870838820934297
  - 2.601902723312378
  - 2.6336432218551638
  - 2.604640391469002
  - 2.644924166798592
  - 2.6827997624874116
  - 2.603170239925385
  - 2.658329501748085
  - 2.612615141272545
  - 2.5972056925296787
  - 2.611666512489319
  - 2.6113682180643085
  - 2.638359445333481
  - 2.580381149053574
  - 2.612853699922562
  - 2.6393366008996964
  - 2.577984401583672
  - 2.6349387526512147
  - 2.6111025869846345
  - 2.571090602874756
  - 2.767361554503441
  - 2.628489664196968
  - 2.618988460302353
  - 2.6052025288343432
  - 2.661981052160263
  - 2.6497854590415955
  - 2.579818317294121
  - 2.527907866239548
  - 2.586800292134285
  - 2.662032440304756
  - 2.6215779393911363
  - 2.624765378236771
  - 2.569607526063919
  - 2.562482950091362
  - 2.5547724217176437
  - 2.614212626218796
  - 2.597750920057297
  - 2.5686603605747225
  - 2.585069262981415
  - 2.5851639777421953
  - 2.563590580224991
  - 2.6097939878702165
  - 2.6074116319417957
  - 2.5686942249536515
  - 2.5451757639646533
  - 2.546554604172707
  - 2.6223605006933215
  - 2.5958272188901903
  - 2.583392855525017
  validation_losses:
  - 0.3485768735408783
  - 0.34582963585853577
  - 0.3777582347393036
  - 0.35299229621887207
  - 0.39477279782295227
  - 0.3615890443325043
  - 0.37985435128211975
  - 0.38905879855155945
  - 0.4284302294254303
  - 0.39810842275619507
  - 0.37281814217567444
  - 0.392361581325531
  - 0.40625321865081787
  - 0.3826518654823303
  - 0.3768271207809448
  - 0.4207174479961395
  - 1.5721467733383179
  - 0.43050211668014526
  - 2.1258111000061035
  - 0.37809616327285767
  - 0.3818146586418152
  - 1.7718284130096436
  - 0.40426570177078247
  - 1.1059750318527222
  - 1.064185619354248
  - 0.9960830807685852
  - 0.3917372524738312
  - 0.360965758562088
  - 3.8918159008026123
  - 4.456500053405762
  - 0.890133798122406
  - 0.5289015173912048
  - 1.2336312532424927
  - 0.5732240676879883
  - 0.42077794671058655
  - 0.8215221762657166
  - 0.4544670581817627
  - 0.4727713465690613
  - 0.6307563185691833
  - 0.5299471616744995
  - 1.421026587486267
  - 1.3231754302978516
  - 4.5885701179504395
  - 4.528873920440674
  - 0.3726401925086975
  - 0.4123251140117645
  - 4.519819736480713
  - 2.7125816345214844
  - 0.5301737785339355
  - 0.4732246994972229
  - 0.47350823879241943
  - 0.8658744692802429
  - 0.5359710454940796
  - 0.40827155113220215
  - 7.205071449279785
  - 0.41450411081314087
  - 5.313618183135986
  - 0.8249983787536621
  - 3.1901652812957764
  - 1.2972277402877808
  - 1.395015835762024
  - 3.8904006481170654
  - 1.2066981792449951
  - 2.6649577617645264
  - 0.992024838924408
  - 0.8940209746360779
  - 6.740894794464111
  - 5.148471832275391
  - 2.8248989582061768
  - 0.6919722557067871
  - 3.4416115283966064
  - 0.38919711112976074
  - 0.4579201340675354
  - 0.5884875059127808
  - 0.4298502206802368
  - 0.4097591042518616
  - 1.3886184692382812
  - 0.752763032913208
  - 0.4213325083255768
  - 1.2846424579620361
  - 0.4210827648639679
  - 0.6312767863273621
  - 3.7518696784973145
  - 3.892378807067871
  - 2.022902011871338
  - 0.3861924707889557
  - 2.2530765533447266
  - 0.8465237617492676
  - 4.303643703460693
  - 0.487280935049057
  - 4.6239542961120605
  - 4.753635883331299
  - 2.4272453784942627
  - 2.0881659984588623
  - 0.6584064960479736
  - 2.6090877056121826
  - 0.5736917853355408
  - 3.242827892303467
  - 3.9281115531921387
  - 4.71909761428833
training fold messages:
  fold 0 training message: completed 100 epochs without stopping early
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: completed 100 epochs without stopping early
  fold 3 training message: stopped training due to stagnating improvement on validation
    loss after 81 epochs
  fold 4 training message: completed 100 epochs without stopping early
training_metrics:
  fold_eval_accs: '[0.8542024013722127, 0.8370497427101201, 0.8164665523156089, 0.8593481989708405,
    0.8470790378006873]'
  fold_eval_f1: '[0.08602150537634409, 0.04040404040404041, 0.19548872180451124, 0.046511627906976744,
    0.18348623853211007]'
  mean_eval_accuracy: 0.8428291866338938
  mean_f1_accuracy: 0.11038242680479651
  total_train_time: '0:45:33.573501'
