config:
  aggregation: mean
  batch_size: 256
  class_weights: false
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.0
  epochs: 100
  hidden_units:
  - 64
  - 64
  - 64
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.01
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: true
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-22 17:46:44.280916'
fold_0_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_67fold_0_optim_dict.pt
fold_0_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_67fold_0_state_dict.pt
fold_1_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_67fold_1_optim_dict.pt
fold_1_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_67fold_1_state_dict.pt
fold_2_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_67fold_2_optim_dict.pt
fold_2_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_67fold_2_state_dict.pt
fold_3_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_67fold_3_optim_dict.pt
fold_3_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_67fold_3_state_dict.pt
fold_4_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_67fold_4_optim_dict.pt
fold_4_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_67fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 0.9393980383872986
  - 0.8474725365638733
  - 0.8195612370967865
  - 0.750501561164856
  - 0.8038532435894012
  - 0.7757997512817383
  - 0.7921770751476288
  - 0.7455782800912858
  - 0.7881458818912507
  - 0.7685558557510377
  - 0.8187796831130982
  - 0.7577215492725373
  - 0.739159294962883
  - 0.7471671640872956
  - 0.7752357125282288
  - 0.7938297331333161
  - 0.8502648651599884
  - 0.7702325582504272
  - 0.7588729202747345
  - 0.761670583486557
  - 0.7766480267047883
  - 0.7783635854721069
  - 0.7883706092834473
  - 0.7392066776752473
  - 0.7476908326148988
  validation_losses:
  - 0.46079951524734497
  - 0.44262266159057617
  - 0.43515872955322266
  - 0.4361577033996582
  - 0.4160735309123993
  - 0.3872099220752716
  - 0.39788562059402466
  - 0.4099770784378052
  - 0.388126403093338
  - 0.38437768816947937
  - 0.40130892395973206
  - 0.3843855559825897
  - 0.38744568824768066
  - 0.38742536306381226
  - 0.3883951008319855
  - 0.38950398564338684
  - 0.40958285331726074
  - 0.38513559103012085
  - 0.39854058623313904
  - 0.4001506268978119
  - 0.3895726799964905
  - 0.3881543278694153
  - 0.38440942764282227
  - 0.38563117384910583
  - 0.3851882219314575
loss_records_fold1:
  train_losses:
  - 0.7434837639331818
  - 0.7365662634372712
  - 0.8076619029045106
  - 0.7707715153694153
  - 0.7607172906398774
  - 0.7579260528087617
  - 0.7240350544452667
  - 0.7808276534080506
  - 0.8042530775070191
  - 0.7481043756008149
  - 0.7581128239631654
  validation_losses:
  - 0.383362352848053
  - 0.38359010219573975
  - 0.38683071732521057
  - 0.3910945653915405
  - 0.3847687840461731
  - 0.3843476474285126
  - 0.3857175409793854
  - 0.3860037624835968
  - 0.3871310353279114
  - 0.3869610130786896
  - 0.3852773606777191
loss_records_fold2:
  train_losses:
  - 0.761329746246338
  - 0.7672526955604554
  - 0.8031267523765564
  - 0.7665123224258423
  - 0.7569249272346497
  - 0.769381582736969
  - 0.7447167336940765
  - 0.7498241186141968
  - 0.7407762229442597
  - 0.7614510715007783
  - 0.7359608560800552
  validation_losses:
  - 0.3840799927711487
  - 0.38423413038253784
  - 0.3870437443256378
  - 0.3816578984260559
  - 0.3855132460594177
  - 0.3834143877029419
  - 0.3864845037460327
  - 0.3918968141078949
  - 0.3840677738189697
  - 0.39011210203170776
  - 0.38961324095726013
loss_records_fold3:
  train_losses:
  - 0.7528561174869538
  - 0.7646634221076966
  - 0.7541613221168518
  - 0.7407741010189057
  - 0.7578086435794831
  - 0.764161342382431
  - 0.8519407093524933
  - 0.7592121869325639
  - 0.7633040606975556
  - 0.7672532200813293
  - 0.7504685699939728
  - 0.75863676071167
  - 0.7493990004062653
  - 0.7587336599826813
  - 0.7168840706348419
  - 0.7386185586452485
  - 0.7391899824142456
  - 0.7311582028865815
  - 0.7489677846431733
  - 0.7603564262390137
  - 0.827660346031189
  - 0.7449518620967865
  - 0.8169492185115814
  - 0.7887274563312531
  - 0.7921241700649262
  - 0.7967898726463318
  validation_losses:
  - 0.38670477271080017
  - 0.39424121379852295
  - 0.37870991230010986
  - 0.36870861053466797
  - 0.3738446831703186
  - 0.4126475751399994
  - 0.48177456855773926
  - 0.38647860288619995
  - 0.3777390122413635
  - 0.5385278463363647
  - 0.6753653287887573
  - 0.38927772641181946
  - 0.378213107585907
  - 0.37809687852859497
  - 0.45590677857398987
  - 0.4170081615447998
  - 0.6181731224060059
  - 0.4198101758956909
  - 0.48644381761550903
  - 0.7484870553016663
  - 0.3841537535190582
  - 0.3859509527683258
  - 0.3775646984577179
  - 0.37703970074653625
  - 0.3823968470096588
  - 0.3866284489631653
loss_records_fold4:
  train_losses:
  - 0.7446375012397767
  - 0.7572963654994965
  - 0.7953384816646576
  - 0.7406988590955734
  - 0.7514085173606873
  - 0.7581165492534638
  - 0.7498803436756134
  - 0.8665403902530671
  - 0.7873380184173584
  - 0.8205593526363373
  - 0.7275643914937974
  - 0.7544436872005463
  - 0.7523335218429565
  - 0.7666046917438507
  validation_losses:
  - 0.3805748224258423
  - 0.3908129334449768
  - 0.3806786835193634
  - 0.38658860325813293
  - 0.381322979927063
  - 0.3812277019023895
  - 0.37778663635253906
  - 0.38805025815963745
  - 0.3949059545993805
  - 0.4007655084133148
  - 0.3879280388355255
  - 0.39513686299324036
  - 0.38588741421699524
  - 0.38526758551597595
training fold messages:
  fold 0 training message: stopped training due to stagnating improvement on validation
    loss after 25 epochs
  fold 1 training message: stopped training due to stagnating improvement on validation
    loss after 11 epochs
  fold 2 training message: stopped training due to stagnating improvement on validation
    loss after 11 epochs
  fold 3 training message: stopped training due to stagnating improvement on validation
    loss after 26 epochs
  fold 4 training message: stopped training due to stagnating improvement on validation
    loss after 14 epochs
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.8576329331046312, 0.8593481989708405, 0.8593481989708405,
    0.8591065292096219]'
  fold_eval_f1: '[0.0, 0.0, 0.0, 0.0, 0.0]'
  mean_eval_accuracy: 0.858613758672113
  mean_f1_accuracy: 0.0
  total_train_time: '0:07:21.048662'
