config:
  aggregation: mean
  batch_size: 256
  class_weights: true
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.5
  epochs: 100
  hidden_units:
  - 32
  - 32
  - 32
  - 32
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.01
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: true
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-24 21:20:37.740436'
fold_0_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_39fold_0_optim_dict.pt
fold_0_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_39fold_0_state_dict.pt
fold_1_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_39fold_1_optim_dict.pt
fold_1_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_39fold_1_state_dict.pt
fold_2_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_39fold_2_optim_dict.pt
fold_2_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_39fold_2_state_dict.pt
fold_3_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_39fold_3_optim_dict.pt
fold_3_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_39fold_3_state_dict.pt
fold_4_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_39fold_4_optim_dict.pt
fold_4_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_39fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 1.1233369290828705
  - 0.8760549902915955
  - 0.9966548323631287
  - 0.8616108655929566
  - 0.8434895634651185
  - 0.8616968870162964
  - 0.90617516040802
  - 0.8488592147827149
  - 0.8006717771291734
  - 0.8586756110191346
  - 0.85339595079422
  validation_losses:
  - 0.40738093852996826
  - 0.4070943593978882
  - 0.40639978647232056
  - 0.4034758508205414
  - 0.41058218479156494
  - 0.40530866384506226
  - 0.41166871786117554
  - 0.3960133194923401
  - 0.4007534682750702
  - 0.4057430326938629
  - 0.40105023980140686
loss_records_fold1:
  train_losses:
  - 0.806031608581543
  - 0.8201807618141175
  - 0.8012502372264863
  - 0.7819207668304444
  - 0.897137987613678
  - 0.84152609705925
  - 0.7984944164752961
  - 0.8336060881614685
  - 0.7596932858228684
  - 0.781194943189621
  - 0.8210671901702882
  validation_losses:
  - 0.4000566303730011
  - 0.4123789668083191
  - 0.3994462788105011
  - 0.3936396539211273
  - 0.39851126074790955
  - 0.3949127197265625
  - 0.39662083983421326
  - 0.39451950788497925
  - 0.39999836683273315
  - 0.4033311605453491
  - 0.4005250632762909
loss_records_fold2:
  train_losses:
  - 0.859750521183014
  - 0.848025643825531
  - 0.840685796737671
  - 0.7845848917961121
  - 0.8096880257129669
  - 0.8396077394485474
  - 0.8043021619319917
  - 0.8226700484752656
  - 0.7893631219863892
  - 0.7548010110855103
  - 0.7951434552669525
  - 0.7768083810806274
  - 0.8048430144786836
  - 0.7863698720932008
  validation_losses:
  - 0.4258013665676117
  - 0.398578017950058
  - 0.39562177658081055
  - 0.4020344018936157
  - 0.393947958946228
  - 0.4171275794506073
  - 0.4017931818962097
  - 0.414623498916626
  - 0.3919467031955719
  - 0.38967442512512207
  - 0.3915039598941803
  - 0.38779306411743164
  - 0.38864654302597046
  - 0.3938847780227661
loss_records_fold3:
  train_losses:
  - 0.8300880074501038
  - 0.8037419319152832
  - 0.8514238059520722
  - 0.810232424736023
  - 0.8078545331954956
  - 0.7630153387784958
  - 0.8300943970680237
  - 0.8389638602733612
  - 0.80013467669487
  - 0.8283344388008118
  - 0.7757379055023194
  - 0.8111478626728058
  - 0.8040723681449891
  - 0.813908863067627
  - 0.8341802418231965
  - 0.8253542661666871
  - 0.8047380685806275
  - 0.8601549148559571
  - 0.8318780064582825
  - 0.8323792219161987
  - 0.790736973285675
  - 0.818555361032486
  - 0.8061113655567169
  - 0.8781709134578706
  validation_losses:
  - 0.40676262974739075
  - 0.3900706171989441
  - 0.41203197836875916
  - 0.40258046984672546
  - 0.38508886098861694
  - 0.3737247884273529
  - 0.3815772831439972
  - 0.37535470724105835
  - 0.3732250928878784
  - 0.551362931728363
  - 0.5472080111503601
  - 0.4829336702823639
  - 0.7655639052391052
  - 0.4164755940437317
  - 0.6486791372299194
  - 0.3813486695289612
  - 0.39393702149391174
  - 0.4117729663848877
  - 0.39130493998527527
  - 0.3907674551010132
  - 0.3714577257633209
  - 0.37670576572418213
  - 0.37323078513145447
  - 0.38161584734916687
loss_records_fold4:
  train_losses:
  - 0.8333809018135071
  - 0.8343080222606659
  - 0.772121798992157
  - 0.7841298997402192
  - 0.7883722066879273
  - 0.8110972404479981
  - 0.77235706448555
  - 0.8122288882732391
  - 0.9557379007339478
  - 0.8820913910865784
  - 0.7624736517667771
  - 0.7840899050235749
  - 0.8333053827285767
  - 0.79994255900383
  - 0.7864651560783387
  - 0.8006227016448975
  - 0.8144658625125886
  - 0.7562640100717545
  validation_losses:
  - 0.40870755910873413
  - 0.3804982602596283
  - 0.3908223807811737
  - 0.38184913992881775
  - 0.3913230299949646
  - 0.4088406562805176
  - 0.3880957067012787
  - 0.4089012145996094
  - 0.38530367612838745
  - 0.38181617856025696
  - 0.3965568244457245
  - 0.411922425031662
  - 0.4071528911590576
  - 0.40859806537628174
  - 0.3999427258968353
  - 0.40521079301834106
  - 0.40480977296829224
  - 0.387058287858963
training fold messages:
  fold 0 training message: stopped training due to stagnating improvement on validation
    loss after 11 epochs
  fold 1 training message: stopped training due to stagnating improvement on validation
    loss after 11 epochs
  fold 2 training message: stopped training due to stagnating improvement on validation
    loss after 14 epochs
  fold 3 training message: stopped training due to stagnating improvement on validation
    loss after 24 epochs
  fold 4 training message: stopped training due to stagnating improvement on validation
    loss after 18 epochs
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.8576329331046312, 0.8593481989708405, 0.8593481989708405,
    0.8591065292096219]'
  fold_eval_f1: '[0.023529411764705882, 0.0, 0.0, 0.0, 0.0]'
  mean_eval_accuracy: 0.858613758672113
  mean_f1_accuracy: 0.004705882352941176
  total_train_time: '0:06:33.028759'
