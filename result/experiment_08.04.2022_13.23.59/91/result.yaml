config:
  aggregation: sum
  batch_size: 64
  class_weights: false
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.5
  epochs: 100
  hidden_units:
  - 32
  - 32
  - 32
  - 32
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.1
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: true
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-04 23:49:18.449001'
fold_0_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/91/fold_0_optim_dict.pt
fold_0_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/91/fold_0_state_dict.pt
fold_1_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/91/fold_1_optim_dict.pt
fold_1_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/91/fold_1_state_dict.pt
fold_2_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/91/fold_2_optim_dict.pt
fold_2_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/91/fold_2_state_dict.pt
fold_3_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/91/fold_3_optim_dict.pt
fold_3_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/91/fold_3_state_dict.pt
fold_4_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/91/fold_4_optim_dict.pt
fold_4_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/91/fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 678.1123337745667
  - 142.27820280194283
  - 113.45009076595306
  - 162.78478345274925
  - 108.49797511100769
  - 193.1790789961815
  - 68.40877199172974
  - 28.06693497300148
  - 27.142257392406464
  - 18.230568051338196
  - 39.862750351428986
  - 36.69124615192413
  - 35.29944458603859
  - 28.83313888311386
  - 23.215172916650772
  - 26.098201796412468
  - 32.76869344711304
  - 93.86765877902508
  - 127.56116756796837
  - 100.79866227507591
  - 67.02475348114967
  - 42.775132685899734
  - 39.344955176115036
  - 70.58817055821419
  - 29.281939417123795
  - 37.64724442362785
  - 35.41928666830063
  - 36.07967048883438
  - 36.11884671449661
  - 29.86303272843361
  - 22.85120902955532
  - 21.49394518136978
  - 24.541695535182953
  - 25.677775502204895
  - 22.569174766540527
  - 22.021022379398346
  - 25.50014367699623
  - 20.166924118995667
  - 19.912513464689255
  - 23.635156124830246
  - 21.074452251195908
  - 28.631824493408203
  - 19.93364006280899
  - 20.853369787335396
  - 21.165959239006042
  - 21.40283265709877
  - 17.808324053883553
  - 22.092956066131592
  - 22.354108542203903
  - 26.030654340982437
  - 20.7859568297863
  - 25.33773136138916
  - 20.047752141952515
  - 18.64912039041519
  - 21.91853818297386
  - 31.2930870950222
  - 19.548844426870346
  - 22.13405381143093
  - 19.12215530872345
  - 22.16617986559868
  - 19.76164475083351
  - 39.4454091489315
  - 19.78804636001587
  - 20.68831616640091
  - 19.855612114071846
  - 30.004197537899017
  - 19.172816663980484
  - 42.1173751950264
  - 21.091988891363144
  - 26.400567203760147
  - 21.962878048419952
  - 22.127527862787247
  - 20.646778911352158
  - 21.691030979156494
  - 21.30334486067295
  - 21.94365745782852
  - 18.22229553759098
  - 18.231557101011276
  - 23.64705666899681
  - 19.41828516125679
  - 26.7217039167881
  - 19.165211528539658
  - 19.4769504070282
  - 20.880477726459503
  - 19.266702264547348
  - 19.01121275126934
  - 20.326517641544342
  - 17.883519649505615
  - 20.034066796302795
  - 19.585082679986954
  - 18.934420257806778
  - 19.715884566307068
  - 34.15498968958855
  - 30.034739434719086
  - 58.825664818286896
  - 245.62622982263565
  - 701.8965436220169
  - 114.28615418076515
  - 256.2001339495182
  - 171.26236620545387
  validation_losses:
  - 4.556554317474365
  - 0.5501770377159119
  - 0.689443826675415
  - 0.6735973358154297
  - 0.6938402652740479
  - 0.978218138217926
  - 0.4040261507034302
  - 0.7379377484321594
  - 0.5096349716186523
  - 0.4797515273094177
  - 0.47702115774154663
  - 0.5016209483146667
  - 0.4555850625038147
  - 0.8212766051292419
  - 0.6406466960906982
  - 0.6910266280174255
  - 16.800996780395508
  - 1.016843557357788
  - 1.568744421005249
  - 0.586331844329834
  - 0.5189821720123291
  - 0.49193206429481506
  - 0.40881848335266113
  - 25.519550323486328
  - 3399.802001953125
  - 30.518653869628906
  - 19.091787338256836
  - 0.4648972153663635
  - 1.3298461437225342
  - 0.49994415044784546
  - 10768.328125
  - 1118.572021484375
  - 1758.782470703125
  - 2166.42578125
  - 0.6135653853416443
  - 1.0164306163787842
  - 0.6322733759880066
  - 0.4774809777736664
  - 0.9872766733169556
  - 0.5093765258789062
  - 0.9346913695335388
  - 0.6668716073036194
  - 0.5624197125434875
  - 0.5086248517036438
  - 0.6414974331855774
  - 0.4061555862426758
  - 0.4285876154899597
  - 0.5211453437805176
  - 0.5876885056495667
  - 0.6192271709442139
  - 0.4578303098678589
  - 0.6419672966003418
  - 0.5351489186286926
  - 0.448586642742157
  - 0.6219209432601929
  - 0.5520163178443909
  - 0.5043022036552429
  - 0.5729376673698425
  - 0.4612615704536438
  - 0.655001699924469
  - 1.1302868127822876
  - 1.1026020050048828
  - 0.4458572268486023
  - 0.5668365359306335
  - 0.5516186356544495
  - 0.595648467540741
  - 1.5226130485534668
  - 0.6683961153030396
  - 0.9382012486457825
  - 0.404147744178772
  - 0.6009669899940491
  - 1.0513179302215576
  - 0.6945080161094666
  - 0.4434988796710968
  - 3530998.75
  - 33561472.0
  - 2972025856.0
  - 1582336512.0
  - 1183898752.0
  - 1516478592.0
  - 2286917120.0
  - 7896515584.0
  - 8031630336.0
  - 11594458112.0
  - 11344852992.0
  - 12308578304.0
  - 11955176448.0
  - 11505765376.0
  - 12452726784.0
  - 11088121856.0
  - 10428168192.0
  - 10337569792.0
  - 0.4091443717479706
  - 0.4845012128353119
  - 47.304649353027344
  - 1148.96826171875
  - 1.1976633071899414
  - 0.5386906266212463
  - 0.655554473400116
  - 1.031718373298645
loss_records_fold1:
  train_losses:
  - 58.00220453739166
  - 61.62768638134003
  - 30.693605333566666
  - 751.7903538048267
  - 85.23901283740997
  - 146.69929146766663
  - 40.927962243556976
  - 246.86058980226517
  - 33.04201227426529
  - 36.40805462002754
  - 45.36962413787842
  - 37.526903599500656
  - 74.83399575948715
  - 31.60755404829979
  - 37.99586018919945
  - 20.903772115707397
  - 22.61625102162361
  - 21.92444109916687
  - 19.483649909496307
  - 29.053446397185326
  - 22.33824671804905
  - 21.536754220724106
  - 18.20546865463257
  - 23.74902194738388
  - 24.262589514255524
  - 18.892014265060425
  - 24.84661766886711
  - 29.219538271427155
  - 27.34347230195999
  - 19.019240885972977
  - 28.96312975883484
  - 19.56611779332161
  - 23.053324103355408
  - 30.58925774693489
  - 251.689457654953
  - 159.3113396167755
  - 35.641804188489914
  - 308.7474523335695
  - 168.05881097912788
  - 202.49603712558746
  - 110.36139589548111
  - 286.6328181773424
  - 176.03963768482208
  - 49.61343893408775
  - 24.291632801294327
  - 24.414209634065628
  - 24.39653977751732
  - 18.561615616083145
  - 42.40677160024643
  - 36.40466171503067
  - 29.113452792167664
  - 23.211487501859665
  - 23.697747737169266
  - 22.537967652082443
  - 27.379604309797287
  - 51.65433353185654
  - 55.33912843465805
  - 23.815379112958908
  - 51.613788574934006
  - 20.816262751817703
  - 35.142958998680115
  - 36.0930744856596
  - 48.87780028581619
  - 51.264610558748245
  - 48.91470165550709
  - 29.050725609064102
  - 20.64974719285965
  - 21.80587202310562
  - 21.86398085951805
  - 21.859648823738098
  - 27.050327211618423
  - 22.666866704821587
  - 28.436403796076775
  - 21.228534549474716
  - 22.7307630777359
  - 32.359400779008865
  - 18.81701870262623
  - 19.514487326145172
  - 24.529092758893967
  - 60.13770027458668
  - 164.27761468291283
  - 241.38404539227486
  - 52.19416685402393
  - 51.45778973400593
  - 107.16938251256943
  - 126.90042099356651
  - 57.85850927233696
  - 97.65942235291004
  - 32.81654945015907
  - 25.828136265277863
  - 30.550216555595398
  - 61.791712284088135
  - 42.270182490348816
  - 22.054682701826096
  - 46.00225129723549
  - 73.07259215414524
  - 42.82073751091957
  - 73.85232669115067
  - 21.185668468475342
  - 22.29376757144928
  validation_losses:
  - 0.9883425235748291
  - 0.42170289158821106
  - 742.7401733398438
  - 12.352375030517578
  - 0.9725232124328613
  - 349.29229736328125
  - 0.6796509027481079
  - 0.9111697673797607
  - 1.0767356157302856
  - 0.45875805616378784
  - 0.4985823929309845
  - 0.6686285138130188
  - 67.52842712402344
  - 0.6795728206634521
  - 1.1557193994522095
  - 0.7876721620559692
  - 0.4852598011493683
  - 0.528364896774292
  - 0.46188053488731384
  - 0.7738988995552063
  - 0.6383781433105469
  - 0.44728028774261475
  - 0.5611216425895691
  - 0.465615451335907
  - 0.5237156748771667
  - 0.7803924679756165
  - 0.6533170938491821
  - 0.4859136641025543
  - 0.43034684658050537
  - 0.4371982514858246
  - 0.4621836543083191
  - 0.7944093346595764
  - 0.44110924005508423
  - 0.5770847201347351
  - 2.479630708694458
  - 0.48446640372276306
  - 1.0257554054260254
  - 1.5662634372711182
  - 1.0958523750305176
  - 1.4919694662094116
  - 2.798333168029785
  - 1.3323423862457275
  - 1.3560197353363037
  - 0.5676625370979309
  - 0.5566907525062561
  - 0.7134816646575928
  - 0.44334933161735535
  - 0.4791010320186615
  - 0.8709133267402649
  - 71740208.0
  - 0.7331640720367432
  - 0.9233622550964355
  - 0.481304407119751
  - 0.882953941822052
  - 0.6253300309181213
  - 3200842.75
  - 0.46632981300354004
  - 0.4450535476207733
  - 0.478424072265625
  - 0.5929251909255981
  - 0.7180781364440918
  - 0.680915355682373
  - 0.4507940411567688
  - 0.6180490851402283
  - 8209918.5
  - 0.4356440305709839
  - 0.5823270082473755
  - 0.8122367262840271
  - 0.9330791234970093
  - 0.4692181348800659
  - 0.785946249961853
  - 0.8170036673545837
  - 8132.08349609375
  - 1.0871453285217285
  - 0.4243638515472412
  - 0.7130604982376099
  - 0.6159886121749878
  - 0.7273274660110474
  - 0.49505814909935
  - 1376558.25
  - 1.1800403594970703
  - 0.8234683871269226
  - 0.41254183650016785
  - 0.9891036152839661
  - 1.2727108001708984
  - 1.4744011163711548
  - 1.7806116342544556
  - 0.7499972581863403
  - 0.6595579385757446
  - 0.4911770224571228
  - 0.46768227219581604
  - 0.659321129322052
  - 0.5113141536712646
  - 0.6002974510192871
  - 0.4918108284473419
  - 1.1643002033233643
  - 0.6302332282066345
  - 0.606509804725647
  - 0.9542797803878784
  - 0.629910409450531
loss_records_fold2:
  train_losses:
  - 22.004489362239838
  - 19.117495715618134
  - 19.69887238740921
  - 19.223793387413025
  - 27.357054591178894
  - 20.94526019692421
  - 18.61425232887268
  - 18.969472274184227
  - 19.19507271051407
  - 21.973344951868057
  - 33.07207578420639
  - 24.661017686128616
  - 20.27919378876686
  - 22.13360807299614
  - 26.96073517203331
  - 28.24446028470993
  - 32.4589926302433
  - 24.245533049106598
  - 19.058462977409363
  - 20.39792424440384
  - 19.89096535742283
  - 24.87274107336998
  - 27.343493163585663
  - 41.64419549703598
  - 22.830865621566772
  - 21.354209423065186
  - 20.013655215501785
  - 27.19899097084999
  - 26.77250376343727
  - 22.418846055865288
  - 23.26709857583046
  - 19.522732347249985
  - 18.42846192419529
  - 24.53196480870247
  - 18.721448630094528
  - 20.503740340471268
  - 18.92636314034462
  - 21.374718487262726
  - 26.48192723095417
  - 23.485812693834305
  - 22.99745273590088
  - 20.393762469291687
  - 21.669034153223038
  - 21.788059562444687
  - 18.780391693115234
  - 18.65610219538212
  - 22.586279824376106
  - 20.869707375764847
  - 19.23030561208725
  - 21.354859083890915
  - 33.52282965183258
  - 33.58583292365074
  - 33.212428867816925
  - 24.15731145441532
  - 23.01209157705307
  - 24.535297453403473
  - 21.088594049215317
  - 20.80807590484619
  - 19.435593456029892
  - 21.815383315086365
  - 20.926157757639885
  - 36.57037064433098
  - 27.76941230893135
  - 29.32363212108612
  - 23.10313904285431
  - 18.361404582858086
  - 24.21399064362049
  - 23.523805171251297
  - 22.448478892445564
  - 22.792504727840424
  - 17.384496957063675
  - 21.308366656303406
  - 23.59719893336296
  - 22.03900319337845
  - 21.432737410068512
  - 22.240803211927414
  - 21.055760145187378
  - 23.83867222070694
  - 26.902852058410645
  - 20.127401918172836
  - 27.883009284734726
  - 31.17532627284527
  - 25.06344074010849
  - 31.37205347418785
  - 38.37244749069214
  - 30.71367421746254
  - 21.84136101603508
  - 24.391320914030075
  - 20.780843555927277
  - 19.551795482635498
  - 24.282417863607407
  - 21.337918400764465
  - 19.909494429826736
  - 18.135285913944244
  - 20.58106890320778
  - 24.737689077854156
  - 24.136821389198303
  - 21.42414218187332
  - 24.718725621700287
  - 23.27985969185829
  validation_losses:
  - 0.42138412594795227
  - 6.589393155911166e+22
  - 1.8384161188596483e+25
  - 9.392188568166833e+23
  - 1.509509173227451e+24
  - 1.0237927108238113e+24
  - 0.48491165041923523
  - 0.5145598649978638
  - 0.9667786955833435
  - 7.006982901139635e+21
  - 8.897229278175949e+23
  - 9.237852010376697e+23
  - 9.651894945718631e+23
  - 3.3151779402545473e+24
  - 8.565218149038673e+23
  - 8.625813541592987e+23
  - 1.099442447982124e+24
  - 8.071803053288021e+23
  - 7.591647995992228e+23
  - 1.1342701169660697e+24
  - 1.0373579852470154e+24
  - 8.930514842589889e+23
  - 9.377690580246402e+23
  - 8.04824454349326e+23
  - 1.2069709691459742e+24
  - 8.198574699054888e+23
  - 1.0347266580855324e+24
  - 8.816131338390022e+23
  - 8.852385675678325e+23
  - 1.0723281841519682e+24
  - 1.0673490044039474e+24
  - 1.0706247426289116e+24
  - 8.999643295430175e+23
  - 0.4898454546928406
  - 0.407340407371521
  - 0.5288628339767456
  - 6.137002970462097e+22
  - 3.2149778205195424e+23
  - 2.2442189224468938e+24
  - 2.603820183765352e+24
  - 2.741935568331234e+24
  - 2.4418182832366493e+24
  - 2.724460737085908e+24
  - 7.298137469933718e+25
  - 1.535045992561181e+26
  - 2.9026718492782543e+24
  - 4.7666910573997175e+26
  - 2.6217218841977586e+24
  - 2.6120399376324465e+24
  - 2.6442482410155195e+24
  - 2.742842052864231e+24
  - 2.847926812783879e+24
  - 2.1745256187738556e+26
  - 1.4049915584543492e+26
  - 1.3901383323599186e+26
  - 8.936349000102688e+25
  - 1.1389589795500155e+26
  - 5.490747898385706e+26
  - 2.9249027699604597e+24
  - 7.024422006590125e+26
  - 1.2184058780952696e+26
  - 4.387560291541106e+26
  - 2.256262772829581e+26
  - 2.335967118746814e+24
  - 2.2527741764718289e+24
  - 2.480006502233742e+24
  - 4.4532568948200964e+26
  - 2.4047289425486351e+24
  - 8.762384950973722e+26
  - 2.2795931482816172e+24
  - 2.509687889909093e+24
  - 2.544793773263619e+24
  - 2.3229960312440465e+24
  - 0.5859416127204895
  - 0.4903769791126251
  - 0.5334597229957581
  - 1.652330927490326e+24
  - 3.677523803272316e+23
  - 8.790315984749994e+23
  - 9.762163240722992e+23
  - 1.2813393781671045e+24
  - 7.244085396909687e+23
  - 8.386945499661018e+23
  - 8.924220611750676e+23
  - 8.658679010233686e+23
  - 8.132487076683002e+23
  - 8.592403317541362e+23
  - 1.273577622367715e+24
  - 8.97843098089729e+23
  - 9.269614997828616e+23
  - 9.776651861156198e+23
  - 8.319404475617387e+23
  - 9.893993329591321e+23
  - 9.026007007360832e+23
  - 1.0437395498902024e+24
  - 1.2159175679641293e+24
  - 8.623983278704424e+23
  - 9.776628802726106e+23
  - 9.83648272263777e+23
  - 8.248017017204012e+23
loss_records_fold4:
  train_losses:
  - 24.308924853801727
  - 20.93638077378273
  - 22.783896297216415
  - 16.922534614801407
  - 21.278919890522957
  - 26.662059992551804
  - 19.166730418801308
  - 21.637658268213272
  - 31.000115394592285
  - 27.540096566081047
  - 21.716093361377716
  - 17.935763895511627
  - 26.648756116628647
  - 29.14947134256363
  - 22.037985920906067
  - 19.174961522221565
  - 22.0648984760046
  - 22.755734264850616
  - 20.658513486385345
  - 23.641250878572464
  - 22.61454278230667
  - 24.170527070760727
  - 23.57918357849121
  - 17.750666201114655
  - 22.340446650981903
  - 17.681077420711517
  - 20.731982588768005
  - 33.997254848480225
  - 23.695556968450546
  - 31.642813831567764
  - 18.142852514982224
  - 21.186641454696655
  - 23.3202363550663
  - 22.97984939813614
  - 25.147872880101204
  - 31.653135776519775
  - 23.395471662282944
  - 19.34477698802948
  - 32.26409977674484
  - 23.52646306157112
  - 21.61654195189476
  - 18.439575135707855
  - 20.66885420680046
  - 37.80782109498978
  - 27.505887806415558
  - 28.83900658786297
  - 34.524842381477356
  - 22.305059641599655
  - 19.880983769893646
  - 19.482328921556473
  - 19.313115000724792
  - 25.545867919921875
  - 18.448618859052658
  - 18.37217003107071
  - 17.599287509918213
  - 18.22055411338806
  - 22.813379108905792
  - 20.634379506111145
  - 26.347742676734924
  - 18.18855792284012
  - 37.21686473488808
  - 28.51022082567215
  - 20.22820356488228
  - 18.408118695020676
  - 20.77831655740738
  - 19.33605122566223
  - 23.292850345373154
  - 42.85461865365505
  - 26.784401327371597
  - 18.888151705265045
  - 21.095230124890804
  - 18.772464126348495
  - 19.067006438970566
  - 24.227797150611877
  - 20.95809632539749
  - 28.233034044504166
  - 25.014931589365005
  - 21.866881996393204
  - 19.457808673381805
  - 28.95288273692131
  - 20.436130613088608
  - 19.60465106368065
  - 19.856936246156693
  - 20.79538357257843
  - 22.415524780750275
  - 17.983501613140106
  - 19.16951671242714
  - 29.094822704792023
  - 18.775429353117943
  - 20.350202322006226
  - 19.480094850063324
  - 24.114515036344528
  - 22.18915969133377
  - 18.560870558023453
  - 35.836146235466
  - 28.926609337329865
  - 26.048885345458984
  - 24.65232890844345
  - 26.728693038225174
  - 27.037498950958252
  validation_losses:
  - 0.5254984498023987
  - 0.6364320516586304
  - 0.4478198289871216
  - 8.245193800669606e+23
  - 1.4409995510047625e+24
  - 6.581854490422918e+23
  - 6.960629556938928e+23
  - 8.775813673373921e+23
  - 7.875135541304364e+23
  - 6.20863290267941e+23
  - 7.818128616933138e+23
  - 8.755610165157567e+23
  - 9.825694259658412e+23
  - 6.094492232571452e+23
  - 9.093238183750099e+23
  - 6.627064866074194e+23
  - 6.225935372159797e+23
  - 7.120365390250326e+23
  - 7.451464270247082e+23
  - 7.094517610692981e+23
  - 9.265200029041912e+23
  - 9.238570424589256e+23
  - 7.89251295068255e+23
  - 6.446202466766816e+23
  - 6.895949219378603e+23
  - 9.216138174989308e+23
  - 6.824301633050751e+23
  - 6.792573953819911e+23
  - 5.831273407598275e+23
  - 6.989670208488094e+23
  - 5.998601229017509e+23
  - 7.744544122477546e+23
  - 7.954835563765954e+23
  - 2.3596613850487416e+24
  - 6.976342435894839e+23
  - 8.270987537031423e+23
  - 7.858501766296648e+23
  - 1.2608670951249888e+24
  - 6.446207510798399e+23
  - 0.44242045283317566
  - 0.4066079258918762
  - 0.5019733905792236
  - 1.2316283032066173e+23
  - 1.3314463555636346e+23
  - 5.552121928007372e+23
  - 6.707998514545714e+23
  - 1.3480125405481423e+24
  - 1240734720.0
  - 1318492288.0
  - 1656418432.0
  - 8.539480617600206e+23
  - 9.891931761825896e+23
  - 5.788534967710469e+23
  - 5.517495371768386e+23
  - 0.5533977746963501
  - 0.5717400312423706
  - 0.5170992016792297
  - 45106384.0
  - 723865088.0
  - 1048249344.0
  - 3.31038423675358e+23
  - 1.2219107421754519e+24
  - 1.6643994215701744e+24
  - 6.372321095023788e+23
  - 6.206959004769909e+23
  - 7.584985550847482e+23
  - 8.222475482421328e+23
  - 6.361522543981265e+23
  - 6.219855152374877e+23
  - 6.624546453162569e+23
  - 8.47107634358e+23
  - 7.702499236932356e+23
  - 6.641519619438203e+23
  - 6.106924329270815e+23
  - 1.1895068024245659e+24
  - 7.695146480036725e+23
  - 6.840774719623762e+23
  - 6.464288202294396e+23
  - 7.860216737034751e+23
  - 6.935508838505426e+23
  - 1.9596888478642177e+24
  - 7.352975950716042e+23
  - 6.949887931395694e+23
  - 8.17296831243757e+23
  - 7.725870396982617e+23
  - 6.739769428332977e+23
  - 9.382041417774412e+23
  - 8.59196376621773e+23
  - 6.392247902079037e+23
  - 7.339150980723925e+23
  - 5.892351586032644e+23
  - 5.936295909756674e+23
  - 9.788599730823627e+23
  - 6.598364326368888e+23
  - 5.725263356113586e+23
  - 8.239340562305905e+23
  - 6.178183525166803e+23
  - 7.475953043580872e+23
  - 6.891264034614257e+23
  - 7.827848465792914e+23
training fold messages:
  fold 0 training message: completed 100 epochs without stopping early
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: completed 100 epochs without stopping early
  fold 3 training message: stopped training due to stagnating improvement on validation
    loss after 57 epochs
  fold 4 training message: completed 100 epochs without stopping early
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.758147512864494, 0.8593481989708405, 0.8593481989708405,
    0.8591065292096219]'
  fold_eval_f1: '[0.0, 0.053691275167785234, 0.0, 0.0, 0.0]'
  mean_eval_accuracy: 0.8387166746240856
  mean_f1_accuracy: 0.010738255033557046
  total_train_time: '0:12:33.401663'
