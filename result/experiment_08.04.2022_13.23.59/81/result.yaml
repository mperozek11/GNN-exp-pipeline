config:
  aggregation: sum
  batch_size: 32
  class_weights: false
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.0
  epochs: 100
  hidden_units:
  - 32
  - 32
  - 32
  - 32
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.1
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: true
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-04 22:00:22.422957'
fold_0_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/81/fold_0_optim_dict.pt
fold_0_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/81/fold_0_state_dict.pt
fold_1_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/81/fold_1_optim_dict.pt
fold_1_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/81/fold_1_state_dict.pt
fold_2_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/81/fold_2_optim_dict.pt
fold_2_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/81/fold_2_state_dict.pt
fold_3_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/81/fold_3_optim_dict.pt
fold_3_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/81/fold_3_state_dict.pt
fold_4_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/81/fold_4_optim_dict.pt
fold_4_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/81/fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 878.6614010483027
  - 130.2111665531993
  - 61.453453958034515
  - 44.88811093568802
  - 46.31086242944002
  - 63.90424844622612
  - 63.49288336932659
  - 52.30889297276735
  - 83.35316516458988
  - 34.449446419253945
  - 34.61992645263672
  - 37.646185860037804
  - 35.24103853106499
  - 39.33304513990879
  - 40.3011549860239
  - 45.454996928572655
  - 42.94198788702488
  - 36.29518362879753
  - 35.253099367022514
  - 50.67124120891094
  - 43.73095544800162
  - 36.32805635035038
  - 41.83952496945858
  - 40.57574035972357
  - 37.244742035865784
  - 47.37853494659066
  - 39.91410377621651
  - 43.48218826204538
  - 34.35550360381603
  - 38.593448888510466
  - 43.95498610287905
  - 55.563524678349495
  - 33.29246450960636
  - 36.19697315990925
  - 63.71061760187149
  - 48.72556760907173
  - 39.2787701189518
  - 32.59926348924637
  - 38.2413644194603
  - 35.43843910098076
  - 44.442809507250786
  - 38.03872521221638
  - 33.04525043070316
  - 36.189848229289055
  - 42.91672495007515
  - 43.12320455908775
  - 38.008602142333984
  - 35.76880967617035
  - 47.53529991209507
  - 52.17918732017279
  - 43.90966275520623
  - 36.03497536480427
  - 44.6062245965004
  - 33.87309265136719
  - 36.31461991369724
  - 35.14926053583622
  - 37.401986584067345
  - 43.53463737666607
  - 36.29064418375492
  - 37.94477862119675
  - 43.09965631365776
  - 45.52016365528107
  - 43.70166903734207
  - 38.492804154753685
  - 38.84571370482445
  - 52.03598319739103
  - 33.75102823972702
  - 40.41978990286589
  - 37.41412802040577
  - 35.48570568859577
  - 42.61261883378029
  - 35.26921807229519
  - 34.36799514293671
  - 37.31270601833239
  - 42.54106851667166
  - 40.48423475027084
  - 35.40646293759346
  - 39.30511227250099
  - 33.79911486804485
  - 42.719873905181885
  - 33.54751379787922
  - 34.64212705940008
  - 33.75704048573971
  - 46.362239092588425
  - 34.94119302928448
  - 43.12934774905443
  - 33.019235752522945
  - 35.880891010165215
  - 37.56694905459881
  - 35.818580374121666
  - 36.124756813049316
  - 52.07646334171295
  - 49.85521434247494
  - 37.48244156688452
  - 33.350712686777115
  - 38.83728523552418
  - 45.73304809629917
  - 44.69477204978466
  - 34.398104920983315
  - 44.513843432068825
  validation_losses:
  - 1.0971481800079346
  - 1.1884212493896484
  - 0.4401416480541229
  - 0.6567397713661194
  - 0.39843103289604187
  - 0.4638979732990265
  - 0.40307319164276123
  - 2.518841028213501
  - 0.3924892246723175
  - 9755561872588800.0
  - 0.8623883724212646
  - 0.4354538917541504
  - 0.4146749675273895
  - 0.9095934629440308
  - 0.40571027994155884
  - 1.0124738216400146
  - 215466245095424.0
  - 1443681852719104.0
  - 4.020620453172216e+18
  - 5.00544078610432e+17
  - 0.6980483531951904
  - 0.41502928733825684
  - 0.5619693398475647
  - 0.5616649985313416
  - 0.808185875415802
  - 0.6959426403045654
  - 0.9310958385467529
  - 0.46411949396133423
  - 0.43699514865875244
  - 0.3962242305278778
  - 0.9632139205932617
  - 0.4043607711791992
  - 0.43700337409973145
  - 0.39647114276885986
  - 0.7477322220802307
  - 1.127568006515503
  - 0.3954455852508545
  - 0.46767911314964294
  - 0.4081558585166931
  - 1544208917725184.0
  - 0.5701744556427002
  - 0.5777995586395264
  - 0.4936675429344177
  - 0.40011224150657654
  - 0.9658787846565247
  - 0.4863240420818329
  - 0.39811787009239197
  - 1.1342754364013672
  - 0.3934072256088257
  - 0.8338119387626648
  - 0.39905309677124023
  - 0.4121614992618561
  - 0.39340391755104065
  - 0.5654445886611938
  - 1.0352320671081543
  - 0.40536975860595703
  - 0.4008673429489136
  - 1.005083441734314
  - 0.44481778144836426
  - 0.8382206559181213
  - 1.0112913846969604
  - 0.5441927909851074
  - 0.3977871537208557
  - 0.7338191866874695
  - 0.5593788027763367
  - 0.41200634837150574
  - 1.0984050035476685
  - 0.39918026328086853
  - 0.4055738151073456
  - 0.8252035975456238
  - 0.410364031791687
  - 0.522373616695404
  - 0.4030269384384155
  - 0.9650669693946838
  - 0.39610791206359863
  - 0.7893867492675781
  - 0.6769386529922485
  - 0.8115447759628296
  - 0.44099801778793335
  - 0.4055187404155731
  - 0.40622779726982117
  - 0.40211910009384155
  - 0.42835694551467896
  - 0.41089507937431335
  - 0.6743057370185852
  - 0.43954527378082275
  - 0.4555688202381134
  - 0.4691910743713379
  - 0.3967014253139496
  - 0.5452073812484741
  - 0.4242546558380127
  - 1.4734703302383423
  - 0.45373913645744324
  - 0.40739625692367554
  - 0.3914768397808075
  - 0.3964088559150696
  - 0.7036701440811157
  - 0.39791128039360046
  - 0.4813093841075897
  - 0.4197496175765991
loss_records_fold1:
  train_losses:
  - 34.7735865265131
  - 35.43194201588631
  - 30.933237954974174
  - 33.98721231520176
  - 51.71557550691068
  - 35.27970924973488
  - 37.32328339666128
  - 45.14010538160801
  - 35.951698273420334
  - 33.95761699974537
  - 32.52881072834134
  - 45.27181515842676
  - 42.2543543279171
  - 40.41403050720692
  - 34.43894408643246
  - 43.46649906039238
  - 34.28497180342674
  - 40.702951684594154
  - 38.495884366333485
  - 42.12301517650485
  - 40.60085400938988
  - 34.2609710842371
  - 37.09235402569175
  - 38.51322007924318
  - 43.13142587244511
  - 42.70525985956192
  - 30.432290628552437
  - 39.28074814379215
  - 51.00463651865721
  - 43.28275080025196
  - 34.98567283153534
  - 34.42412742972374
  - 37.37894469127059
  - 34.74345974624157
  - 34.70896327495575
  - 51.58638495206833
  - 42.75189170986414
  - 34.22101689875126
  - 45.457662388682365
  - 35.17224742472172
  - 37.90679058432579
  - 48.11161631345749
  - 47.07748091220856
  - 33.05979195982218
  - 38.56827073544264
  - 39.846322387456894
  - 55.15843651816249
  - 34.259667202830315
  - 45.53597778081894
  - 42.38881476223469
  - 35.37622168660164
  - 47.67744353413582
  - 45.09630662202835
  - 37.923301227390766
  - 46.091155007481575
  - 45.70429016649723
  - 35.9723629206419
  - 43.56805291771889
  - 34.18114010244608
  - 33.1879964992404
  - 34.639686182141304
  - 49.62817332148552
  - 48.23055513203144
  - 33.68940408527851
  - 43.60037548840046
  - 32.78663744032383
  - 38.31345908343792
  - 31.792508229613304
  - 38.498187720775604
  - 48.77172827720642
  - 33.42057826370001
  - 40.56253791600466
  - 37.51446743309498
  - 48.23719245940447
  - 33.4395497739315
  - 33.569937869906425
  - 39.27951109409332
  - 33.47165744006634
  - 35.26987185329199
  - 45.54308684542775
  - 34.19662199169397
  - 37.12459187954664
  - 35.867189571261406
  - 38.07665674388409
  - 36.522973239421844
  - 33.63351646065712
  - 37.37282808125019
  - 36.123040691018105
  - 32.83794082701206
  - 39.840911865234375
  - 34.094692930579185
  - 37.763908725231886
  - 35.03453476727009
  - 33.864742428064346
  - 44.15140846371651
  - 32.97403767704964
  - 38.93954884260893
  - 37.774802669882774
  - 49.383857786655426
  - 35.976645931601524
  validation_losses:
  - 0.58371901512146
  - 0.6655913591384888
  - 0.4042368233203888
  - 0.8686869740486145
  - 0.5790287256240845
  - 0.553154706954956
  - 0.40561985969543457
  - 0.5724455118179321
  - 0.4139254093170166
  - 0.4491327106952667
  - 0.6547945737838745
  - 0.7211654186248779
  - 1.4216201305389404
  - 0.41229143738746643
  - 0.6211395263671875
  - 0.6158729195594788
  - 0.40889376401901245
  - 0.4185487627983093
  - 0.42665353417396545
  - 0.783981442451477
  - 0.5218242406845093
  - 0.49699467420578003
  - 0.45495375990867615
  - 0.9072691202163696
  - 1.3016650676727295
  - 0.6528139114379883
  - 0.4255397915840149
  - 0.544696569442749
  - 0.4311351776123047
  - 0.8944571614265442
  - 0.44197043776512146
  - 0.6082236766815186
  - 0.6805670261383057
  - 0.4268084764480591
  - 0.8615131378173828
  - 0.8993198871612549
  - 0.4518148899078369
  - 0.4857955276966095
  - 0.4395890235900879
  - 0.5982264280319214
  - 0.8640839457511902
  - 0.4796046316623688
  - 0.5894851088523865
  - 0.7443829774856567
  - 0.6024425625801086
  - 1.314713478088379
  - 0.6715959310531616
  - 0.6990538835525513
  - 0.8770244717597961
  - 0.4126693308353424
  - 1.6655633449554443
  - 0.4177943170070648
  - 0.4329772889614105
  - 0.4203772246837616
  - 0.436862051486969
  - 0.4288976788520813
  - 0.9451717138290405
  - 0.5782948136329651
  - 0.5451721549034119
  - 0.4423898458480835
  - 0.8278549313545227
  - 0.5253840088844299
  - 0.5013766288757324
  - 0.7369311451911926
  - 0.41478776931762695
  - 0.41156020760536194
  - 0.507334291934967
  - 0.44553419947624207
  - 0.4409010708332062
  - 0.8530638217926025
  - 0.533078670501709
  - 0.4666884243488312
  - 0.6721166968345642
  - 0.6194156408309937
  - 0.40825995802879333
  - 0.6330401301383972
  - 0.6713581085205078
  - 0.41005977988243103
  - 0.699984610080719
  - 0.4239393174648285
  - 0.528336763381958
  - 0.8243943452835083
  - 0.4069949984550476
  - 0.782812774181366
  - 0.46532467007637024
  - 0.41799843311309814
  - 1.0105336904525757
  - 0.5190601348876953
  - 0.47141575813293457
  - 0.4490586817264557
  - 0.45040711760520935
  - 0.40944766998291016
  - 0.47462546825408936
  - 0.4680790305137634
  - 0.41401034593582153
  - 0.4228227436542511
  - 0.5957653522491455
  - 2.3695130348205566
  - 0.4232638478279114
  - 0.40752148628234863
loss_records_fold3:
  train_losses:
  - 49.28636360913515
  - 31.23694133758545
  - 37.99873377382755
  - 43.16230135411024
  - 33.36655484139919
  - 37.07647880911827
  - 3098.9640736728907
  - 3792.1229759454727
  - 933.7396962493658
  - 468.6753738671541
  - 394.83780892938375
  - 246.51931599527597
  - 152.55966651439667
  - 169.66712975502014
  - 155.64714097976685
  - 141.57396733760834
  - 160.30289898766205
  - 122.79856403172016
  - 55.63699831068516
  - 63.11458441615105
  - 57.51366663724184
  - 52.93125993013382
  - 46.78846809267998
  - 60.31194490194321
  - 70.69028401374817
  - 41.35987523198128
  - 50.03403429687023
  - 67.47015421837568
  - 224.0785747617483
  - 180.2592289596796
  - 61.74865326285362
  - 68.08892425894737
  - 54.437304332852364
  - 60.498126700520515
  - 136.20519221574068
  - 66.12067022919655
  - 56.56727609038353
  - 42.28468559682369
  - 44.16575047373772
  - 47.2697528898716
  - 39.596854746341705
  - 218.5743741840124
  - 47.660796105861664
  - 117.82684490829706
  - 58.07840648293495
  - 53.263220101594925
  - 56.76004792749882
  - 40.65304486453533
  - 34.62290635704994
  - 36.80572567880154
  - 50.093472987413406
  - 47.00356903672218
  - 42.881680339574814
  - 47.18824936449528
  - 33.89646189659834
  - 31.435618311166763
  - 33.7736057639122
  - 33.38960163295269
  - 42.63431241363287
  - 44.22660247422755
  - 35.980069410055876
  - 37.729437507689
  - 39.75768856704235
  - 37.17411333322525
  - 37.23674041032791
  - 33.52158861607313
  - 33.135299518704414
  - 46.29617938399315
  - 43.78033249080181
  - 39.96327071636915
  - 42.820496536791325
  - 33.96221159398556
  - 58.46454229950905
  - 41.6405790373683
  - 36.5523956567049
  - 44.95685984194279
  - 42.948161490261555
  - 45.37950652837753
  - 36.21746112406254
  - 31.378975674510002
  - 35.63297180831432
  - 46.68162685632706
  - 34.249987453222275
  - 32.99748505651951
  - 33.57880611717701
  - 43.00407572090626
  - 34.54930618405342
  - 32.56611531972885
  - 38.49312261864543
  - 38.619855016469955
  - 38.30038796365261
  - 51.23076090216637
  - 39.84405133500695
  - 48.650614915415645
  - 34.33101047575474
  - 44.868713706731796
  - 37.17665050923824
  - 41.23730982840061
  - 33.76636083424091
  - 37.2865846902132
  validation_losses:
  - 0.5790473818778992
  - 0.42363449931144714
  - 0.4394213557243347
  - 0.4081745147705078
  - 0.6382545828819275
  - 0.6289600729942322
  - 28186.205078125
  - 2.259800910949707
  - 1.0649369955062866
  - 992.6035766601562
  - 1.2266663312911987
  - 5.777292251586914
  - 0.4079364240169525
  - 0.8627098798751831
  - 0.5045708417892456
  - 1.3384339809417725
  - 1.2479867935180664
  - 0.5339924693107605
  - 0.524791419506073
  - 0.394721120595932
  - 0.5527044534683228
  - 0.39230266213417053
  - 0.3975677192211151
  - 0.48347964882850647
  - 0.6252905130386353
  - 0.6043519377708435
  - 0.4600661098957062
  - 0.47802484035491943
  - 0.6047552824020386
  - 0.6117387413978577
  - 0.5223984718322754
  - 0.7470343112945557
  - 0.5815224647521973
  - 0.4471334218978882
  - 0.43036726117134094
  - 110126728.0
  - 71246792.0
  - 43585340.0
  - 732513920.0
  - 5983978.5
  - 483533.84375
  - 0.4035704731941223
  - 0.8588234186172485
  - 0.4810370206832886
  - 0.6781350374221802
  - 0.9658467173576355
  - 0.5141799449920654
  - 68739437428736.0
  - 0.43844473361968994
  - 9.696965999700686e+19
  - 1.859920641347876e+26
  - 4.602391626425849e+25
  - 2.853264896996284e+26
  - 1.4718206015874174e+24
  - 9.518564214219906e+25
  - 9.428313087788502e+19
  - 6.023821631926603e+25
  - 1.3898860731347107e+24
  - 8.467534222841397e+25
  - 2.0545958185024597e+25
  - 435271488.0
  - 2.0003320554848256e+17
  - 3.001610240541655e+23
  - 4.383316249132067e+25
  - 7.462829078686593e+25
  - 0.5068343877792358
  - 29839030272.0
  - 0.5100622177124023
  - 355868608561152.0
  - 9.538373610631429e+22
  - 1.057187730723095e+24
  - 2.313847022644239e+24
  - 7.240028542402665e+19
  - 0.8278971910476685
  - 0.4016002416610718
  - 4030379.0
  - 0.39700061082839966
  - 1.0056489829924864e+16
  - 2.5390093152808023e+20
  - 0.41339120268821716
  - 1.3137978315353394
  - 1.345495606092628e+18
  - 0.41069385409355164
  - 6211206381568.0
  - 3.0279566473907436e+21
  - 8.565874737835546e+24
  - 2.1146282106630373e+25
  - 7.082000197802276e+25
  - 9.034331648261808e+25
  - 4.1679116905360654e+19
  - 1.0839821020702787e+25
  - 4.468423438862619e+26
  - 5.35549452616286e+26
  - 3.3303705828032774e+19
  - 1.054820966114347e+20
  - 3.5416934191269413e+19
  - 1.9674852382446977e+19
  - 4.1769188897908064e+19
  - 1.1757913464645878e+20
  - 8.97382511859613e+19
loss_records_fold4:
  train_losses:
  - 36.47531911730766
  - 34.74099789559841
  - 1204.5965597182512
  - 304.6296884045005
  - 83.30170395970345
  - 51.75823302194476
  - 48.800698451697826
  - 56.77376349270344
  - 41.40982563048601
  - 51.9023227840662
  - 48.03626136854291
  - 40.06622979789972
  - 51.29762079194188
  - 42.493014082312584
  - 33.69925132393837
  - 34.640002213418484
  - 36.77282211184502
  - 82.18921269476414
  - 346.3190682679415
  - 354.9320859014988
  - 92.22015945613384
  - 38.07807321846485
  - 71.47392408549786
  - 36.38759829103947
  - 45.039105735719204
  - 35.031386986374855
  - 36.312167435884476
  - 33.107470855116844
  - 35.58891083300114
  - 42.80460776388645
  - 40.27920226752758
  - 36.40156735479832
  - 38.82618796825409
  - 81.9203674942255
  - 33.44930770993233
  - 37.16358470916748
  - 33.253251656889915
  - 37.05877907574177
  - 36.73888295888901
  - 51.022525653243065
  - 49.79581830650568
  - 35.97383734583855
  - 43.158177345991135
  - 50.04762638732791
  - 38.36420601606369
  - 35.295106545090675
  - 38.47190773487091
  - 33.13934503495693
  - 35.924836345016956
  - 33.505075231194496
  - 31.798119708895683
  - 52.178895354270935
  - 30.232271939516068
  - 45.577998861670494
  - 44.835450172424316
  - 64.13962726294994
  - 42.7345479875803
  - 36.39925301074982
  - 37.71208733320236
  - 41.11926760524511
  - 33.55912884324789
  - 35.64996662735939
  - 32.34600358456373
  - 38.53081953525543
  - 40.658744513988495
  - 35.3683051019907
  - 39.94215965270996
  - 33.390187084674835
  - 37.882047429680824
  - 36.80994150042534
  - 46.65540660172701
  - 42.345272712409496
  - 36.57822459936142
  - 35.927295967936516
  - 39.80808658152819
  - 40.822521328926086
  - 36.0511674284935
  - 41.04974949359894
  - 36.31434817612171
  - 39.295333340764046
  - 40.61697080731392
  - 34.02879633009434
  - 44.4528419226408
  - 48.42553102970123
  - 32.10820923745632
  - 49.807285621762276
  - 45.86616377532482
  - 40.64008675515652
  - 32.59648039191961
  - 40.585614293813705
  - 39.55454894900322
  - 43.5425194054842
  - 37.52670655399561
  - 47.35713028907776
  - 133.11816300451756
  - 684.5003314614296
  - 1603.7348669469357
  - 325.0905485600233
  - 418.3440670967102
  - 148.00848093628883
  validation_losses:
  - 3.8917695122552555e+27
  - 7.962417797358472e+19
  - 174.20040893554688
  - 0.5510545372962952
  - 0.45526355504989624
  - 1.433026671409607
  - 0.8500378131866455
  - 0.40566486120224
  - 0.445252001285553
  - 1.0850543975830078
  - 0.6970208287239075
  - 0.6704413890838623
  - 0.4988071024417877
  - 0.4363398849964142
  - 0.4397304654121399
  - 5.694019907323167e+17
  - 0.44994300603866577
  - 0.42628443241119385
  - 25.871671676635742
  - 1.0860261917114258
  - 0.43886998295783997
  - 0.45460179448127747
  - 0.4057466685771942
  - 0.6708024144172668
  - 0.4874107837677002
  - 5.211335934817075e+16
  - 1.0463963101102342e+19
  - 1.2458784438668493e+17
  - 8.12565893522391e+16
  - 1.3323058130662195e+17
  - 1.2345611191425434e+17
  - 1.5082837657832653e+17
  - 1.1212063665815552e+17
  - 1.1256641131380736e+17
  - 2.2422782147873997e+17
  - 1.1137932530286592e+17
  - 7.108584480230605e+16
  - 9.35739113120727e+16
  - 1.0774640144574054e+17
  - 3.672966696219443e+17
  - 8.910433641562112e+16
  - 1.100343734739927e+17
  - 1.7752209653917286e+17
  - 6.633646137645466e+16
  - 1.4642259912608973e+17
  - 1.7004854420648755e+17
  - 4.95838898987991e+16
  - 8.590915562530406e+16
  - 1.4509663964259942e+17
  - 1.5321170547048448e+17
  - 3.334802961564959e+17
  - 1.4846142010150093e+17
  - 4.330739219614925e+16
  - 4.366369838805811e+16
  - 2.689339728540467e+16
  - 6.854583979815731e+16
  - 1.320328781365248e+17
  - 3.1955494703097446e+17
  - 6.608915286458368e+16
  - 8.359164281199002e+16
  - 7.244638306749645e+16
  - 1.718247880612905e+17
  - 8.580623377780179e+18
  - 1.2080116929029734e+17
  - 1.0142944944612966e+17
  - 1.1271255187102106e+17
  - 1.8862976672989184e+16
  - 1.8357190157297254e+17
  - 8.666977715355648e+16
  - 1.4325000127381504e+17
  - 4.2078241275510784e+17
  - 3.841039503930163e+16
  - 1.4008009207106765e+17
  - 6.344819035917517e+16
  - 1.1612383823580365e+17
  - 9.270140588575949e+17
  - 4.544391079264256e+16
  - 6.679700212967014e+16
  - 2.373079038605394e+17
  - 2.0446495896292557e+17
  - 1.6378433440527155e+17
  - 1.282630736716759e+17
  - 3.864191525139251e+16
  - 2.0843989484540264e+19
  - 1.3541803392027853e+17
  - 3.253684429641482e+17
  - 4.089407584233062e+16
  - 9.693454283256627e+16
  - 6.251105855995904e+16
  - 2.335966999294771e+16
  - 1.0970092939300045e+17
  - 6.618849975310746e+16
  - 5.631519457332429e+16
  - 2.778278107419771e+17
  - 0.7516321539878845
  - 3.68094801902771
  - 0.7569873332977295
  - 2.104395866394043
  - 9.21757963780096e+16
  - 7.092788707207414e+17
training fold messages:
  fold 0 training message: completed 100 epochs without stopping early
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: stopped training due to stagnating improvement on validation
    loss after 40 epochs
  fold 3 training message: completed 100 epochs without stopping early
  fold 4 training message: completed 100 epochs without stopping early
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.8576329331046312, 0.8593481989708405, 0.14065180102915953,
    0.8591065292096219]'
  fold_eval_f1: '[0.0, 0.0, 0.0, 0.24661654135338348, 0.0]'
  mean_eval_accuracy: 0.7148744790837769
  mean_f1_accuracy: 0.0493233082706767
  total_train_time: '0:20:54.648107'
