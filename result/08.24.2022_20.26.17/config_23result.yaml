config:
  aggregation: mean
  batch_size: 256
  class_weights: true
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.5
  epochs: 100
  hidden_units:
  - 32
  - 32
  - 32
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.01
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: false
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-24 20:53:12.053751'
fold_0_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_23fold_0_optim_dict.pt
fold_0_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_23fold_0_state_dict.pt
fold_1_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_23fold_1_optim_dict.pt
fold_1_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_23fold_1_state_dict.pt
fold_2_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_23fold_2_optim_dict.pt
fold_2_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_23fold_2_state_dict.pt
fold_3_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_23fold_3_optim_dict.pt
fold_3_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_23fold_3_state_dict.pt
fold_4_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_23fold_4_optim_dict.pt
fold_4_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_23fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 1.0966505110263824
  - 0.8608744382858277
  - 0.8766737997531892
  - 0.863291871547699
  - 0.8684302568435669
  - 0.826169216632843
  - 0.8307690918445587
  - 0.8811976492404938
  - 0.8393181085586549
  - 0.7950208485126495
  - 0.807673716545105
  - 0.809036123752594
  - 0.8666939735412598
  - 0.8271171689033509
  - 0.8538914978504182
  - 0.8359192311763763
  - 0.7938059747219086
  - 0.8026895821094513
  - 0.8133556306362153
  - 0.7890161037445069
  - 0.8493224322795868
  - 0.8336232066154481
  - 0.8326813936233521
  - 0.8769170165061951
  - 0.9676769316196442
  - 0.8898249864578247
  validation_losses:
  - 0.4073851406574249
  - 0.42143306136131287
  - 0.39907214045524597
  - 0.4171455502510071
  - 0.4116959571838379
  - 0.4026442766189575
  - 0.38265666365623474
  - 0.38632071018218994
  - 0.3904356360435486
  - 0.3845001757144928
  - 0.39772215485572815
  - 0.3887900412082672
  - 0.3880607485771179
  - 0.4123817980289459
  - 0.396919846534729
  - 0.388557493686676
  - 0.39367571473121643
  - 0.38750478625297546
  - 0.38293638825416565
  - 0.3947125971317291
  - 0.3875034749507904
  - 0.3927077054977417
  - 0.3927726149559021
  - 0.38145744800567627
  - 0.3835642337799072
  - 0.3913077712059021
loss_records_fold1:
  train_losses:
  - 0.8325693905353546
  - 0.7846039652824403
  - 0.8335390090942383
  - 0.814305078983307
  - 0.8086390674114228
  - 0.7982686817646027
  - 0.8167022049427033
  - 0.8246986985206605
  - 0.8093013584613801
  - 0.7931237280368806
  - 0.8133489549160005
  validation_losses:
  - 0.39654678106307983
  - 0.39042696356773376
  - 0.40090927481651306
  - 0.39273154735565186
  - 0.39048057794570923
  - 0.3938749432563782
  - 0.39251062273979187
  - 0.3988862931728363
  - 0.3933047652244568
  - 0.3936672508716583
  - 0.39701783657073975
loss_records_fold2:
  train_losses:
  - 0.8369268774986267
  - 0.8366855323314667
  - 0.8125938832759858
  - 0.8152947068214417
  - 0.7925519347190857
  - 0.8324732184410095
  - 0.8192360162734986
  - 0.8235774099826814
  - 0.7933838963508606
  - 0.7948503375053406
  - 0.8142382740974426
  - 0.8435686439275742
  - 0.9018067300319672
  - 0.84840686917305
  - 0.8434372663497925
  - 0.8206056773662568
  - 0.7729704499244691
  validation_losses:
  - 0.3993419408798218
  - 0.3908930718898773
  - 0.38410651683807373
  - 0.3965372145175934
  - 0.3911924362182617
  - 0.39601096510887146
  - 0.40323570370674133
  - 0.4005550444126129
  - 0.3998412787914276
  - 0.39951780438423157
  - 0.628383219242096
  - 0.41298919916152954
  - 0.39422106742858887
  - 0.39120224118232727
  - 0.38922300934791565
  - 0.3948803246021271
  - 0.4011588394641876
loss_records_fold3:
  train_losses:
  - 0.8337959587574005
  - 0.8539270102977753
  - 0.8518730044364929
  - 0.8199738681316376
  - 0.8292786359786988
  - 0.8384648382663727
  - 0.7892586112022401
  - 0.7845056027173997
  - 0.8300486087799073
  - 0.8376569747924805
  - 0.8318782210350038
  - 0.8018109798431396
  - 0.8118316173553467
  - 0.8304833531379701
  - 0.8150750160217286
  - 0.8011868327856064
  - 0.8313918709754944
  - 0.7899372071027756
  - 0.8288448750972748
  - 0.7996487379074098
  - 0.7929398000240326
  - 0.8002455174922943
  - 0.8173058331012726
  - 0.8009347200393677
  validation_losses:
  - 0.3913217782974243
  - 0.39403092861175537
  - 0.37514030933380127
  - 0.3818046450614929
  - 0.3733629584312439
  - 0.3801102042198181
  - 0.381785124540329
  - 0.38468801975250244
  - 0.38543879985809326
  - 0.4019787013530731
  - 0.3885233700275421
  - 0.3749891221523285
  - 0.3717154562473297
  - 0.38849663734436035
  - 0.3727375864982605
  - 0.376455157995224
  - 0.38255858421325684
  - 0.39549949765205383
  - 0.38615384697914124
  - 0.38409674167633057
  - 0.3800281882286072
  - 0.3810855448246002
  - 0.383970707654953
  - 0.38788512349128723
loss_records_fold4:
  train_losses:
  - 0.8093226313591004
  - 0.8835245013237
  - 0.8273237168788911
  - 0.8209659576416016
  - 0.8028278708457948
  - 0.8456333696842194
  - 0.8120842695236207
  - 0.8107155919075013
  - 0.8000485718250275
  - 0.7823612779378891
  - 0.8400549232959748
  validation_losses:
  - 0.36995238065719604
  - 0.3910764455795288
  - 0.3945305347442627
  - 0.3889327645301819
  - 0.3961976170539856
  - 0.39979371428489685
  - 0.3946065306663513
  - 0.3803209960460663
  - 0.3859412670135498
  - 0.38264110684394836
  - 0.39230287075042725
training fold messages:
  fold 0 training message: stopped training due to stagnating improvement on validation
    loss after 26 epochs
  fold 1 training message: stopped training due to stagnating improvement on validation
    loss after 11 epochs
  fold 2 training message: stopped training due to stagnating improvement on validation
    loss after 17 epochs
  fold 3 training message: stopped training due to stagnating improvement on validation
    loss after 24 epochs
  fold 4 training message: stopped training due to stagnating improvement on validation
    loss after 11 epochs
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.8576329331046312, 0.8593481989708405, 0.8593481989708405,
    0.8591065292096219]'
  fold_eval_f1: '[0.0, 0.0, 0.0, 0.0, 0.0]'
  mean_eval_accuracy: 0.858613758672113
  mean_f1_accuracy: 0.0
  total_train_time: '0:07:20.987899'
