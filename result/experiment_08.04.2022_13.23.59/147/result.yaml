config:
  aggregation: sum
  batch_size: 64
  class_weights: false
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.0
  epochs: 100
  hidden_units:
  - 64
  - 64
  - 64
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.1
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: true
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-05 07:22:23.397944'
fold_0_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/147/fold_0_optim_dict.pt
fold_0_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/147/fold_0_state_dict.pt
fold_1_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/147/fold_1_optim_dict.pt
fold_1_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/147/fold_1_state_dict.pt
fold_2_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/147/fold_2_optim_dict.pt
fold_2_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/147/fold_2_state_dict.pt
fold_3_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/147/fold_3_optim_dict.pt
fold_3_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/147/fold_3_state_dict.pt
fold_4_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/147/fold_4_optim_dict.pt
fold_4_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/147/fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 883.0369861423969
  - 91.94133046269417
  - 129.0697274506092
  - 42.90889701247215
  - 31.9555025100708
  - 20.776752680540085
  - 21.186076030135155
  - 31.589216873049736
  - 20.32003116607666
  - 16.111705362796783
  - 19.836620956659317
  - 15.88585615158081
  - 18.66316646337509
  - 24.9355408847332
  - 17.080008283257484
  - 53.91209268569946
  - 44.289881125092506
  - 102.78557133674622
  - 52.80317208170891
  - 20.364831686019897
  - 56.91245794296265
  - 17.811302468180656
  - 16.50712278485298
  - 19.503010123968124
  - 18.655641973018646
  - 17.33472791314125
  - 22.692844063043594
  - 24.975147664546967
  - 17.967369690537453
  - 15.253180637955666
  - 15.945990085601807
  - 19.91288697719574
  - 20.287696480751038
  - 17.85619369149208
  - 20.076021149754524
  - 21.10762482881546
  - 22.172381296753883
  - 28.30680561065674
  - 20.87225443124771
  - 19.114449590444565
  - 22.773987382650375
  - 19.939565673470497
  - 15.894258424639702
  - 24.901037395000458
  - 18.384628921747208
  - 20.243978336453438
  - 16.70510822534561
  - 18.604469150304794
  - 15.691276133060455
  - 15.778321266174316
  - 16.708442479372025
  - 17.787040293216705
  - 15.897956788539886
  - 15.98134046792984
  - 16.355219572782516
  - 21.620927304029465
  - 16.58591729402542
  - 19.729550927877426
  - 18.79256008565426
  - 16.503758937120438
  - 17.660172060132027
  - 16.741637706756592
  - 16.22477427124977
  - 15.179000407457352
  - 20.68455669283867
  - 19.068438202142715
  - 16.024810314178467
  - 16.056474909186363
  - 21.377902448177338
  - 16.49834555387497
  - 28.323999345302582
  - 24.608073264360428
  - 17.154879435896873
  - 15.674201980233192
  - 19.540292993187904
  - 30.528434976935387
  - 25.86600472033024
  - 15.898049756884575
  - 18.446338832378387
  - 26.274746865034103
  - 18.704236537218094
  - 15.55719467997551
  - 15.457493409514427
  - 16.750911667943
  - 18.08695986866951
  - 16.507041424512863
  - 19.40683352947235
  - 17.141242116689682
  - 16.973280042409897
  - 17.98958121240139
  - 18.09628228843212
  - 41.63498458266258
  - 31.78177995979786
  - 19.09542852640152
  - 15.28223192691803
  - 16.10095751285553
  - 17.46888068318367
  - 17.042823761701584
  - 17.163818165659904
  - 15.18759423494339
  validation_losses:
  - 0.7245396971702576
  - 0.3949894905090332
  - 2.113884925842285
  - 0.47025352716445923
  - 0.4840840697288513
  - 0.3906508684158325
  - 0.95220947265625
  - 0.4359508156776428
  - 0.3926421105861664
  - 0.39096859097480774
  - 0.42215824127197266
  - 0.4239403307437897
  - 0.39415767788887024
  - 2030.578125
  - 8532858368.0
  - 17651.587890625
  - 0.6489492654800415
  - 0.9848365187644958
  - 0.5068573355674744
  - 0.4360886216163635
  - 0.4954354166984558
  - 0.47789689898490906
  - 0.5203800201416016
  - 1.039516806602478
  - 6.458649635314941
  - 63.227455139160156
  - 0.4904998242855072
  - 0.4325319826602936
  - 74.69635772705078
  - 270778.84375
  - 0.5139261484146118
  - 26051008.0
  - 2.4186768531799316
  - 0.4707671105861664
  - 0.3895520865917206
  - 0.3905320465564728
  - 0.6269101500511169
  - 0.5417524576187134
  - 0.39351126551628113
  - 0.3940148949623108
  - 0.42169860005378723
  - 611996.3125
  - 1375929.75
  - 1101922.375
  - 1027529.375
  - 3621157.25
  - 1179638.75
  - 1438457.375
  - 2898078.5
  - 1314827.5
  - 1165112.5
  - 1282856.875
  - 1369683.625
  - 1299230.5
  - 3013264.25
  - 2560129.75
  - 2920685.0
  - 1577249.25
  - 1273705.0
  - 1707852.375
  - 1566983.375
  - 1647966.125
  - 3029255.25
  - 3092176.25
  - 1328301.375
  - 893327.1875
  - 692466.4375
  - 992664.625
  - 1190907.875
  - 1598615.5
  - 1656738.5
  - 1887144.625
  - 1314603.375
  - 1308033.625
  - 840497.625
  - 2001807.625
  - 1198164.0
  - 1392889.875
  - 1967386.0
  - 1402295.25
  - 3606606.25
  - 2359015.75
  - 1308891.375
  - 1837774.375
  - 889905.75
  - 1649862.25
  - 3407658.75
  - 1786916.375
  - 1471811.875
  - 1317476.375
  - 1240392.5
  - 1295127.75
  - 2402242.25
  - 1249763.625
  - 893327.0625
  - 1500879.125
  - 1100027.375
  - 1562369.25
  - 941643.75
  - 1532538.5
loss_records_fold1:
  train_losses:
  - 15.584713622927666
  - 15.58425459265709
  - 15.387867614626884
  - 16.43920722603798
  - 15.349551811814308
  - 16.529041349887848
  - 15.144276559352875
  - 14.924484431743622
  - 15.209975749254227
  - 16.25708718597889
  - 21.141558915376663
  - 17.533749878406525
  - 16.784036546945572
  - 22.430303543806076
  - 20.589365392923355
  - 25.18642184138298
  - 15.80431142449379
  - 24.996216624975204
  - 17.653930068016052
  - 15.94724352657795
  - 15.611472591757774
  - 16.944185495376587
  - 15.785213887691498
  - 17.863922625780106
  - 15.735164016485214
  - 15.109588980674744
  - 15.332895427942276
  - 19.771991282701492
  - 22.070351779460907
  - 21.54131753742695
  - 18.590187177062035
  - 16.05285868048668
  - 21.155278027057648
  - 26.670852482318878
  - 26.247839629650116
  - 27.52550494670868
  - 18.10086041688919
  - 16.034770220518112
  - 21.319378346204758
  - 16.055709198117256
  - 15.561623588204384
  - 15.910674020648003
  - 18.206877946853638
  - 18.617321878671646
  - 20.62381014227867
  - 15.611441254615784
  - 17.219696760177612
  - 16.55772489309311
  - 15.677389413118362
  - 21.44712783396244
  - 15.390196681022644
  - 18.1625866740942
  - 15.974572241306305
  - 16.15245060622692
  - 26.113380759954453
  - 19.562865763902664
  - 16.372913405299187
  - 15.25352594256401
  - 16.739545553922653
  - 17.97814080119133
  - 17.683758974075317
  - 16.65133845806122
  - 15.555395424365997
  - 16.013602048158646
  - 17.18394134938717
  - 15.576686054468155
  - 22.79842258989811
  - 22.956345558166504
  - 15.66341745853424
  - 15.04422801733017
  - 15.461392536759377
  - 21.54135049879551
  - 25.144351840019226
  - 16.853225231170654
  - 15.600659415125847
  - 15.791802823543549
  - 19.841131806373596
  - 20.202894657850266
  - 16.43734908103943
  - 18.63965019583702
  - 17.708334982395172
  - 17.196278035640717
  - 19.646034955978394
  - 15.94814720749855
  - 20.449534446001053
  - 20.953398317098618
  - 22.96749509871006
  - 15.323982611298561
  - 21.63138173520565
  - 24.352051258087158
  - 16.702437609434128
  - 15.865953162312508
  - 17.66585737466812
  - 23.45191217958927
  - 16.245741605758667
  - 15.682998239994049
  - 21.793928861618042
  - 15.62750381231308
  - 15.09897318482399
  - 19.400293737649918
  validation_losses:
  - 1099932.875
  - 1060454.75
  - 3147270.75
  - 1611134.0
  - 1429968.625
  - 2079690.875
  - 1134181.875
  - 1293161.375
  - 1257593.625
  - 2184893.0
  - 4443783.5
  - 2590320.0
  - 2415324.0
  - 1793683.125
  - 2779121.75
  - 1562529.125
  - 2338861.75
  - 2031103.375
  - 1010297.4375
  - 1522988.5
  - 1105103.0
  - 3679601.5
  - 1803789.0
  - 2527825.0
  - 1689890.5
  - 861880.125
  - 1337694.625
  - 1162205.375
  - 1043371.1875
  - 1398875.75
  - 1060594.25
  - 1189281.875
  - 643588.4375
  - 1618968.25
  - 1125333.625
  - 1159612.25
  - 1654202.5
  - 1242187.875
  - 1497128.5
  - 1199407.875
  - 2189482.0
  - 1294832.625
  - 1049212.625
  - 2899675.75
  - 1778742.0
  - 3792846.0
  - 2666029.75
  - 812968.6875
  - 1407312.5
  - 1747315.125
  - 1948207.0
  - 2922249.75
  - 1417043.75
  - 3332626.5
  - 3200467.25
  - 2643882.0
  - 2062941.75
  - 847390.625
  - 3430809.25
  - 1672978.0
  - 1679620.875
  - 1482386.25
  - 878133.375
  - 1239539.125
  - 1083178.125
  - 2980723.5
  - 1267094.0
  - 1330712.375
  - 894367.5625
  - 2676427.75
  - 1852742.25
  - 2207875.75
  - 1209667.0
  - 1035956.5
  - 1367063.5
  - 914393.1875
  - 1225006.625
  - 656838.4375
  - 1160684.875
  - 1810475.625
  - 901301.8125
  - 1536325.5
  - 744560.1875
  - 961643.25
  - 1180078.375
  - 1239538.625
  - 3076363.5
  - 2250328.0
  - 2460913.75
  - 3310626.75
  - 1404391.375
  - 2828209.75
  - 1643840.125
  - 1336347.5
  - 3068186.75
  - 1627624.5
  - 2473722.0
  - 2900427.0
  - 1427053.375
  - 1291576.375
loss_records_fold2:
  train_losses:
  - 29.277390748262405
  - 18.85673362016678
  - 16.68184569478035
  - 19.176650166511536
  - 15.525170743465424
  - 16.43929675221443
  - 19.084424048662186
  - 15.397584795951843
  - 19.216570883989334
  - 29.432611972093582
  - 20.274161234498024
  - 15.364804774522781
  - 16.029410555958748
  - 17.946499079465866
  - 16.0297599285841
  - 15.965369552373886
  - 16.888185128569603
  - 19.601575300097466
  - 18.577912390232086
  - 17.36180916428566
  - 19.68641635775566
  - 17.340185299515724
  - 16.792781740427017
  - 24.086069643497467
  - 21.7007999420166
  - 16.34459999203682
  - 16.098930165171623
  - 17.028373539447784
  - 16.17236077785492
  - 16.45112682878971
  - 17.661530286073685
  - 15.514402121305466
  - 16.4333655834198
  - 25.349098920822144
  - 21.622501879930496
  - 20.38623398542404
  - 17.113740116357803
  - 20.46565318107605
  - 15.52297168970108
  - 16.11522141098976
  - 18.19256256520748
  - 22.76972460746765
  - 16.7656988799572
  - 16.51274272799492
  - 16.462138324975967
  - 20.10151332616806
  - 15.276692539453506
  - 16.139612436294556
  - 18.829692646861076
  - 25.062222629785538
  - 21.553534358739853
  - 16.25324833393097
  - 15.505055993795395
  - 16.376605108380318
  - 16.84983429312706
  - 23.037730246782303
  - 25.29204234480858
  - 21.303826451301575
  - 17.475474759936333
  - 18.45714643597603
  - 24.309133887290955
  - 16.521833896636963
  - 16.216344714164734
  - 19.57435753941536
  - 19.13515192270279
  - 20.110298961400986
  - 17.44357204437256
  - 16.70732879638672
  - 23.75577485561371
  - 16.077297121286392
  - 18.52326676249504
  - 19.499988734722137
  - 19.291137263178825
  - 16.483171045780182
  - 16.940445870161057
  - 17.588033229112625
  - 17.844895616173744
  - 16.589652985334396
  - 15.680416464805603
  - 17.524121016263962
  - 18.17880643904209
  - 18.892504394054413
  - 18.168515041470528
  - 28.04407560825348
  - 24.951712906360626
  - 15.640400737524033
  - 16.520668148994446
  - 18.079127609729767
  - 16.779196560382843
  - 25.953714817762375
  - 18.833730399608612
  - 17.218574702739716
  - 16.61017106473446
  - 19.724424839019775
  - 25.522318452596664
  - 16.523525312542915
  - 16.149049013853073
  - 19.822675734758377
  - 26.79463705420494
  - 23.920164734125137
  validation_losses:
  - 966699.0625
  - 2797980.75
  - 3334138.75
  - 1744728.5
  - 1574661.875
  - 1384421.5
  - 2833341.75
  - 1092116.0
  - 1123322.625
  - 1306373.25
  - 1676065.625
  - 3645150.25
  - 2666617.25
  - 1140830.625
  - 2430612.75
  - 1727788.0
  - 1250974.75
  - 727395.5625
  - 2352897.0
  - 1327244.375
  - 1765053.75
  - 1108616.125
  - 1025999.75
  - 1453057.375
  - 993188.5
  - 2835811.5
  - 1333684.875
  - 1240091.75
  - 1661736.5
  - 979781.625
  - 1380506.625
  - 888284.6875
  - 1166019.125
  - 2821172.25
  - 1160136.375
  - 2866970.5
  - 3041730.5
  - 1399064.625
  - 1158697.0
  - 1694769.25
  - 1759201.75
  - 631422.8125
  - 979385.3125
  - 1327373.375
  - 1257462.125
  - 1023065.8125
  - 2777590.0
  - 1058525.125
  - 2037452.625
  - 1006357.125
  - 1017654.9375
  - 3051738.25
  - 916361.25
  - 1703503.25
  - 3142451.0
  - 3058373.0
  - 2918615.25
  - 3005887.0
  - 1020119.3125
  - 1252833.5
  - 2554385.75
  - 2871887.0
  - 1615382.125
  - 2539908.25
  - 761216.5625
  - 1597416.5
  - 1375416.0
  - 0.41701218485832214
  - 161619.65625
  - 0.4531264305114746
  - 0.8037258386611938
  - 179381.140625
  - 133603.046875
  - 0.3922577202320099
  - 400055.78125
  - 133603.1875
  - 863209.75
  - 0.4078143239021301
  - 1568955.75
  - 0.3944300711154938
  - 0.41865217685699463
  - 503400.96875
  - 250244.78125
  - 49343.0390625
  - 0.4058498740196228
  - 90723.4609375
  - 262084.671875
  - 214819.828125
  - 115850.5546875
  - 0.39718136191368103
  - 1537405.375
  - 669829.1875
  - 817591.6875
  - 451907.3125
  - 124688.0703125
  - 171955.921875
  - 0.48843148350715637
  - 0.38664692640304565
  - 151289.390625
  - 997033.3125
loss_records_fold3:
  train_losses:
  - 16.945975691080093
  - 16.971885934472084
  - 17.68458442389965
  - 15.744783267378807
  - 15.613110899925232
  - 18.61790359020233
  - 20.866287499666214
  - 18.307556360960007
  - 20.345492988824844
  - 16.65823160111904
  - 18.200180634856224
  - 29.604303508996964
  - 19.6400605738163
  - 20.021107494831085
  - 16.418485164642334
  - 16.279394015669823
  - 15.841997891664505
  - 15.703608721494675
  - 17.847628384828568
  - 15.489559829235077
  - 17.755837380886078
  - 16.93064235150814
  - 17.284939885139465
  - 15.756227642297745
  - 18.757654279470444
  - 17.080755546689034
  - 16.217681616544724
  - 17.61583136022091
  - 16.480277180671692
  - 17.242374658584595
  - 17.295084446668625
  - 15.787101477384567
  - 17.460105702281
  - 16.13055545091629
  - 16.315810292959213
  - 16.393389403820038
  - 17.258063703775406
  - 20.498212933540344
  - 20.707463294267654
  - 16.23822173476219
  - 18.50962695479393
  - 20.13341397047043
  - 19.750878497958183
  - 16.834276601672173
  - 17.201134577393532
  - 15.479411602020264
  - 17.132697850465775
  - 16.398307859897614
  - 22.191667646169662
  - 19.92923480272293
  - 16.573070228099823
  - 17.108047157526016
  - 20.62531892210245
  - 16.29537996649742
  - 15.90339082479477
  - 15.540141701698303
  - 15.119819611310959
  - 17.90273430943489
  - 15.622338563203812
  - 21.839282631874084
  - 25.276228934526443
  - 19.512720316648483
  - 22.3554225564003
  - 18.889696300029755
  - 21.026347368955612
  - 17.857668414711952
  - 21.30297362804413
  - 18.365072056651115
  - 24.5136658847332
  - 25.473228812217712
  - 20.91323310136795
  - 17.102822095155716
  - 19.075419276952744
  - 18.348804116249084
  - 22.414729967713356
  - 16.333646908402443
  - 17.51835972070694
  - 16.02915881574154
  - 15.156929984688759
  - 23.173643618822098
  - 17.49604919552803
  - 16.164906412363052
  - 16.449159801006317
  - 28.383899688720703
  - 17.098692715168
  - 17.875404685735703
  - 14.91160386800766
  - 16.15591076016426
  - 15.911181196570396
  - 18.092339754104614
  - 17.670050084590912
  - 25.258810073137283
  - 21.09836672246456
  - 18.50622710585594
  - 25.88638450205326
  - 30.503696620464325
  - 21.32552406191826
  - 15.644739478826523
  - 15.57426331937313
  - 18.881051927804947
  validation_losses:
  - 222607.921875
  - 417395.78125
  - 0.42630454897880554
  - 197226.59375
  - 38255.4453125
  - 1649996.25
  - 0.42510002851486206
  - 504284.5
  - 31892.96484375
  - 326395.9375
  - 1.0307029485702515
  - 40381.984375
  - 866276.875
  - 2067978.125
  - 459781.40625
  - 504284.125
  - 154809.703125
  - 1347259.25
  - 364465.5
  - 411032.4375
  - 1006260.0625
  - 0.5533168911933899
  - 21266.7734375
  - 235321.90625
  - 531814.0
  - 0.6075711846351624
  - 1256013.875
  - 307304.4375
  - 0.8048015236854553
  - 180265.140625
  - 0.4478531777858734
  - 0.40111979842185974
  - 1972891.0
  - 775315.875
  - 0.4596971869468689
  - 917147.25
  - 290348.875
  - 0.7579551935195923
  - 0.39853861927986145
  - 0.43861454725265503
  - 0.7650871872901917
  - 0.5282978415489197
  - 48867.1171875
  - 34022.52734375
  - 0.4536232352256775
  - 0.40267929434776306
  - 0.41478610038757324
  - 353918.3125
  - 0.6330320239067078
  - 1177807.125
  - 722038.6875
  - 116728.6640625
  - 434345.75
  - 1563295.25
  - 228931.65625
  - 438561.78125
  - 584703.875
  - 247975.109375
  - 0.44955408573150635
  - 315775.28125
  - 0.46930938959121704
  - 0.60796058177948
  - 1072787.0
  - 0.4642607271671295
  - 459781.1875
  - 0.5074577331542969
  - 188706.34375
  - 57356.4765625
  - 1273011.25
  - 0.9515337944030762
  - 0.4838864207267761
  - 161183.765625
  - 0.40925833582878113
  - 510630.09375
  - 1283569.125
  - 256502.078125
  - 0.5155131220817566
  - 123071.3984375
  - 1218712.125
  - 1548036.25
  - 334872.84375
  - 1673040.75
  - 1268625.375
  - 1306978.0
  - 0.4190707504749298
  - 216225.65625
  - 222607.890625
  - 152723.328125
  - 449332.28125
  - 0.6363515853881836
  - 0.5950605273246765
  - 624912.125
  - 0.6726364493370056
  - 252250.296875
  - 830612.0625
  - 55230.8203125
  - 273415.8125
  - 0.4122718274593353
  - 0.6700959801673889
  - 0.40003150701522827
loss_records_fold4:
  train_losses:
  - 15.695309609174728
  - 15.978217780590057
  - 16.20106938481331
  - 16.35392990708351
  - 16.073642909526825
  - 16.57132712006569
  - 16.74493034183979
  - 16.26383428275585
  - 18.370591402053833
  - 19.93809811770916
  - 21.135208129882812
  - 16.757269755005836
  - 27.87411203980446
  - 21.659714490175247
  - 19.21440154314041
  - 18.089925333857536
  - 15.755154222249985
  - 17.772064968943596
  - 18.03239604830742
  - 17.89372870326042
  - 16.571466356515884
  - 17.05151130259037
  - 17.194881409406662
  - 15.960810720920563
  - 22.24720299243927
  - 16.14304155111313
  - 15.865873843431473
  - 15.953966200351715
  - 15.706510424613953
  - 21.35448044538498
  - 16.957025468349457
  - 18.832509391009808
  - 16.013120085000992
  - 17.048657208681107
  - 19.508119642734528
  - 24.031391248106956
  - 18.26360434293747
  - 18.358363837003708
  - 22.45822712779045
  - 24.55941565334797
  - 15.693085834383965
  - 17.135705560445786
  - 16.79533463716507
  - 15.443367511034012
  - 17.814935013651848
  - 17.113273441791534
  - 15.588693022727966
  - 15.504359483718872
  - 15.263319313526154
  - 15.983880519866943
  - 18.2311649620533
  - 17.1558655500412
  - 17.5288123190403
  - 20.467182517051697
  - 20.281596466898918
  - 17.532817348837852
  - 21.27416041493416
  - 16.176255583763123
  - 15.944186583161354
  - 15.538910180330276
  - 15.230713605880737
  - 15.333773493766785
  - 24.658756762742996
  - 17.706137999892235
  - 28.299254417419434
  - 23.670248955488205
  - 18.871660754084587
  - 20.51324114203453
  - 28.10147061944008
  - 25.08715058863163
  - 17.64490094780922
  - 22.903143048286438
  - 15.434090688824654
  - 16.291228979825974
  - 16.012367069721222
  - 24.195513546466827
  - 16.601013898849487
  - 18.640008091926575
  - 15.704853489995003
  - 32.461444437503815
  - 26.482654690742493
  - 23.48676198720932
  - 18.017729938030243
  - 15.621869385242462
  - 18.16130530834198
  - 15.761541992425919
  - 16.14790515601635
  - 18.30549755692482
  - 15.659623205661774
  - 15.602724403142929
  - 16.432736940681934
  - 15.770134210586548
  - 21.737131237983704
  - 15.992975011467934
  - 16.248094350099564
  - 16.901185005903244
  - 16.09174484014511
  - 17.361626729369164
  - 20.729995787143707
  - 16.303464964032173
  validation_losses:
  - 276434.6875
  - 87266.7421875
  - 834361.0625
  - 119678.4453125
  - 259525.78125
  - 100223.015625
  - 0.42079958319664
  - 1192357.125
  - 1074583.5
  - 0.47278058528900146
  - 0.6005091071128845
  - 0.7350391745567322
  - 1.3011219501495361
  - 8394.8212890625
  - 354110.40625
  - 0.41209521889686584
  - 0.4010089039802551
  - 0.401355504989624
  - 1084162.375
  - 84693.640625
  - 0.4093168079853058
  - 194814.875
  - 0.3926295042037964
  - 0.3944443464279175
  - 31526.935546875
  - 998806.75
  - 0.6055508852005005
  - 0.4499984681606293
  - 0.4459226429462433
  - 181819.96875
  - 320459.34375
  - 110628.1796875
  - 172797.578125
  - 785462.25
  - 139074.25
  - 21146.01171875
  - 17238.29296875
  - 385094.09375
  - 842228.5625
  - 971464.0625
  - 0.4909915626049042
  - 1063102.875
  - 28938.33984375
  - 275141.125
  - 0.5636332035064697
  - 137805.21875
  - 0.39269858598709106
  - 31526.890625
  - 63959.0234375
  - 0.39235612750053406
  - 1355868.125
  - 874719.125
  - 201246.734375
  - 0.42268693447113037
  - 0.6311500072479248
  - 850247.25
  - 0.39517250657081604
  - 0.39097437262535095
  - 800630.25
  - 770929.375
  - 210344.53125
  - 663590.75
  - 78233.5
  - 183158.6875
  - 36735.1015625
  - 0.433828204870224
  - 769976.1875
  - 650482.8125
  - 420188.71875
  - 818590.375
  - 857803.375
  - 30234.796875
  - 959084.0
  - 15939.927734375
  - 1063848.5
  - 145558.015625
  - 177931.203125
  - 113161.7890625
  - 600239.3125
  - 1151518.125
  - 101522.375
  - 649565.375
  - 0.4078710675239563
  - 784388.3125
  - 985072.1875
  - 768441.4375
  - 132596.53125
  - 351485.9375
  - 0.3960091173648834
  - 1069231.125
  - 1069122.0
  - 1264649.25
  - 66544.765625
  - 96352.8984375
  - 1024843.0
  - 126101.1953125
  - 31534.9765625
  - 164991.78125
  - 0.3931981921195984
  - 0.7281619906425476
training fold messages:
  fold 0 training message: completed 100 epochs without stopping early
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: completed 100 epochs without stopping early
  fold 3 training message: completed 100 epochs without stopping early
  fold 4 training message: completed 100 epochs without stopping early
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.8576329331046312, 0.8593481989708405, 0.8593481989708405,
    0.8591065292096219]'
  fold_eval_f1: '[0.0, 0.0, 0.0, 0.0, 0.0]'
  mean_eval_accuracy: 0.858613758672113
  mean_f1_accuracy: 0.0
  total_train_time: '0:11:52.939469'
