config:
  aggregation: mean
  batch_size: 64
  class_weights: true
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.0
  epochs: 100
  hidden_units:
  - 64
  - 64
  - 64
  - 64
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.01
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: true
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-24 22:39:09.490166'
fold_0_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_97fold_0_optim_dict.pt
fold_0_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_97fold_0_state_dict.pt
fold_1_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_97fold_1_optim_dict.pt
fold_1_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_97fold_1_state_dict.pt
fold_2_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_97fold_2_optim_dict.pt
fold_2_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_97fold_2_state_dict.pt
fold_3_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_97fold_3_optim_dict.pt
fold_3_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_97fold_3_state_dict.pt
fold_4_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_97fold_4_optim_dict.pt
fold_4_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_97fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 3.3427314102649692
  - 3.1086970746517184
  - 2.9845792144536976
  - 3.0801074743270878
  - 3.08828496336937
  - 2.999939972162247
  - 3.010960668325424
  - 2.918236529827118
  - 3.023511075973511
  - 2.9579539954662324
  - 2.915580847859383
  - 2.8964737117290498
  - 3.371534836292267
  - 3.1127103149890902
  - 2.930700868368149
  - 2.824976325035095
  - 2.8847543597221375
  - 2.835331210494042
  - 2.857064235210419
  - 2.850203597545624
  - 3.0037005841732025
  - 2.893779933452606
  - 2.920283794403076
  - 2.8037503480911257
  - 2.8939938962459566
  - 2.9394700795412065
  - 2.914815843105316
  - 2.9159472316503527
  - 2.955751651525498
  - 2.8346476912498475
  - 2.8711878955364227
  - 2.9411006510257724
  - 2.8607094794511796
  - 2.844391751289368
  - 2.9061839908361438
  - 2.9466104358434677
  - 2.878692951798439
  - 2.884394294023514
  - 2.830573630332947
  - 2.8578325390815738
  - 2.858928656578064
  - 2.883949425816536
  - 2.8669485539197925
  - 2.905667531490326
  - 2.823355033993721
  - 2.8476064383983615
  - 2.8345460534095768
  validation_losses:
  - 0.4660344123840332
  - 0.4130047857761383
  - 0.41498860716819763
  - 0.3888365626335144
  - 0.39628323912620544
  - 0.43493711948394775
  - 0.40037789940834045
  - 0.40441903471946716
  - 0.42554202675819397
  - 0.3864442706108093
  - 0.39961162209510803
  - 0.3818623423576355
  - 0.3809215724468231
  - 0.39357489347457886
  - 0.3898233473300934
  - 0.4008655548095703
  - 0.3885974884033203
  - 0.38079217076301575
  - 0.3822881579399109
  - 0.4432287812232971
  - 0.380568265914917
  - 0.3794560432434082
  - 0.384677529335022
  - 1.9174087047576904
  - 0.42366141080856323
  - 0.40813666582107544
  - 0.3922847807407379
  - 0.4102213680744171
  - 0.38988494873046875
  - 0.42192500829696655
  - 0.38363099098205566
  - 0.3887215852737427
  - 0.38931846618652344
  - 0.384743869304657
  - 0.38120120763778687
  - 0.4329124391078949
  - 0.39077818393707275
  - 0.49655959010124207
  - 0.41152358055114746
  - 0.3904315233230591
  - 0.4170648455619812
  - 0.3968740999698639
  - 0.38562676310539246
  - 0.3843727707862854
  - 0.3904716372489929
  - 0.3786379396915436
  - 0.37837255001068115
loss_records_fold1:
  train_losses:
  - 2.798842185735703
  - 2.8099554628133774
  - 2.8183727204799656
  - 2.836268588900566
  - 2.8374624580144885
  - 2.7980483651161197
  - 2.774057757854462
  - 2.799602681398392
  - 2.8508795469999315
  - 2.8183121383190155
  - 2.8007298678159716
  - 2.797863495349884
  - 2.8207413345575336
  - 2.8026067525148393
  - 2.7795258909463882
  - 2.7561772733926775
  - 2.7764646947383884
  - 2.7564711779356004
  - 2.7557646334171295
  - 2.7618080496788027
  - 2.708954679965973
  - 2.7100927352905275
  - 2.8207578718662263
  - 2.787611517310143
  - 2.791936805844307
  - 2.7428800016641617
  - 2.7462434947490695
  - 2.8082906246185306
  - 2.8125039458274843
  - 2.7796475797891618
  - 2.8066298216581345
  - 2.7363961338996887
  - 2.8054196298122407
  - 2.7595112532377244
  - 2.822562074661255
  - 2.766036343574524
  - 2.785508555173874
  - 2.808613657951355
  - 2.821859335899353
  - 2.7719062477350236
  - 2.773953223228455
  - 2.775836181640625
  - 2.7419457137584686
  - 2.8584085881710055
  - 2.7810091346502306
  - 2.7345053195953373
  - 2.8180195510387422
  - 2.813996204733849
  - 2.769775754213333
  - 2.7666354417800907
  - 2.7429439187049867
  - 2.7578024089336397
  - 2.7060653626918794
  - 2.750471466779709
  - 2.80089607834816
  - 2.824215972423554
  - 2.779060083627701
  - 2.7497683346271518
  - 2.769382303953171
  - 2.7634383499622346
  - 2.742975726723671
  - 2.6701830416917804
  - 2.688928058743477
  - 2.76170871257782
  - 2.751182416081429
  - 2.8187029480934145
  - 2.7429478198289874
  - 2.763898277282715
  - 2.7543927222490314
  - 2.7107793748378755
  - 2.686661866307259
  - 2.7763119429349903
  - 2.7051555752754215
  - 2.745392858982086
  - 2.7694308310747147
  - 2.719989052414894
  - 2.7297962307929993
  - 2.7099663078784944
  - 2.6771664530038835
  - 2.739731061458588
  - 2.720921862125397
  - 2.660684394836426
  - 2.7048936903476717
  - 2.6781684666872025
  - 2.704134625196457
  - 2.699418491125107
  - 2.716159534454346
  - 2.690041732788086
  - 2.6568426847457887
  - 3.067818868160248
  - 2.7888564050197604
  - 2.767559897899628
  - 2.7329279571771625
  - 2.7011123597621918
  - 2.722557079792023
  - 2.701827245950699
  - 2.689803567528725
  - 2.6967610090970995
  - 2.684328588843346
  - 2.71435546875
  validation_losses:
  - 0.4551086127758026
  - 0.49219179153442383
  - 0.45506295561790466
  - 0.6251997947692871
  - 0.5037004947662354
  - 0.6547829508781433
  - 0.516748309135437
  - 0.537476122379303
  - 0.5436796545982361
  - 0.4979746639728546
  - 0.6871329545974731
  - 0.42425820231437683
  - 0.4594946503639221
  - 0.4023772180080414
  - 0.5400274395942688
  - 0.43900054693222046
  - 0.47731560468673706
  - 0.39235615730285645
  - 0.5441574454307556
  - 0.5982524156570435
  - 0.6308429837226868
  - 0.6984508633613586
  - 0.8097929358482361
  - 1.51687753200531
  - 0.4600081145763397
  - 0.5565745830535889
  - 0.39511197805404663
  - 0.42361682653427124
  - 0.4100336730480194
  - 0.5195711255073547
  - 0.5706602931022644
  - 0.6480389833450317
  - 0.4444945156574249
  - 0.411933571100235
  - 0.5095470547676086
  - 0.4433802664279938
  - 0.4259587228298187
  - 0.4477778375148773
  - 0.43170884251594543
  - 0.6173433065414429
  - 0.4408192038536072
  - 0.7681106328964233
  - 0.4147489666938782
  - 0.43230536580085754
  - 0.5678563714027405
  - 0.4410284161567688
  - 0.5580788254737854
  - 0.6129198670387268
  - 0.6806853413581848
  - 0.548594057559967
  - 0.6534445881843567
  - 0.5359081625938416
  - 0.7166692614555359
  - 2.122549057006836
  - 0.8943975567817688
  - 0.6005605459213257
  - 0.8125885128974915
  - 1.0561411380767822
  - 1.020917296409607
  - 0.8822470903396606
  - 0.6959928274154663
  - 0.7802777290344238
  - 1.4836689233779907
  - 2.6250133514404297
  - 1.0328541994094849
  - 0.7158401012420654
  - 1.445255160331726
  - 3.366692066192627
  - 1.3872215747833252
  - 2.7875423431396484
  - 2.7330286502838135
  - 1.1927075386047363
  - 0.6261234283447266
  - 0.961661159992218
  - 0.5465937852859497
  - 1.1148147583007812
  - 1.0722935199737549
  - 0.7611826658248901
  - 1.1555601358413696
  - 1.1000250577926636
  - 1.2518240213394165
  - 0.7768165469169617
  - 0.7262105941772461
  - 1.0754706859588623
  - 0.8990656733512878
  - 1.0383710861206055
  - 1.5612865686416626
  - 1.06508469581604
  - 1.1349421739578247
  - 0.9807531237602234
  - 0.4514516294002533
  - 0.4701468050479889
  - 0.6152306199073792
  - 0.4624617099761963
  - 0.4939120411872864
  - 1.5426748991012573
  - 3.2659177780151367
  - 0.729579508304596
  - 0.7002854943275452
  - 0.7068392634391785
loss_records_fold2:
  train_losses:
  - 2.7408951222896576
  - 2.7422146260738374
  - 2.715711855888367
  - 2.717331433296204
  - 2.7392832010984423
  - 2.697259166836739
  - 2.724153065681458
  - 2.7418796718120575
  - 2.738422265648842
  - 2.6939399003982545
  - 2.6895049482584
  - 2.714768335223198
  - 2.7454968214035036
  - 2.69465970993042
  - 2.6783164471387866
  - 2.662332996726036
  - 2.6683443889021876
  - 2.7121204137802124
  - 2.685048854351044
  - 2.661750239133835
  - 2.7332547783851626
  - 2.728341200947762
  - 2.6657321542501453
  - 2.69612974524498
  - 2.7992866903543474
  - 2.6684128880500797
  - 2.7411030471324924
  - 2.71362966299057
  - 2.6893262714147568
  - 2.676350384950638
  - 2.706648948788643
  - 2.6956516325473787
  - 2.6741786092519764
  - 2.7258632987737657
  - 2.7376041024923325
  - 2.7839180618524555
  - 2.809150618314743
  - 2.713091915845871
  - 2.7354595094919207
  - 2.7397737681865695
  - 2.759307447075844
  - 2.746516126394272
  - 2.7197210788726807
  - 2.713121908903122
  - 2.692953771352768
  - 2.7190537065267564
  - 2.716178259253502
  - 2.7216936647892
  - 2.733713036775589
  - 2.6851329982280734
  - 2.6707820355892182
  - 2.7033334970474243
  - 2.7187018156051637
  - 2.6690056681632996
  - 2.683495193719864
  - 2.6843599677085876
  - 2.6903343141078953
  - 2.6591863572597507
  - 2.687732690572739
  - 2.6651744902133943
  - 2.7005361676216126
  - 2.7728000938892365
  - 2.7440625429153442
  - 2.6260599315166475
  - 2.6867967665195467
  - 2.6589063704013824
  - 2.696956253051758
  - 2.6990188121795655
  - 2.9378925174474717
  - 2.743599006533623
  - 2.7546659052371982
  - 2.748373857140541
  - 2.6889413535594944
  - 2.6813730478286746
  - 2.7244735300540928
  - 2.6463355720043182
  - 2.688958936929703
  - 2.6647450238466264
  - 2.7087587118148804
  - 2.6136921495199203
  - 2.6879427045583726
  - 2.682153269648552
  - 2.6352974563837055
  - 2.696453306078911
  - 2.7494476795196534
  - 2.692495876550675
  - 2.705536812543869
  - 2.6577281147241596
  - 2.659872090816498
  - 2.6749401301145554
  - 2.698960542678833
  - 2.7027569949626926
  - 2.745297604799271
  - 2.668892884254456
  - 2.6698682963848115
  - 2.7318287253379823
  - 2.709449672698975
  - 2.6603146314620973
  - 2.6713637799024585
  - 2.670466107130051
  validation_losses:
  - 0.660335898399353
  - 1.994013786315918
  - 2.2455508708953857
  - 1.7789632081985474
  - 3.5203349590301514
  - 8.71247386932373
  - 3.490115165710449
  - 0.39080554246902466
  - 4.359457492828369
  - 1.7534308433532715
  - 3.8499691486358643
  - 14.263715744018555
  - 3.9298062324523926
  - 2.676007032394409
  - 2.5703072547912598
  - 4.439666748046875
  - 1.8883675336837769
  - 6.306423664093018
  - 3.899054527282715
  - 3.3476974964141846
  - 0.6264108419418335
  - 0.41516008973121643
  - 0.8842788338661194
  - 0.6054763793945312
  - 0.9842432141304016
  - 13.823944091796875
  - 12.590303421020508
  - 20.542001724243164
  - 24.601638793945312
  - 9.686034202575684
  - 19.575756072998047
  - 49.302886962890625
  - 30.194337844848633
  - 0.4578862190246582
  - 0.37706294655799866
  - 0.4118506610393524
  - 0.37712711095809937
  - 8.134514808654785
  - 1.2572933435440063
  - 0.6718466877937317
  - 0.3743854761123657
  - 0.45932483673095703
  - 2.854382038116455
  - 0.5005093216896057
  - 0.4256208837032318
  - 1.359426736831665
  - 0.6563741564750671
  - 0.6228768825531006
  - 1.7022669315338135
  - 0.48990973830223083
  - 1.0844775438308716
  - 0.5796260833740234
  - 0.8581373691558838
  - 0.9906233549118042
  - 0.966093897819519
  - 5.545156002044678
  - 4.1465959548950195
  - 0.9082562327384949
  - 1.3345249891281128
  - 0.9461429119110107
  - 1.6402535438537598
  - 0.9660084843635559
  - 1.211618423461914
  - 2.5120317935943604
  - 0.3791615068912506
  - 7.571780204772949
  - 10.277352333068848
  - 1.4509530067443848
  - 0.48354846239089966
  - 0.4433140456676483
  - 0.4025610387325287
  - 0.3802993893623352
  - 0.41161099076271057
  - 0.8218614459037781
  - 0.38538604974746704
  - 1.3122245073318481
  - 0.6020343899726868
  - 1.2003157138824463
  - 1.8453139066696167
  - 5.712726593017578
  - 0.8552334308624268
  - 10.412468910217285
  - 79.25861358642578
  - 20.47385025024414
  - 0.3753144443035126
  - 0.8263961672782898
  - 0.5469440817832947
  - 4.995006084442139
  - 4.213180065155029
  - 8.892830848693848
  - 4.246868133544922
  - 24.930118560791016
  - 1.5849570035934448
  - 8.275781631469727
  - 1.868108868598938
  - 0.9062811136245728
  - 2.7082529067993164
  - 12.020920753479004
  - 16.28630828857422
  - 15.115007400512695
loss_records_fold3:
  train_losses:
  - 2.689374974370003
  - 2.7383451938629153
  - 2.730844828486443
  - 2.6961923241615295
  - 2.6945999503135685
  - 2.8327088892459873
  - 2.728605031967163
  - 2.66462841629982
  - 2.7852949500083923
  - 2.7258364617824555
  - 2.714332491159439
  - 2.736823645234108
  - 2.7356734037399293
  - 2.737243348360062
  - 2.6917249470949174
  - 2.695356145501137
  - 2.682186257839203
  - 2.747948092222214
  - 2.722156870365143
  - 2.683487975597382
  - 2.701772403717041
  - 2.6560618668794636
  - 2.692731037735939
  - 2.744200211763382
  - 2.7534175515174866
  - 2.706217795610428
  - 2.7057922899723055
  - 2.7189130365848544
  - 2.7307303577661517
  - 2.672218441963196
  - 2.6864442229270935
  - 2.692834973335266
  - 2.6919566690921783
  - 2.703631168603897
  - 2.6638793081045153
  - 2.69443094432354
  - 2.691125711798668
  - 2.72546221613884
  - 2.6743433415889744
  - 2.712305480241776
  - 2.6957134276628496
  - 2.676712927222252
  - 2.6995274066925052
  - 2.696894884109497
  - 2.7207251340150833
  - 2.647982743382454
  - 2.723642793297768
  - 2.7452553749084476
  - 2.6885672092437747
  - 2.7097607105970383
  - 2.6833360850811006
  - 2.717812418937683
  - 2.6566911935806274
  - 2.6774961352348328
  - 2.651588571071625
  - 2.684249645471573
  - 2.6772699385881427
  - 2.732996064424515
  - 2.6435073018074036
  - 2.6864207446575166
  - 2.7145509958267215
  - 2.7192749023437504
  - 2.655425322055817
  - 2.6589056938886646
  - 2.746798399090767
  - 2.685847133398056
  - 2.6732748389244083
  - 2.6918032079935075
  - 2.665082883834839
  - 2.7156385809183123
  - 2.718701481819153
  - 2.6770295679569247
  - 2.6653122425079347
  - 2.8401163011789325
  - 2.694223621487618
  - 2.70255084335804
  - 2.763589408993721
  - 2.660126745700836
  - 2.6742553740739825
  - 2.673350286483765
  - 2.660638839006424
  - 2.687544932961464
  - 2.6303156167268753
  - 2.645318973064423
  - 2.671303677558899
  - 2.649778562784195
  - 2.6599575817584995
  - 2.6743094593286516
  - 2.6086340248584747
  - 2.6732994407415394
  - 2.7005406498909
  - 2.6571687400341037
  - 2.6813538432121278
  - 2.6501991093158725
  - 2.7017212510108948
  - 2.6844019055366517
  - 2.656706088781357
  - 2.6739595979452133
  - 2.6764355778694155
  - 2.655237624049187
  validation_losses:
  - 1.3170480728149414
  - 14.521308898925781
  - 4.48149299621582
  - 4.655444622039795
  - 0.5294347405433655
  - 0.3800676167011261
  - 0.3888112008571625
  - 0.42936962842941284
  - 1.447460651397705
  - 0.4037953019142151
  - 1.4685910940170288
  - 20.042898178100586
  - 4.932760715484619
  - 0.9458034038543701
  - 0.9002354741096497
  - 0.5537732839584351
  - 0.7729060053825378
  - 3.8763067722320557
  - 4.051832675933838
  - 2.888608694076538
  - 2.337719440460205
  - 2.9313483238220215
  - 3.2571065425872803
  - 5.2036590576171875
  - 0.5717524886131287
  - 1.1633678674697876
  - 0.3751983940601349
  - 1.2937055826187134
  - 1.793760061264038
  - 1.0217626094818115
  - 1.269317865371704
  - 1.0426499843597412
  - 1.0997226238250732
  - 1.0317730903625488
  - 0.8656293153762817
  - 1.0767616033554077
  - 2.246098518371582
  - 5.659700393676758
  - 8.191658973693848
  - 1.2062445878982544
  - 0.3749125897884369
  - 17.025997161865234
  - 11.769152641296387
  - 6.577762603759766
  - 4.848772048950195
  - 2.066948175430298
  - 5.575836181640625
  - 5.5151519775390625
  - 7.454714775085449
  - 5.875363826751709
  - 7.063015937805176
  - 2.5876386165618896
  - 2.0065650939941406
  - 8.470518112182617
  - 7.314243793487549
  - 4.387852191925049
  - 26.378992080688477
  - 25.08335304260254
  - 39.58857727050781
  - 50.908260345458984
  - 192.76528930664062
  - 172.57891845703125
  - 146.7268524169922
  - 26.2247314453125
  - 9.390227317810059
  - 1.765865683555603
  - 5.822639465332031
  - 19.468196868896484
  - 26.980850219726562
  - 39.30824661254883
  - 57.163272857666016
  - 103.96583557128906
  - 96.19739532470703
  - 11.152037620544434
  - 10.233115196228027
  - 3.106393575668335
  - 1.416452169418335
  - 1.5617316961288452
  - 4.088484764099121
  - 2.9045543670654297
  - 4.188408851623535
  - 1.2757072448730469
  - 1.500795841217041
  - 2.5318551063537598
  - 1.6995213031768799
  - 3.372830390930176
  - 2.8691015243530273
  - 1.5972836017608643
  - 1.9487096071243286
  - 4.33056116104126
  - 1.3742409944534302
  - 1.5422487258911133
  - 1.431147813796997
  - 3.235252857208252
  - 16.06951141357422
  - 2.7364025115966797
  - 238.8993682861328
  - 2.1383070945739746
  - 0.9541300535202026
  - 2.156615972518921
loss_records_fold4:
  train_losses:
  - 2.693108478188515
  - 2.735737180709839
  - 2.6517271131277087
  - 2.6319882929325105
  - 2.6809027194976807
  - 2.6781788527965547
  - 2.644190725684166
  - 2.782821643352509
  - 2.664356142282486
  - 2.6532418549060823
  - 2.6616493225097657
  - 2.6800701826810838
  - 2.667667889595032
  - 2.652626180648804
  - 2.7743091166019442
  - 2.635967743396759
  - 2.7142206460237506
  - 2.6986641854047777
  - 2.6856043964624408
  - 2.697841000556946
  - 2.668194550275803
  - 2.6924535006284716
  - 2.7070628583431247
  - 2.6580058485269547
  - 2.669105812907219
  - 2.6572176903486255
  - 2.662394082546234
  - 2.7757423877716065
  - 2.6681384593248367
  - 2.6934148728847505
  - 2.6746785640716553
  - 2.681370735168457
  - 2.681561079621315
  - 2.7416159689426425
  - 2.640886825323105
  validation_losses:
  - 0.5278541445732117
  - 0.4678393006324768
  - 0.7957893013954163
  - 1.2843589782714844
  - 1.0252889394760132
  - 0.5700123906135559
  - 0.8228340148925781
  - 0.5033928751945496
  - 0.7006931304931641
  - 0.3553989827632904
  - 0.5153111219406128
  - 0.8306924700737
  - 0.7026612758636475
  - 0.3700243830680847
  - 0.757957398891449
  - 0.831781268119812
  - 0.7327526211738586
  - 0.7405523657798767
  - 2.2585461139678955
  - 4.143593788146973
  - 2.202316999435425
  - 6.342531681060791
  - 6.904980659484863
  - 6.755782604217529
  - 4.354546070098877
  - 3.8880300521850586
  - 0.6462182998657227
  - 0.41832002997398376
  - 0.7564907670021057
  - 0.3691401183605194
  - 0.3640868663787842
  - 0.368033766746521
  - 0.3722904622554779
  - 0.37269142270088196
  - 0.3632953464984894
training fold messages:
  fold 0 training message: stopped training due to stagnating improvement on validation
    loss after 47 epochs
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: completed 100 epochs without stopping early
  fold 3 training message: completed 100 epochs without stopping early
  fold 4 training message: stopped training due to stagnating improvement on validation
    loss after 35 epochs
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.8421955403087479, 0.8542024013722127, 0.8593481989708405,
    0.8556701030927835]'
  fold_eval_f1: '[0.0, 0.14814814814814814, 0.15841584158415842, 0.18, 0.08695652173913045]'
  mean_eval_accuracy: 0.853809835369843
  mean_f1_accuracy: 0.1147041022942874
  total_train_time: '0:37:16.484220'
