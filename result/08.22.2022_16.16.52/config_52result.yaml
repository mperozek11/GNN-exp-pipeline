config:
  aggregation: mean
  batch_size: 32
  class_weights: false
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.5
  epochs: 100
  hidden_units:
  - 32
  - 32
  - 32
  - 32
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.01
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: false
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-22 17:13:59.551006'
fold_0_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_52fold_0_optim_dict.pt
fold_0_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_52fold_0_state_dict.pt
fold_1_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_52fold_1_optim_dict.pt
fold_1_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_52fold_1_state_dict.pt
fold_2_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_52fold_2_optim_dict.pt
fold_2_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_52fold_2_state_dict.pt
fold_3_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_52fold_3_optim_dict.pt
fold_3_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_52fold_3_state_dict.pt
fold_4_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_52fold_4_optim_dict.pt
fold_4_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_52fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 6.577160507440567
  - 6.565385845303536
  - 6.529250928759575
  - 6.235942289233208
  - 6.253597213327885
  - 6.45726661682129
  - 6.384125530719757
  - 6.211600914597511
  - 6.2516406118869785
  - 6.099412894248963
  - 6.133488222956657
  - 6.111449310183525
  - 6.243816259503365
  - 6.171229356527329
  - 6.043066099286079
  - 6.0739635825157166
  - 6.10237492620945
  - 5.93279311656952
  validation_losses:
  - 0.40484997630119324
  - 0.6549700498580933
  - 0.4067157804965973
  - 0.4084281623363495
  - 0.42340347170829773
  - 0.6002235412597656
  - 0.39900970458984375
  - 0.393943727016449
  - 0.42773953080177307
  - 0.3873859643936157
  - 0.38801446557044983
  - 0.45833608508110046
  - 0.4109531342983246
  - 0.40389716625213623
  - 0.39092394709587097
  - 0.39896804094314575
  - 0.3899917006492615
  - 0.39644932746887207
loss_records_fold1:
  train_losses:
  - 6.101329517364502
  - 5.9772921979427345
  - 6.011418372392654
  - 6.034655469655991
  - 5.980746948719025
  - 6.102107647061349
  - 5.924783235788346
  - 6.375592914223671
  - 5.9859744846820835
  - 5.896450939774514
  - 5.996220892667771
  validation_losses:
  - 0.3944664001464844
  - 0.39194953441619873
  - 0.3950388431549072
  - 0.39640310406684875
  - 0.3948092460632324
  - 0.3918851912021637
  - 0.3960602879524231
  - 0.3968992829322815
  - 0.3997710347175598
  - 0.3905361294746399
  - 0.3968375027179718
loss_records_fold2:
  train_losses:
  - 5.9628123372793205
  - 6.112264543771744
  - 5.990852510929108
  - 5.940223920345307
  - 5.901474177837372
  - 6.103190803527832
  - 5.9273925781250005
  - 5.945384481549263
  - 5.90558879673481
  - 5.9355532258749015
  - 6.126623383164406
  - 6.083865839242936
  - 5.943893030285835
  - 5.937127646803856
  - 5.935537055134773
  - 5.950504535436631
  - 5.845766419172287
  - 6.099215713143349
  - 5.827048000693321
  - 5.912107861042023
  - 6.073799678683281
  - 5.918849742412568
  - 5.927183115482331
  - 5.966655132174492
  - 5.871809050440788
  - 5.932771828770638
  validation_losses:
  - 0.42010509967803955
  - 0.40249159932136536
  - 0.3936502933502197
  - 0.3909176290035248
  - 0.3907416760921478
  - 0.3992987275123596
  - 0.39361700415611267
  - 0.38178372383117676
  - 0.39833465218544006
  - 0.4484998881816864
  - 0.40904298424720764
  - 2.426943778991699
  - 0.5284581184387207
  - 0.3919137716293335
  - 2.0421416759490967
  - 0.4039335548877716
  - 0.3912092447280884
  - 0.40691912174224854
  - 0.38655993342399597
  - 0.40447157621383667
  - 0.3927009403705597
  - 0.39592963457107544
  - 0.3939395844936371
  - 0.3892769515514374
  - 0.3951098918914795
  - 0.39486417174339294
loss_records_fold3:
  train_losses:
  - 6.0220584064722065
  - 5.964109045267105
  - 6.061005717515946
  - 6.058776009082795
  - 6.100209575891495
  - 6.036886835098267
  - 5.84614554643631
  - 5.987303221225739
  - 6.033761033415795
  - 6.001687872409821
  - 5.918936493992806
  - 5.8252383261919025
  - 6.0639309108257295
  - 5.9746005773544315
  - 5.956059285998345
  validation_losses:
  - 0.3747105002403259
  - 0.3863762617111206
  - 0.3778234124183655
  - 0.3804168999195099
  - 0.3781881332397461
  - 0.39343199133872986
  - 0.3958796262741089
  - 0.3748098611831665
  - 0.389737069606781
  - 0.38379546999931335
  - 0.3776719868183136
  - 0.3790505528450012
  - 0.37528717517852783
  - 0.3778592050075531
  - 0.37394991517066956
loss_records_fold4:
  train_losses:
  - 6.016016358137131
  - 5.989322662353516
  - 5.851443108916283
  - 5.89858168065548
  - 6.003523746132851
  - 6.092811286449432
  - 5.918037021160126
  - 6.108093750476837
  - 5.867061740159989
  - 6.031809797883034
  - 5.96465212404728
  - 5.979714995622635
  - 5.79993389248848
  - 5.9819132626056675
  - 5.889430072903633
  - 5.9195824563503265
  - 6.083498924970627
  - 5.896636039018631
  - 6.047162550687791
  validation_losses:
  - 0.39485204219818115
  - 0.3792523443698883
  - 0.37556907534599304
  - 0.38016918301582336
  - 0.40616270899772644
  - 0.3791039288043976
  - 0.3898053467273712
  - 0.3811768889427185
  - 0.4045298397541046
  - 0.3827560842037201
  - 0.3875240981578827
  - 0.38127660751342773
  - 0.39553630352020264
  - 0.38778871297836304
  - 0.39329004287719727
  - 0.38975852727890015
  - 0.38553380966186523
  - 0.39105188846588135
  - 0.37687191367149353
training fold messages:
  fold 0 training message: stopped training due to stagnating improvement on validation
    loss after 18 epochs
  fold 1 training message: stopped training due to stagnating improvement on validation
    loss after 11 epochs
  fold 2 training message: stopped training due to stagnating improvement on validation
    loss after 26 epochs
  fold 3 training message: stopped training due to stagnating improvement on validation
    loss after 15 epochs
  fold 4 training message: stopped training due to stagnating improvement on validation
    loss after 19 epochs
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.8576329331046312, 0.8593481989708405, 0.8593481989708405,
    0.8591065292096219]'
  fold_eval_f1: '[0.0, 0.0, 0.0, 0.0, 0.0]'
  mean_eval_accuracy: 0.858613758672113
  mean_f1_accuracy: 0.0
  total_train_time: '0:09:26.219880'
