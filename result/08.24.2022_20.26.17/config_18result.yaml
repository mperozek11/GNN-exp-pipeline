config:
  aggregation: mean
  batch_size: 128
  class_weights: true
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.0
  epochs: 100
  hidden_units:
  - 32
  - 32
  - 32
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.01
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: false
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-24 20:49:07.248617'
fold_0_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_18fold_0_optim_dict.pt
fold_0_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_18fold_0_state_dict.pt
fold_1_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_18fold_1_optim_dict.pt
fold_1_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_18fold_1_state_dict.pt
fold_2_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_18fold_2_optim_dict.pt
fold_2_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_18fold_2_state_dict.pt
fold_3_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_18fold_3_optim_dict.pt
fold_3_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_18fold_3_state_dict.pt
fold_4_optim_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_18fold_4_optim_dict.pt
fold_4_state_dict: GNN-exp-pipeline/result/08.24.2022_20.26.17/config_18fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 1.779270362854004
  - 1.5278199315071106
  - 1.512162208557129
  - 1.516967409849167
  - 1.5380360603332521
  - 1.4919570803642275
  - 1.479847151041031
  - 1.5131295323371887
  - 1.466349655389786
  - 1.4539203166961672
  - 1.442306709289551
  - 1.4467030704021455
  - 1.47641339302063
  - 1.4571034908294678
  - 1.4830338835716248
  - 1.4617087781429292
  - 1.4509172886610031
  - 1.4315474510192872
  - 1.4271067321300508
  - 1.4313065052032472
  - 1.4592000782489778
  - 1.4398800492286683
  - 1.4502509891986848
  - 1.4766884446144104
  - 1.4907956004142762
  - 1.46971093416214
  - 1.477050018310547
  - 1.4908782958984377
  - 1.4520696341991426
  - 1.4231140166521072
  - 1.3898921459913254
  - 1.4434993982315065
  - 1.4378584384918214
  - 1.4375555187463762
  - 1.4443137049674988
  - 1.4241345286369325
  - 1.4541023552417756
  - 1.4524904668331147
  - 1.4191839873790741
  - 1.424925971031189
  - 1.4309271931648255
  - 1.426665884256363
  - 1.4046162068843842
  - 1.4149600863456726
  - 1.430430966615677
  - 1.4114465922117234
  - 1.4275498270988465
  - 1.3866779804229736
  - 1.425770288705826
  - 1.4025550067424775
  - 1.4285632193088533
  - 1.400222408771515
  - 1.375613194704056
  - 1.3875673532485964
  - 1.4594000279903412
  - 1.4190698206424714
  - 1.4147247970104218
  - 1.3844307303428651
  - 1.394554251432419
  - 1.3692905336618424
  - 1.4492673814296724
  - 1.417506390810013
  - 1.3887690991163255
  - 1.4052260637283327
  - 1.405644339323044
  - 1.414101552963257
  - 1.405624431371689
  - 1.4192539751529694
  - 1.4452562510967255
  - 1.427030211687088
  - 1.4399653255939484
  - 1.4556437313556672
  - 1.4209224343299867
  - 1.433122915029526
  - 1.3955236017704011
  - 1.3923776209354402
  - 1.3601255148649216
  - 1.3878520876169205
  - 1.3840436577796937
  - 1.3957558810710908
  - 1.3781470984220505
  - 1.3578449428081514
  - 1.4425289750099184
  - 1.3994857251644135
  - 1.3952406883239747
  - 1.5094367980957033
  - 1.4514037251472474
  - 1.407334589958191
  - 1.404416310787201
  - 1.4113817274570466
  - 1.3763870894908905
  - 1.3991847574710847
  - 1.3810903847217562
  - 1.3954274356365204
  - 1.3871985912323
  - 1.3743729293346405
  - 1.3810683965682984
  - 1.3553958982229233
  - 1.3818450510501863
  - 1.407366156578064
  validation_losses:
  - 0.4789173901081085
  - 0.4217161536216736
  - 0.4291894733905792
  - 0.40481725335121155
  - 0.39684584736824036
  - 0.41706323623657227
  - 0.41134172677993774
  - 0.38765639066696167
  - 0.3910331130027771
  - 0.3846089839935303
  - 0.37971755862236023
  - 0.4040645360946655
  - 0.3909148573875427
  - 0.3818601965904236
  - 0.4011712372303009
  - 0.381395548582077
  - 0.40118491649627686
  - 0.3813612163066864
  - 0.3814195990562439
  - 0.4185817241668701
  - 0.45555511116981506
  - 0.3849012851715088
  - 0.4010944664478302
  - 0.3779425621032715
  - 0.3766656517982483
  - 0.40331801772117615
  - 0.42461568117141724
  - 0.3927895724773407
  - 0.5419385433197021
  - 0.4261819124221802
  - 0.3818838894367218
  - 0.4059104323387146
  - 0.4143059551715851
  - 0.4523954689502716
  - 0.4420338273048401
  - 0.3729812204837799
  - 0.4541555345058441
  - 0.4785621762275696
  - 0.3747932016849518
  - 0.39889395236968994
  - 0.3951696753501892
  - 0.3901131749153137
  - 0.42230454087257385
  - 0.7281433343887329
  - 0.383786678314209
  - 0.3782960772514343
  - 0.3776886761188507
  - 0.449882835149765
  - 0.3844531774520874
  - 0.39306527376174927
  - 0.3823373019695282
  - 0.411587119102478
  - 0.37959006428718567
  - 0.38872331380844116
  - 0.45416638255119324
  - 0.4486595392227173
  - 0.5098518133163452
  - 0.6065212488174438
  - 0.42768654227256775
  - 0.5094950795173645
  - 0.41063782572746277
  - 0.3817252814769745
  - 0.40870267152786255
  - 0.45748886466026306
  - 0.4428548216819763
  - 0.463811457157135
  - 0.49082013964653015
  - 0.41381576657295227
  - 0.49923813343048096
  - 0.4157106280326843
  - 0.4032629132270813
  - 0.3837801516056061
  - 0.4576238691806793
  - 0.44968485832214355
  - 0.4095616042613983
  - 0.4045860469341278
  - 0.4221029281616211
  - 0.41120585799217224
  - 0.7465042471885681
  - 2.2418484687805176
  - 0.7477512955665588
  - 0.5622336268424988
  - 0.9399977326393127
  - 1.5560309886932373
  - 0.5101006627082825
  - 0.3907361924648285
  - 0.3881393373012543
  - 0.40693676471710205
  - 0.4612029492855072
  - 0.40247079730033875
  - 0.47161635756492615
  - 0.463992714881897
  - 0.5998796224594116
  - 0.7483740448951721
  - 0.4414237439632416
  - 0.48396429419517517
  - 0.7220737934112549
  - 0.7322292327880859
  - 1.2723156213760376
  - 0.4065355062484741
loss_records_fold1:
  train_losses:
  - 1.3907188534736634
  - 1.4004312932491303
  - 1.4418215066194535
  - 1.3960457265377046
  - 1.3921132504940035
  - 1.4078171372413637
  - 1.407447725534439
  - 1.3944154620170595
  - 1.3684758692979813
  - 1.3651684433221818
  - 1.3733178645372393
  - 1.464065957069397
  - 1.3631381899118424
  - 1.4104747533798219
  - 1.4456830203533173
  - 1.355489754676819
  - 1.3810975790023805
  - 1.3941003262996674
  - 1.349178320169449
  - 1.375132215023041
  - 1.3434418201446534
  - 1.3722151786088945
  - 1.396389389038086
  - 1.3604117512702942
  - 1.3882751107215883
  - 1.3487619936466217
  - 1.3886339187622072
  - 1.4183298408985139
  - 1.4070603072643282
  - 1.3582622468471528
  - 1.3566421866416931
  - 1.3799535453319551
  - 1.401878359913826
  - 1.374819701910019
  - 1.4018977284431458
  - 1.3683855652809145
  - 1.3698481678962708
  - 1.4050699293613436
  - 1.4245370924472809
  - 1.372151392698288
  - 1.3568317711353304
  - 1.414246529340744
  - 1.3760848462581636
  - 1.3572284609079361
  - 1.4107110619544985
  - 1.370767503976822
  - 1.3641047656536103
  - 1.4152419567108154
  - 1.3542098999023438
  - 1.3257168412208558
  - 1.4058794736862184
  - 1.435742348432541
  - 1.4027411818504334
  - 1.4030874371528625
  - 1.3632594794034958
  - 1.3914460003376008
  - 1.430594438314438
  - 1.4269612073898317
  - 1.4521146595478058
  - 1.3489394426345827
  - 1.364572024345398
  - 1.356570065021515
  - 1.4122656792402268
  - 1.3578146398067474
  - 1.387647730112076
  - 1.4082343995571138
  - 1.3728223979473115
  - 1.429058986902237
  - 1.3701161921024323
  - 1.3668275296688082
  - 1.3464556336402893
  - 1.3288638323545456
  - 1.3406941056251527
  - 1.3405342221260073
  - 1.3590289056301117
  - 1.3551969468593599
  - 1.3247239261865618
  - 1.3816694796085358
  - 1.3628993034362793
  - 1.3400215923786165
  - 1.3748973608016968
  - 1.3483873575925829
  - 1.3627990722656251
  - 1.336207389831543
  - 1.336143308877945
  - 1.3355040192604066
  - 1.356111389398575
  - 1.3541710793972017
  - 1.3492471218109132
  - 1.3687220215797424
  - 1.334383898973465
  - 1.3435363113880159
  - 1.3497732877731323
  - 1.3247221291065217
  - 1.3535765022039414
  - 1.373151993751526
  - 1.3419587135314943
  - 1.3558365672826769
  - 1.3987278640270233
  - 1.3993834972381594
  validation_losses:
  - 0.49780526757240295
  - 0.4976143538951874
  - 1.4749829769134521
  - 1.0342912673950195
  - 0.8819591999053955
  - 0.6098557114601135
  - 0.5574460625648499
  - 0.8677040338516235
  - 0.5701985955238342
  - 0.5994355082511902
  - 0.3884143829345703
  - 0.5024600028991699
  - 0.5922567844390869
  - 0.39450252056121826
  - 0.5037077069282532
  - 0.5051653981208801
  - 0.6240034699440002
  - 0.8514128923416138
  - 0.6250261664390564
  - 0.6473534107208252
  - 1.339429497718811
  - 1.0227305889129639
  - 0.9905464053153992
  - 0.5501243472099304
  - 0.9451504349708557
  - 0.9259347319602966
  - 0.37569329142570496
  - 0.43228620290756226
  - 0.5388270616531372
  - 0.4245327413082123
  - 0.5636144280433655
  - 0.490618497133255
  - 0.6069483757019043
  - 0.8305431604385376
  - 0.5424784421920776
  - 0.5422055125236511
  - 0.6272466778755188
  - 0.5688292384147644
  - 0.5677135586738586
  - 0.6975271701812744
  - 0.7973239421844482
  - 0.49017760157585144
  - 0.3726159930229187
  - 0.38111740350723267
  - 0.5312596559524536
  - 0.5642357468605042
  - 0.5339276194572449
  - 0.5636791586875916
  - 0.6369286775588989
  - 0.6445565223693848
  - 0.9299693703651428
  - 0.9941276907920837
  - 0.43961331248283386
  - 0.9493816494941711
  - 1.0837405920028687
  - 1.5929794311523438
  - 0.895656168460846
  - 0.6564803123474121
  - 0.45475873351097107
  - 0.52939772605896
  - 0.7886720895767212
  - 0.6332584619522095
  - 0.6433522701263428
  - 0.5097512006759644
  - 0.5175857543945312
  - 0.5992186069488525
  - 0.5719423294067383
  - 0.5594007968902588
  - 0.44124263525009155
  - 0.5235212445259094
  - 0.553320586681366
  - 0.6034635305404663
  - 0.7234727144241333
  - 0.7576133012771606
  - 0.6839697360992432
  - 0.400779664516449
  - 0.5547268390655518
  - 0.7319189310073853
  - 0.7163950800895691
  - 0.6969304084777832
  - 0.876147449016571
  - 0.9792903661727905
  - 0.6753984093666077
  - 0.6492709517478943
  - 0.7145655751228333
  - 0.5948938727378845
  - 0.6022894978523254
  - 0.743621289730072
  - 0.426408588886261
  - 0.4251026213169098
  - 0.6326326131820679
  - 0.7264670729637146
  - 0.6149317026138306
  - 0.803551971912384
  - 0.7698384523391724
  - 0.7847973704338074
  - 0.86646568775177
  - 0.3969595730304718
  - 0.6558631658554077
  - 0.6354172229766846
loss_records_fold2:
  train_losses:
  - 1.4229388356208803
  - 1.3346705168485642
  - 1.3962002277374268
  - 1.3778671681880952
  - 1.3784145891666413
  - 1.3609851360321046
  - 1.3582013189792634
  - 1.3635371446609499
  - 1.3505977988243103
  - 1.3456233680248262
  - 1.316789996623993
  - 1.3616303384304047
  - 1.363840937614441
  - 1.3296011984348297
  - 1.3331625759601593
  - 1.3179334223270418
  - 1.3050761312246324
  - 1.3453082621097565
  - 1.3342664361000063
  - 1.4148912310600281
  - 1.380060011148453
  - 1.335691213607788
  - 1.3100450038909912
  - 1.2983573436737061
  - 1.3806760132312776
  - 1.3775784611701967
  - 1.3867618560791017
  - 1.3388831049203873
  - 1.3225034296512606
  - 1.318411296606064
  - 1.3674267113208771
  - 1.3157171547412874
  - 1.340242785215378
  - 1.304507386684418
  - 1.3571665346622468
  - 1.3466592490673066
  - 1.317867735028267
  - 1.3366003453731539
  - 1.2975329101085664
  - 1.3246890008449554
  - 1.2922612011432648
  - 1.3324872374534609
  - 1.3093361496925355
  - 1.2998403847217561
  - 1.2963103652000427
  - 1.2677436441183092
  - 1.2789351403713227
  - 1.3012632310390473
  - 1.2721752762794496
  - 1.2724909216165543
  - 1.2941729068756105
  - 1.3081238567829132
  - 1.3263243198394776
  - 1.28417067527771
  - 1.295055514574051
  - 1.3207085967063905
  - 1.3593791961669923
  - 1.4675589203834534
  - 1.3553628504276276
  - 1.2689926832914353
  - 1.291174477338791
  - 1.2934194386005402
  - 1.2995145201683045
  - 1.306549221277237
  - 1.2910052001476289
  - 1.2554588556289674
  - 1.3566836893558503
  - 1.2861312091350556
  - 1.326270180940628
  - 1.3758344590663911
  - 1.35734743475914
  - 1.3451981186866762
  - 1.2955383479595186
  - 1.3101816177368164
  - 1.2806980788707734
  - 1.344350850582123
  - 1.3011964440345765
  - 1.3108303725719452
  - 1.2976527631282808
  - 1.274638682603836
  - 1.321521556377411
  - 1.2919217646121979
  - 1.2734186410903932
  - 1.285211193561554
  - 1.259925726056099
  - 1.2750825762748719
  - 1.2813014447689057
  - 1.340120053291321
  - 1.3786311745643616
  - 1.3175998747348787
  - 1.2940981924533845
  - 1.3460782945156098
  - 1.6684810817241669
  - 1.5565978050231934
  - 1.4863697350025178
  - 1.51282477080822
  - 1.4527184993028641
  - 1.4565929472446442
  - 1.4401780009269716
  - 1.4869446575641634
  validation_losses:
  - 0.9338912963867188
  - 0.5444852113723755
  - 0.8252334594726562
  - 0.7625724673271179
  - 0.5347747802734375
  - 0.3882971405982971
  - 0.462963342666626
  - 0.5495397448539734
  - 0.5374273657798767
  - 0.5010641813278198
  - 0.5327256321907043
  - 0.553615152835846
  - 0.4773740768432617
  - 0.45041537284851074
  - 0.5030525922775269
  - 0.579422652721405
  - 0.5528187155723572
  - 0.5357558727264404
  - 0.5152710676193237
  - 0.5536665916442871
  - 0.5180654525756836
  - 0.4377795457839966
  - 0.4665280878543854
  - 0.5336554646492004
  - 0.5563735365867615
  - 1.0744177103042603
  - 0.4475829601287842
  - 0.47228869795799255
  - 0.6262028813362122
  - 0.5641909837722778
  - 0.6931362748146057
  - 0.6224310994148254
  - 0.571269690990448
  - 0.47579461336135864
  - 0.4893485903739929
  - 0.549383819103241
  - 0.5071913599967957
  - 0.517147421836853
  - 0.5771812200546265
  - 0.6059647798538208
  - 0.5144720673561096
  - 0.5457701086997986
  - 0.4486556649208069
  - 0.471861332654953
  - 0.5116527676582336
  - 0.566386878490448
  - 0.49016812443733215
  - 0.491777241230011
  - 0.5659887790679932
  - 0.5734307765960693
  - 0.4960648715496063
  - 0.43638351559638977
  - 0.5037736296653748
  - 0.4604147970676422
  - 0.5593345761299133
  - 0.6422728896141052
  - 0.6169214844703674
  - 0.49596917629241943
  - 0.4344472587108612
  - 0.42448970675468445
  - 0.5250691175460815
  - 0.5750123262405396
  - 0.7870861291885376
  - 0.6709104776382446
  - 0.5466016530990601
  - 0.5630155205726624
  - 0.5847901701927185
  - 1.0669653415679932
  - 0.8679753541946411
  - 0.9561174511909485
  - 1.419281005859375
  - 0.9247793555259705
  - 0.5915716886520386
  - 0.5974401831626892
  - 0.6233274340629578
  - 0.6518751978874207
  - 0.5028061270713806
  - 0.535384476184845
  - 0.5663008689880371
  - 0.6360028982162476
  - 0.5334469079971313
  - 0.7168344855308533
  - 0.9768916964530945
  - 0.6323660612106323
  - 0.5661925673484802
  - 0.4557645916938782
  - 0.5226110816001892
  - 0.6508752703666687
  - 0.624191403388977
  - 0.8732684254646301
  - 0.444936603307724
  - 1.6347955465316772
  - 1.153168797492981
  - 0.4502051770687103
  - 0.39931267499923706
  - 0.6237358450889587
  - 0.5773215293884277
  - 0.45939964056015015
  - 0.5436718463897705
  - 0.5229187607765198
loss_records_fold3:
  train_losses:
  - 1.4710107326507569
  - 1.4898853480815888
  - 1.4162380576133728
  - 1.4356612265110016
  - 1.4376409828662873
  - 1.4415312826633455
  - 1.4264309287071228
  - 1.420897048711777
  - 1.4590898156166077
  - 1.395828640460968
  - 1.4288553655147553
  - 1.4665649473667146
  - 1.3764200776815416
  - 1.4367962539196015
  - 1.3779662221670153
  - 1.4311768352985383
  - 1.4468435466289522
  - 1.405164968967438
  - 1.4468546688556672
  - 1.4722313821315767
  - 1.3892187356948853
  - 1.3972546637058259
  - 1.4147535562515259
  - 1.3906536102294922
  - 1.4731525480747223
  - 1.4542297422885895
  - 1.4563206911087037
  - 1.5243235588073731
  - 1.4929925560951234
  - 1.4701344966888428
  - 1.475799721479416
  - 1.4990488529205324
  - 1.4722278118133545
  - 1.4606248676776887
  - 1.4789718687534332
  - 1.4397107422351838
  - 1.4505844533443453
  - 1.468027576804161
  - 1.4384732484817506
  - 1.4272187471389772
  - 1.4283196389675141
  - 1.4089120209217072
  - 1.44632448554039
  - 1.448882830142975
  - 1.423798030614853
  - 1.4262259244918825
  - 1.4498093634843827
  - 1.3908019214868546
  - 1.4300949394702913
  - 1.4784893572330475
  - 1.4034871578216555
  - 1.437166053056717
  - 1.4048660397529602
  - 1.419053101539612
  - 1.4022004872560503
  - 1.4047480821609497
  - 1.3817665159702301
  - 1.3685788959264755
  - 1.4204298973083498
  - 1.4275433778762818
  - 1.413570111989975
  - 1.402503675222397
  - 1.4080582380294802
  - 1.4404883980751038
  - 1.4644056022167207
  - 1.402529376745224
  - 1.3677875101566315
  - 1.424550247192383
  - 1.3825169563293458
  - 1.4220337986946108
  - 1.3775789320468903
  - 1.4422098577022553
  - 1.4099612534046173
  - 1.3731162250041962
  - 1.4028015971183778
  - 1.4152489364147187
  - 1.4064686834812166
  - 1.4133116781711579
  - 1.3546630054712296
  - 1.4342065393924714
  - 1.439177566766739
  - 1.390915709733963
  - 1.3593598097562791
  - 1.392626625299454
  - 1.4045801341533661
  - 1.3795546412467958
  - 1.4307681322097778
  - 1.3637250483036043
  - 1.3982379555702211
  - 1.3822573244571688
  - 1.3766440749168396
  - 1.4089705586433412
  - 1.3623219788074494
  - 1.38828963637352
  - 1.3929903447628023
  - 1.4136333823204041
  - 1.3933718621730806
  - 1.3638804078102114
  - 1.3575447142124177
  - 1.368567317724228
  validation_losses:
  - 0.4686327576637268
  - 0.5108124613761902
  - 0.6956639885902405
  - 0.5015765428543091
  - 0.5043018460273743
  - 0.48515599966049194
  - 0.41175374388694763
  - 0.537280261516571
  - 0.4568553864955902
  - 0.7418302297592163
  - 0.37428006529808044
  - 0.41753557324409485
  - 0.5983335971832275
  - 0.4801621735095978
  - 0.5231665372848511
  - 0.6182138919830322
  - 0.5658408403396606
  - 0.3842909038066864
  - 0.4445989429950714
  - 0.48107293248176575
  - 0.5182467103004456
  - 0.6090911030769348
  - 0.6261909008026123
  - 0.5397331714630127
  - 0.6246210932731628
  - 0.6298156380653381
  - 0.4943281412124634
  - 0.39737406373023987
  - 0.40359917283058167
  - 0.37022721767425537
  - 0.4073277711868286
  - 0.3987424373626709
  - 0.3885597586631775
  - 0.3864099979400635
  - 0.3960326313972473
  - 0.37990322709083557
  - 0.4090407192707062
  - 0.3835891783237457
  - 0.3999577760696411
  - 0.42339324951171875
  - 0.3983383774757385
  - 0.4658752381801605
  - 0.38914868235588074
  - 0.4448849558830261
  - 0.5063785314559937
  - 0.4591743052005768
  - 0.41382652521133423
  - 0.6420949697494507
  - 0.8785794377326965
  - 0.5226262807846069
  - 0.41002723574638367
  - 0.4242386817932129
  - 0.5189595818519592
  - 0.5179253220558167
  - 0.5053783655166626
  - 0.5275506377220154
  - 0.47258010506629944
  - 0.45628270506858826
  - 0.45036157965660095
  - 0.45984265208244324
  - 0.5162754654884338
  - 0.420833557844162
  - 0.5882030129432678
  - 0.6437104940414429
  - 0.49479594826698303
  - 0.3861672580242157
  - 0.47892382740974426
  - 0.4335174560546875
  - 0.37715944647789
  - 0.6746211051940918
  - 0.7231336832046509
  - 1.0267128944396973
  - 0.6863077878952026
  - 0.657534658908844
  - 0.6718529462814331
  - 0.6549198031425476
  - 0.43473342061042786
  - 0.4550624191761017
  - 0.3985079824924469
  - 0.6108508110046387
  - 0.49217045307159424
  - 0.5066691637039185
  - 0.6625711917877197
  - 0.49822235107421875
  - 0.6432074308395386
  - 0.4387843906879425
  - 0.6428996324539185
  - 0.5087919235229492
  - 0.5607602596282959
  - 0.474625825881958
  - 0.5645666122436523
  - 0.6200939416885376
  - 0.5606542825698853
  - 0.6281043291091919
  - 0.6933565139770508
  - 0.8560245037078857
  - 0.45367735624313354
  - 0.4802805185317993
  - 0.4470609128475189
  - 0.5728304386138916
loss_records_fold4:
  train_losses:
  - 1.3581513226032258
  - 1.3303628057241441
  - 1.457871761918068
  - 1.4548472166061401
  - 1.3897951245307922
  - 1.3819990158081055
  - 1.379200977087021
  - 1.383661037683487
  - 1.3897006213665009
  - 1.4138564050197602
  - 1.3725726902484894
  - 1.433316171169281
  - 1.3809130907058718
  - 1.3562394201755525
  - 1.3982983469963075
  - 1.371679586172104
  - 1.3733068466186524
  - 1.350993412733078
  - 1.3507317662239076
  - 1.3558260321617128
  - 1.364270704984665
  - 1.386673277616501
  - 1.3804609298706056
  - 1.3467329800128938
  - 1.3417781531810762
  - 1.3555862665176392
  - 1.3084771752357485
  - 1.36857328414917
  - 1.3072764873504639
  - 1.3501284420490265
  - 1.336339944601059
  - 1.344365045428276
  - 1.3898196637630464
  - 1.352755630016327
  - 1.3706514060497286
  - 1.3434423595666887
  - 1.3646127104759218
  - 1.4017566978931428
  - 1.350151562690735
  - 1.3640952587127686
  - 1.3679809510707857
  - 1.318212404847145
  - 1.3554869592189789
  - 1.339758813381195
  - 1.3380692541599275
  - 1.2932086735963821
  - 1.329278963804245
  - 1.3387469112873078
  - 1.3309160470962524
  - 1.363924038410187
  - 1.327865329384804
  - 1.350267016887665
  - 1.3389057457447053
  - 1.3676821172237397
  - 1.3909097850322725
  - 1.373960018157959
  - 1.3829153537750245
  - 1.3354469180107118
  - 1.3724088668823242
  - 1.3316350698471071
  - 1.328154295682907
  - 1.3156630605459214
  - 1.3720342516899109
  - 1.3711469620466232
  - 1.334975677728653
  - 1.3289760172367098
  - 1.3584969997406007
  - 1.3880115807056428
  - 1.356164586544037
  - 1.3347680926322938
  - 1.3785544335842133
  - 1.3195141375064852
  - 1.3450918436050416
  - 1.367337852716446
  - 1.329496818780899
  - 1.3056921392679215
  - 1.313663759827614
  - 1.3363737732172014
  - 1.348875278234482
  - 1.3270228981971741
  - 1.3389987409114839
  - 1.3390770137310029
  - 1.2925998687744142
  - 1.3351341098546983
  - 1.3139388740062714
  - 1.2704892754554749
  - 1.3558524787425996
  - 1.2968395054340363
  - 1.3463993310928346
  - 1.3223243355751038
  - 1.4358504056930543
  - 1.3183044850826264
  - 1.3129666298627853
  - 1.351845532655716
  - 1.3349996328353884
  - 1.306845808029175
  - 1.3266970813274384
  - 1.2873965054750443
  - 1.2934674382209779
  - 1.309322714805603
  validation_losses:
  - 0.438169926404953
  - 0.40993157029151917
  - 0.44549497961997986
  - 0.43784332275390625
  - 0.4380619525909424
  - 0.47412896156311035
  - 0.40020281076431274
  - 0.3485577702522278
  - 0.399737149477005
  - 0.4711737334728241
  - 0.4280860722064972
  - 0.4249380826950073
  - 0.39137592911720276
  - 0.4011112153530121
  - 0.565536379814148
  - 0.38620293140411377
  - 0.4233863949775696
  - 0.6194291114807129
  - 0.41136398911476135
  - 0.387807160615921
  - 0.35359516739845276
  - 0.3739318251609802
  - 0.43182653188705444
  - 0.4359501004219055
  - 0.47890380024909973
  - 0.49741774797439575
  - 0.46100983023643494
  - 0.38471999764442444
  - 0.4798271954059601
  - 0.4955601692199707
  - 0.3454815745353699
  - 0.3952025771141052
  - 0.4780398905277252
  - 0.4656270444393158
  - 0.5673388242721558
  - 0.5070640444755554
  - 0.4318789839744568
  - 0.4627613127231598
  - 0.36375531554222107
  - 0.3804739713668823
  - 0.48483359813690186
  - 0.6224964261054993
  - 0.5058320760726929
  - 0.5175104141235352
  - 0.5309085845947266
  - 0.4222531318664551
  - 0.4530847370624542
  - 0.4974666237831116
  - 0.6342155933380127
  - 0.35656362771987915
  - 0.3620195984840393
  - 0.44243085384368896
  - 0.3782801628112793
  - 0.5909804105758667
  - 0.44179055094718933
  - 0.5052063465118408
  - 0.35266998410224915
  - 0.3563375771045685
  - 0.45160531997680664
  - 0.513169527053833
  - 0.4147915244102478
  - 0.42118796706199646
  - 0.638584554195404
  - 0.48214995861053467
  - 0.46116915345191956
  - 0.5411030650138855
  - 0.5259925723075867
  - 0.7232906818389893
  - 0.44741910696029663
  - 0.4520639181137085
  - 0.48046624660491943
  - 0.43180787563323975
  - 0.4673233926296234
  - 0.3987677991390228
  - 0.4603665769100189
  - 0.5137078762054443
  - 0.40668368339538574
  - 0.43487006425857544
  - 0.5148487687110901
  - 0.4977263808250427
  - 0.5079972147941589
  - 0.5429380536079407
  - 0.45074546337127686
  - 0.45281562209129333
  - 0.5523641705513
  - 0.4949699938297272
  - 0.5175870656967163
  - 0.4720480144023895
  - 0.6035391092300415
  - 0.4436335265636444
  - 0.5199503302574158
  - 0.47688913345336914
  - 0.5497235059738159
  - 0.5312409400939941
  - 0.4881740212440491
  - 0.4391408860683441
  - 0.5536729693412781
  - 0.4862498939037323
  - 0.3658977448940277
  - 0.6262648701667786
training fold messages:
  fold 0 training message: completed 100 epochs without stopping early
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: completed 100 epochs without stopping early
  fold 3 training message: completed 100 epochs without stopping early
  fold 4 training message: completed 100 epochs without stopping early
training_metrics:
  fold_eval_accs: '[0.8542024013722127, 0.7478559176672385, 0.8319039451114922, 0.8198970840480274,
    0.7869415807560137]'
  fold_eval_f1: '[0.15841584158415842, 0.23834196891191708, 0.25757575757575757, 0.22222222222222224,
    0.2151898734177215]'
  mean_eval_accuracy: 0.808160185790997
  mean_f1_accuracy: 0.21834913274235537
  total_train_time: '0:42:01.240336'
