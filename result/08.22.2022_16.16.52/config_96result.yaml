config:
  aggregation: mean
  batch_size: 32
  class_weights: false
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.0
  epochs: 100
  hidden_units:
  - 64
  - 64
  - 64
  - 64
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.01
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: true
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-22 18:20:58.549212'
fold_0_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_96fold_0_optim_dict.pt
fold_0_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_96fold_0_state_dict.pt
fold_1_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_96fold_1_optim_dict.pt
fold_1_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_96fold_1_state_dict.pt
fold_2_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_96fold_2_optim_dict.pt
fold_2_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_96fold_2_state_dict.pt
fold_3_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_96fold_3_optim_dict.pt
fold_3_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_96fold_3_state_dict.pt
fold_4_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_96fold_4_optim_dict.pt
fold_4_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_96fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 6.518633341789246
  - 6.064042189717293
  - 6.102966281771661
  - 6.298082539439202
  - 6.037194558978081
  - 5.726734259724617
  - 5.825886535644532
  - 5.753762355446816
  - 5.849781438708305
  - 5.901268899440765
  - 5.7016022354364395
  - 5.753709724545479
  - 5.714301937818528
  - 5.59891620874405
  - 5.634805428981782
  - 5.63406919836998
  - 5.633119383454323
  - 5.663727056980133
  - 5.605945828557015
  - 5.620569589734078
  - 5.65634486079216
  - 5.664021295309067
  - 5.737076875567436
  - 5.627480053901673
  - 5.6088749229907995
  - 5.694299980998039
  - 5.600517445802689
  - 5.635318878293038
  - 5.644062396883965
  - 5.5785881102085115
  - 5.6104103356599815
  - 5.688769659399987
  - 5.601084831357003
  - 5.615293842554093
  - 5.657732003927231
  - 5.601022082567216
  - 5.533596703410149
  - 5.581876364350319
  - 5.57687820494175
  - 5.578482073545456
  - 5.61749692261219
  - 5.625346693396569
  - 5.54111205637455
  - 5.63324303328991
  - 5.585605263710022
  - 5.607427087426186
  validation_losses:
  - 0.39845341444015503
  - 0.4439624547958374
  - 0.4019968509674072
  - 0.39963391423225403
  - 0.3896491825580597
  - 0.3873213529586792
  - 0.3895013630390167
  - 0.3872995972633362
  - 0.3857470154762268
  - 0.39103126525878906
  - 0.4329838752746582
  - 0.3868134021759033
  - 0.3884526491165161
  - 0.3872416019439697
  - 0.38472089171409607
  - 0.385525107383728
  - 0.4021000266075134
  - 0.42423364520072937
  - 0.392240971326828
  - 0.39082369208335876
  - 0.4027423858642578
  - 0.40732690691947937
  - 0.38855457305908203
  - 0.5840218663215637
  - 0.43203455209732056
  - 0.39910590648651123
  - 1.096268653869629
  - 0.41710522770881653
  - 0.40648022294044495
  - 4.881889343261719
  - 0.4394310414791107
  - 0.40112531185150146
  - 0.43511122465133667
  - 0.4022420644760132
  - 0.41390860080718994
  - 6.502444744110107
  - 0.5184805989265442
  - 0.3942513167858124
  - 0.3884260654449463
  - 0.4221855401992798
  - 0.41243666410446167
  - 0.4142645001411438
  - 0.39321109652519226
  - 0.39138954877853394
  - 0.39643052220344543
  - 0.3877476453781128
loss_records_fold1:
  train_losses:
  - 5.5629132956266405
  - 5.563169690966607
  - 5.582471096515656
  - 5.606143721938134
  - 5.580194783210755
  - 5.630085417628289
  - 5.62458046078682
  - 5.620080238580704
  - 5.570439279079437
  - 5.5348125487566
  - 5.585917231440544
  - 5.545086202025414
  - 5.6144850045442585
  - 5.636681836843491
  - 5.6014564961195
  - 5.576331400871277
  - 5.617719933390617
  - 5.5457380503416065
  - 5.58974458873272
  - 5.575492930412293
  - 5.6385034978389745
  - 5.5827093988657
  - 5.607334488630295
  - 5.596909904479981
  - 5.5848012387752535
  - 5.608704939484596
  - 5.592323291301728
  - 5.510166528820992
  - 5.611753304302693
  - 5.5149515032768255
  - 5.605150575935841
  - 5.543958783149719
  - 5.510603547096252
  - 5.585557171702385
  - 5.532791358232498
  - 5.577149641513825
  - 5.693714293837548
  - 5.611456590890885
  - 5.5462898343801506
  - 5.555631548166275
  - 5.588747799396515
  - 5.5283218920230865
  - 5.583055841922761
  - 5.609822592139245
  - 5.551353970170021
  - 5.547212100028992
  - 5.522288820147515
  - 5.596627932786942
  - 5.534528160095215
  - 5.509263977408409
  - 5.526127734780312
  - 5.538498559594155
  - 5.53075918853283
  - 5.487314987182618
  - 5.51398491859436
  - 5.480546998977662
  - 5.6012226939201355
  - 5.474050343036652
  - 5.5813813507556915
  - 5.555306190252304
  - 5.533532595634461
  - 5.5605403065681465
  - 5.523669400811196
  - 5.529709258675576
  - 5.483952295780182
  - 5.5468823432922365
  - 5.539848375320435
  - 5.605017083883286
  - 5.6120562821626665
  - 5.523311349749566
  - 5.514334410429001
  - 5.481046843528748
  - 5.525961938500405
  - 5.509711197018624
  - 5.536887457966805
  - 5.496970543265343
  - 5.5283203542232515
  - 5.541703993082047
  - 5.4441516399383545
  - 5.47592810690403
  - 5.516320124268532
  - 5.496610346436501
  - 5.559300509095192
  - 5.47657635807991
  - 5.470577225089073
  - 5.541031387448311
  - 5.487465584278107
  - 5.543037524819375
  - 5.57040111720562
  - 5.514695450663567
  - 5.5452944308519365
  - 5.515498390793801
  - 5.528778436779977
  - 5.528732770681382
  - 5.434547990560532
  - 5.524351674318314
  - 5.489607664942742
  - 5.49404039978981
  - 5.471347561478615
  - 5.524313451349736
  validation_losses:
  - 1.1925256252288818
  - 0.6736776232719421
  - 0.5339412093162537
  - 0.4021000862121582
  - 0.39260366559028625
  - 0.4060393273830414
  - 0.8930333256721497
  - 1.750220775604248
  - 1.2662519216537476
  - 0.9242404103279114
  - 0.6313855648040771
  - 1.9113043546676636
  - 0.7679484486579895
  - 2.72088623046875
  - 0.9632302522659302
  - 0.7213119864463806
  - 0.7241830229759216
  - 1.0410181283950806
  - 3.405447006225586
  - 15.133624076843262
  - 0.9082034826278687
  - 0.7671561241149902
  - 1.0190238952636719
  - 2.664750337600708
  - 1.1372292041778564
  - 0.6762479543685913
  - 0.48638099431991577
  - 1.0443073511123657
  - 0.984387993812561
  - 1.5142863988876343
  - 0.871831476688385
  - 1.1012705564498901
  - 0.7839697003364563
  - 0.4997299015522003
  - 0.7204356789588928
  - 0.6767430901527405
  - 0.49284252524375916
  - 0.6449047327041626
  - 0.657731831073761
  - 0.6254255175590515
  - 0.43715333938598633
  - 0.8169905543327332
  - 0.581943929195404
  - 0.9324185252189636
  - 0.5851199626922607
  - 0.6652026772499084
  - 0.6767975091934204
  - 0.612707793712616
  - 0.6234617829322815
  - 0.5539976954460144
  - 0.39215371012687683
  - 0.3959331214427948
  - 0.3925365209579468
  - 0.6438631415367126
  - 0.5615178942680359
  - 0.5289039611816406
  - 0.45747509598731995
  - 0.7541965842247009
  - 0.5307438373565674
  - 0.5448633432388306
  - 0.550464391708374
  - 0.4215351939201355
  - 0.639550507068634
  - 0.6363296508789062
  - 0.6785092353820801
  - 0.810753583908081
  - 0.7248767614364624
  - 0.649636447429657
  - 0.5692865252494812
  - 0.7605193853378296
  - 0.6644041538238525
  - 0.8211137056350708
  - 0.6919456124305725
  - 0.9685770869255066
  - 0.6939592957496643
  - 0.648047149181366
  - 0.5438231825828552
  - 0.569866418838501
  - 0.7229213714599609
  - 0.6228447556495667
  - 0.7834787964820862
  - 0.6705768704414368
  - 0.815397322177887
  - 0.9533486366271973
  - 0.6223872303962708
  - 0.5769973397254944
  - 0.6421921253204346
  - 0.5088658332824707
  - 0.41957688331604004
  - 0.6974865198135376
  - 0.6131044626235962
  - 0.563717246055603
  - 0.4621935486793518
  - 0.5556390881538391
  - 0.42516928911209106
  - 0.44277217984199524
  - 0.5993713736534119
  - 0.5943651795387268
  - 0.6107791662216187
  - 0.5990288257598877
loss_records_fold2:
  train_losses:
  - 5.601505881547928
  - 5.4928605377674105
  - 5.505740994215012
  - 5.5517424851655965
  - 5.498252043128014
  - 5.522815224528313
  - 5.485676720738411
  - 5.479208925366402
  - 5.476732227206231
  - 5.519437530636788
  - 5.441560298204422
  - 5.388229268789292
  - 5.493744277954102
  - 5.486072063446045
  - 5.47087306380272
  - 5.550810715556145
  - 5.501920369267464
  - 5.466884371638298
  - 5.547293889522553
  - 5.482822388410568
  - 5.487322169542313
  - 5.542323458194733
  - 5.512866860628129
  - 5.427861601114273
  - 5.443812057375908
  - 5.480663648247719
  - 5.508768165111542
  - 5.688235494494439
  - 5.694018173217774
  - 5.569008147716523
  - 5.571167668700219
  - 5.607813069224358
  - 5.509300684928895
  - 5.587291219830513
  - 5.604497501254082
  - 5.7567910104990005
  - 5.677281200885773
  - 5.60044054389
  - 5.5523515254259115
  - 5.459718218445778
  - 5.492883172631264
  - 5.487446159124374
  - 5.477396306395531
  - 5.5503828734159475
  - 5.472338110208511
  - 5.552848611772061
  - 5.499783003330231
  - 5.452090853452683
  - 5.525058269500732
  - 5.53541399538517
  - 5.542772352695465
  - 5.518333101272583
  - 5.52017577290535
  - 5.4835655927658085
  - 5.481942468881607
  - 5.536990758776665
  - 5.523275637626648
  - 5.510407549142838
  - 5.501002389192582
  - 5.522488501667977
  - 5.529369986057282
  - 5.49043071269989
  - 5.540395097434521
  - 5.490880647301674
  - 5.488755095005036
  - 5.469143980741501
  - 5.556513252854348
  - 5.435528481006623
  - 5.54312042593956
  - 5.466147756576539
  - 5.4790537327528
  - 5.462138149142266
  - 5.570726239681244
  - 5.463403484225274
  - 5.466688892245293
  - 5.528145068883896
  - 5.512618935108185
  - 5.452270340919495
  - 5.495639881491662
  - 5.507973369956017
  - 5.476216185092927
  - 5.47864964902401
  - 5.422285118699074
  - 5.470217174291611
  - 5.406148564815521
  - 5.5120747804641725
  - 5.441890823841096
  - 5.42877936065197
  - 5.478264424204827
  - 5.4203234821558
  - 5.434371533989907
  - 5.465295702219009
  - 5.50691685974598
  - 5.48449569940567
  - 5.39410525560379
  - 5.427250969409943
  - 5.439266625046731
  - 5.877902835607529
  - 6.305981463193894
  - 6.060067650675774
  validation_losses:
  - 0.6603506803512573
  - 0.5489419102668762
  - 0.7964991927146912
  - 0.705522358417511
  - 0.44601425528526306
  - 0.3859497010707855
  - 0.508305013179779
  - 0.6271610856056213
  - 0.649610161781311
  - 0.6334773302078247
  - 0.6305239200592041
  - 0.4087905287742615
  - 0.6478337645530701
  - 0.9724552631378174
  - 0.8240952491760254
  - 1.364450216293335
  - 0.419138103723526
  - 0.3892449736595154
  - 1.1518592834472656
  - 2.264136791229248
  - 1.6964702606201172
  - 1.127272605895996
  - 0.5639069676399231
  - 1.0501861572265625
  - 1.1856975555419922
  - 1.0705180168151855
  - 0.6846497654914856
  - 0.49027588963508606
  - 0.8701499700546265
  - 0.38693538308143616
  - 0.4131576120853424
  - 0.4384187161922455
  - 0.6485648155212402
  - 0.5534940361976624
  - 0.5711575150489807
  - 0.4508698582649231
  - 0.5886439085006714
  - 0.5117570757865906
  - 0.5984074473381042
  - 0.9510695338249207
  - 1.2048832178115845
  - 0.3948281407356262
  - 0.39357101917266846
  - 4.515825271606445
  - 0.39583727717399597
  - 0.4420020580291748
  - 0.39334526658058167
  - 0.39414551854133606
  - 0.39675378799438477
  - 0.5457727909088135
  - 0.7902392148971558
  - 0.9058471918106079
  - 0.9369386434555054
  - 1.4054055213928223
  - 1.54246187210083
  - 2.024346351623535
  - 2.5661892890930176
  - 3.105654001235962
  - 0.39790382981300354
  - 0.39776769280433655
  - 0.466194748878479
  - 6.381990909576416
  - 0.40034419298171997
  - 0.3943158984184265
  - 0.5611376762390137
  - 0.41536256670951843
  - 0.9683599472045898
  - 7.730616569519043
  - 5.038785457611084
  - 5.595189094543457
  - 8.354635238647461
  - 7.627405643463135
  - 4.399750232696533
  - 8.717269897460938
  - 6.486671447753906
  - 0.43843236565589905
  - 9.254251480102539
  - 6.305419445037842
  - 2.0333986282348633
  - 2.3123292922973633
  - 5.336631774902344
  - 3.6639089584350586
  - 8.307333946228027
  - 5.712779998779297
  - 5.1165571212768555
  - 3.819382429122925
  - 9.68371868133545
  - 5.731635570526123
  - 8.594627380371094
  - 7.616457462310791
  - 24.532705307006836
  - 4.2211012840271
  - 6.804337024688721
  - 4.994010925292969
  - 3.211106300354004
  - 7.186767578125
  - 8.86929988861084
  - 0.4547053277492523
  - 0.433123379945755
  - 0.6332685351371765
loss_records_fold3:
  train_losses:
  - 5.913131526112557
  - 6.0678561419248584
  - 5.932959169149399
  - 5.8127433419227605
  - 5.831852242350578
  - 5.776555913686753
  - 5.869179975986481
  - 5.791530030965806
  - 5.7446484744548805
  - 5.792599469423294
  - 5.787806931138039
  - 5.78532851934433
  - 5.761732432246209
  - 5.736895614862442
  - 5.7732912540435795
  - 5.712903013825417
  - 5.720175251364708
  - 5.677254837751389
  - 5.69083577990532
  - 5.676094123721123
  - 5.630323392152786
  - 5.644061413407326
  - 5.656467130780221
  - 5.617300507426262
  - 5.690646642446518
  - 5.821817961335182
  - 5.738703936338425
  - 5.694035458564759
  - 5.642089435458184
  - 5.686375552415848
  - 5.648396208882332
  - 5.672757059335709
  - 5.65875261425972
  - 5.681588098406792
  - 5.695396822690964
  - 5.66437218785286
  - 5.635163414478303
  - 5.616761887073517
  - 5.6382593572139745
  - 5.56946839094162
  - 5.737218436598778
  - 5.635545372962952
  - 5.6395000487566
  - 5.598143759369851
  - 5.632666730880738
  - 5.684616136550904
  - 5.592897003889084
  - 5.623425415158272
  - 5.5802578896284105
  - 5.695326572656632
  - 5.683058971166611
  - 5.649480822682381
  - 5.56830498278141
  - 5.64622004032135
  - 5.622868514060975
  - 5.601603430509567
  - 5.604915437102318
  - 5.649987870454789
  - 5.683854934573174
  - 5.653518250584603
  - 5.61485313475132
  - 5.584387236833573
  - 5.609322878718377
  - 5.622984725236893
  - 5.539577415585518
  - 5.60216615498066
  - 5.614597755670548
  - 5.58251334130764
  - 5.638718506693841
  - 5.61833031475544
  - 5.6200224459171295
  - 5.665060904622078
  - 5.660975310206414
  - 5.66607335805893
  - 5.605950647592545
  - 5.6585551500320435
  - 5.579860958456994
  - 5.6161038994789125
  - 5.637046894431115
  - 5.570417448878288
  - 5.545533245801926
  - 5.541730171442032
  - 5.604447117447854
  - 5.587487924098969
  - 5.571910896897316
  - 5.593291413784027
  - 5.598096480965615
  - 5.603027668595314
  - 5.573153468966485
  - 5.536313864588738
  - 5.566402363777161
  - 5.596430715918541
  - 5.5775608837604524
  - 5.551087057590485
  - 5.580026775598526
  - 5.621271872520447
  - 5.62960738837719
  - 5.503118428587914
  - 5.5735973715782166
  - 5.54102098941803
  validation_losses:
  - 0.42953646183013916
  - 0.4551125168800354
  - 0.594663143157959
  - 0.5638689994812012
  - 0.5026407241821289
  - 0.408873051404953
  - 0.5585374236106873
  - 1.2101017236709595
  - 0.6205106377601624
  - 0.5071672797203064
  - 0.8124487996101379
  - 0.6784365773200989
  - 0.9621149897575378
  - 0.723484992980957
  - 1.1736077070236206
  - 0.6157749891281128
  - 0.5247794389724731
  - 1.6068203449249268
  - 2.5562901496887207
  - 0.6792691946029663
  - 0.6625232100486755
  - 0.8218980431556702
  - 1.0337392091751099
  - 0.6250935196876526
  - 0.5735232830047607
  - 0.7486886382102966
  - 0.7938846945762634
  - 0.6100399494171143
  - 0.5602759718894958
  - 0.4081518352031708
  - 0.40160611271858215
  - 0.5736235976219177
  - 0.4875609874725342
  - 0.7042471170425415
  - 0.7875190377235413
  - 1.0129398107528687
  - 0.580678403377533
  - 0.8631277084350586
  - 0.37814509868621826
  - 0.83454430103302
  - 0.569606363773346
  - 0.6098793148994446
  - 0.6883118748664856
  - 0.6208487749099731
  - 0.7906351685523987
  - 0.5480327010154724
  - 0.5261759161949158
  - 1.0462368726730347
  - 0.9664151668548584
  - 1.2769309282302856
  - 1.0804396867752075
  - 0.7528323531150818
  - 0.8536754846572876
  - 1.3208664655685425
  - 1.303562045097351
  - 1.5995622873306274
  - 1.775611400604248
  - 1.0651041269302368
  - 1.4812363386154175
  - 1.0988785028457642
  - 1.1366163492202759
  - 1.324288249015808
  - 1.388396143913269
  - 1.5555247068405151
  - 1.1166865825653076
  - 1.54261314868927
  - 1.9266029596328735
  - 1.9552130699157715
  - 0.7730257511138916
  - 1.2821769714355469
  - 1.009883999824524
  - 0.919617772102356
  - 0.723035454750061
  - 1.329308271408081
  - 0.8522722721099854
  - 0.9481498599052429
  - 0.9573609232902527
  - 1.5304200649261475
  - 0.8285536170005798
  - 1.085945963859558
  - 0.9256708025932312
  - 1.5467966794967651
  - 1.5438709259033203
  - 1.3027350902557373
  - 1.607034683227539
  - 1.6612135171890259
  - 2.2595818042755127
  - 1.3740878105163574
  - 1.1931849718093872
  - 1.1437071561813354
  - 1.0719045400619507
  - 1.5635441541671753
  - 1.4957040548324585
  - 0.71214359998703
  - 1.232378363609314
  - 2.1507420539855957
  - 3.3604319095611572
  - 1.2329269647598267
  - 0.7595723867416382
  - 1.9767705202102661
loss_records_fold4:
  train_losses:
  - 5.552898275852204
  - 5.56077566742897
  - 5.6488744705915455
  - 5.533008101582528
  - 5.642595422267914
  - 5.663267254829407
  - 5.640530276298524
  - 5.544825106859207
  - 5.581657412648202
  - 5.57563228905201
  - 5.563397845625878
  - 5.586498537659645
  - 5.567741674184799
  - 5.608774256706238
  - 5.570874364674092
  - 5.602739781141281
  - 5.51978132724762
  - 5.587318107485771
  - 5.54240999519825
  - 5.604602295160294
  - 5.622692051529885
  - 5.590040141344071
  - 5.51852669119835
  - 5.620005714893342
  - 5.704970392584801
  - 5.586440095305443
  - 5.6756616860628135
  - 5.585936385393143
  - 5.616940003633499
  - 5.551624810695649
  - 5.571245563030243
  - 5.528675100207329
  - 5.613609045743942
  - 5.580033951997757
  - 5.634137824177742
  - 5.5580883711576465
  - 5.578409549593926
  - 5.5514869004488
  - 5.562076357007027
  - 5.600622025132179
  - 5.554729276895523
  - 5.54846020936966
  - 5.608825156092644
  - 5.579810068011284
  - 5.571124577522278
  - 5.524841392040253
  - 5.5725058078765874
  - 5.5269220024347305
  - 5.519217339158058
  - 5.564475068449974
  - 5.520067104697228
  - 5.509321939945221
  - 5.535926792025567
  - 5.5267450481653215
  - 5.578250935673714
  - 5.504321497678757
  - 5.5083955287933355
  - 5.523038902878762
  - 5.550580748915673
  - 5.563241216540337
  - 5.4974528551101685
  - 5.604684039950371
  - 5.523064234852791
  - 5.577710646390916
  - 5.520438849925995
  - 5.553797879815102
  - 5.524572119116783
  - 5.5356909096241
  - 5.577416548132897
  - 5.533946791291237
  - 5.518063095211983
  - 5.576342612504959
  - 5.481770578026772
  - 5.50088250041008
  - 5.5106093570590025
  - 5.531607988476754
  - 5.581476831436158
  - 5.495040187239647
  - 5.519403424859047
  - 5.536536630988121
  - 5.571687823534012
  validation_losses:
  - 0.3920731544494629
  - 0.3928576111793518
  - 0.37432894110679626
  - 0.38547852635383606
  - 0.4406600892543793
  - 0.3928220570087433
  - 0.38526543974876404
  - 0.3694170415401459
  - 0.38522571325302124
  - 0.3827138841152191
  - 0.4252622425556183
  - 0.4076882600784302
  - 0.44769540429115295
  - 0.37473055720329285
  - 0.411406546831131
  - 0.37436553835868835
  - 0.3803456723690033
  - 0.393551766872406
  - 0.40586400032043457
  - 0.38571617007255554
  - 0.4067783057689667
  - 0.39238667488098145
  - 0.3883865177631378
  - 0.3752840459346771
  - 0.4869552254676819
  - 0.3836280405521393
  - 0.3888745605945587
  - 0.3883267045021057
  - 0.421115517616272
  - 0.38405805826187134
  - 0.42187920212745667
  - 0.40140360593795776
  - 0.39449453353881836
  - 0.4584586024284363
  - 0.38128095865249634
  - 0.3857681453227997
  - 0.3857111632823944
  - 0.4135602116584778
  - 0.42377039790153503
  - 0.4122336804866791
  - 0.3835617005825043
  - 0.37401533126831055
  - 0.3823055624961853
  - 0.41854509711265564
  - 0.3754023611545563
  - 0.42694228887557983
  - 0.4178517758846283
  - 0.45880264043807983
  - 0.4187910258769989
  - 0.3982647955417633
  - 0.424367219209671
  - 0.3952387571334839
  - 0.4109088182449341
  - 0.3761131763458252
  - 0.4106217920780182
  - 0.46708306670188904
  - 0.4376160502433777
  - 0.38396891951560974
  - 0.3776913583278656
  - 0.3798535466194153
  - 0.44305419921875
  - 0.40063267946243286
  - 0.4014626741409302
  - 0.3750617504119873
  - 0.47385334968566895
  - 0.4078541696071625
  - 0.38678622245788574
  - 0.4621492028236389
  - 0.411162793636322
  - 0.45983803272247314
  - 0.37770265340805054
  - 0.47220930457115173
  - 0.3787563741207123
  - 0.4625224769115448
  - 0.4776352345943451
  - 0.4140569567680359
  - 0.4149024784564972
  - 0.4170331358909607
  - 0.42473509907722473
  - 0.42331844568252563
  - 0.41390594840049744
training fold messages:
  fold 0 training message: stopped training due to stagnating improvement on validation
    loss after 46 epochs
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: completed 100 epochs without stopping early
  fold 3 training message: completed 100 epochs without stopping early
  fold 4 training message: stopped training due to stagnating improvement on validation
    loss after 81 epochs
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.8576329331046312, 0.8524871355060034, 0.8490566037735849,
    0.8556701030927835]'
  fold_eval_f1: '[0.0, 0.0, 0.0, 0.06382978723404255, 0.10638297872340424]'
  mean_eval_accuracy: 0.8544959417163268
  mean_f1_accuracy: 0.034042553191489355
  total_train_time: '0:48:01.810705'
