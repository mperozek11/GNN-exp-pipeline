config:
  aggregation: sum
  batch_size: 32
  class_weights: false
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.5
  epochs: 100
  hidden_units:
  - 64
  - 64
  - 64
  - 64
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.01
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: false
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-22 19:04:34.427012'
fold_0_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_124fold_0_optim_dict.pt
fold_0_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_124fold_0_state_dict.pt
fold_1_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_124fold_1_optim_dict.pt
fold_1_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_124fold_1_state_dict.pt
fold_2_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_124fold_2_optim_dict.pt
fold_2_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_124fold_2_state_dict.pt
fold_3_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_124fold_3_optim_dict.pt
fold_3_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_124fold_3_state_dict.pt
fold_4_optim_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_124fold_4_optim_dict.pt
fold_4_state_dict: GNN-exp-pipeline/result/08.22.2022_16.16.52/config_124fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 106.09220389425755
  - 79.23855523467064
  - 55.26700447648764
  - 55.5178823530674
  - 33.801201003789906
  - 20.206933861970903
  - 38.505400222539905
  - 30.591841626167298
  - 28.173265358805658
  - 41.019963717460634
  - 28.20718075633049
  - 21.116097643971443
  - 25.051145774126056
  - 18.442799875140192
  - 18.365921199321747
  - 13.64329108297825
  - 11.974195069074632
  - 10.272984370589256
  - 15.056880098581315
  - 12.94492486715317
  - 9.18326365351677
  - 10.888661840558052
  - 9.319324570894242
  - 13.617868810892105
  - 8.228049701452255
  - 7.652236685156822
  - 9.002051657438278
  - 7.82843596637249
  - 7.2212827742099766
  - 7.158140882849693
  - 7.577028539776802
  - 7.341326132416725
  - 6.652269750833511
  - 7.195235350728035
  - 7.2257294178009035
  - 6.5854843914508825
  - 6.352448996901512
  - 6.318992274999619
  - 6.43399131000042
  - 6.648242938518525
  - 6.461044865846635
  - 6.556424295902253
  - 6.675698566436768
  - 6.497338545322418
  - 7.078688713908196
  - 6.570187306404114
  - 6.617091658711434
  - 6.315162807703018
  - 6.700909966230393
  - 6.487236890196801
  - 7.700472772121429
  - 6.950606781244279
  - 7.440278473496438
  - 6.718318784236908
  - 6.581799724698067
  - 6.442638462781907
  - 6.205934664607049
  - 6.394167199730873
  - 6.309331232309342
  - 6.384610098600388
  - 6.690562954545022
  - 6.481339192390442
  - 6.487550845742226
  - 6.5323284596204765
  - 6.1197686254978185
  - 6.161902448534966
  - 6.614405849575997
  - 6.451011860370636
  - 7.070288279652596
  - 7.175093039870262
  - 6.374691611528397
  - 6.599248677492142
  - 6.680147084593774
  - 6.603775022923947
  - 6.456228038668633
  - 6.4180634200572975
  - 6.497582238912583
  - 6.809548774361611
  - 7.48420042693615
  - 6.385743430256844
  - 6.350505092740059
  - 6.865642514824867
  - 6.492149192094804
  - 6.462434804439545
  - 6.271639373898506
  - 6.40100574195385
  - 6.518428975343705
  - 6.9661844164133075
  - 6.939797425270081
  - 6.8116801440715795
  - 6.443665719032288
  validation_losses:
  - 1.979430913925171
  - 1.3872239589691162
  - 1.0988552570343018
  - 0.8531417846679688
  - 0.8655790686607361
  - 0.8635101318359375
  - 0.5091869831085205
  - 0.4821985363960266
  - 0.4146004617214203
  - 0.43582433462142944
  - 0.48617812991142273
  - 0.40722107887268066
  - 0.810967206954956
  - 0.47635617852211
  - 0.4320712983608246
  - 0.49181339144706726
  - 0.6211264133453369
  - 0.5981056094169617
  - 0.5684347748756409
  - 0.4182266294956207
  - 0.47756844758987427
  - 0.42885854840278625
  - 0.3908790349960327
  - 0.40735119581222534
  - 0.40399253368377686
  - 0.43304917216300964
  - 0.44275417923927307
  - 0.5337475538253784
  - 0.43030455708503723
  - 0.4158334732055664
  - 0.4015941023826599
  - 0.40267929434776306
  - 0.41533827781677246
  - 0.430399626493454
  - 0.4733065962791443
  - 0.397948294878006
  - 0.40373536944389343
  - 0.423992782831192
  - 0.4714236259460449
  - 0.40112990140914917
  - 0.4386594891548157
  - 0.41551175713539124
  - 0.4276195466518402
  - 0.4021260142326355
  - 0.39960408210754395
  - 0.41652175784111023
  - 0.3924156427383423
  - 0.4169486463069916
  - 0.4816826581954956
  - 0.4219246208667755
  - 0.540043294429779
  - 0.44552257657051086
  - 0.4309998154640198
  - 0.4018712341785431
  - 0.40503937005996704
  - 0.3984815180301666
  - 0.41767042875289917
  - 0.4006122052669525
  - 0.5402621030807495
  - 0.43068957328796387
  - 0.5171522498130798
  - 0.39059263467788696
  - 0.4499416649341583
  - 0.384618878364563
  - 0.427961528301239
  - 0.4294804334640503
  - 0.4171753525733948
  - 0.39560794830322266
  - 1.3819369077682495
  - 0.38874560594558716
  - 0.8654045462608337
  - 1.664964199066162
  - 0.40802907943725586
  - 0.41642263531684875
  - 0.4031044542789459
  - 0.4872928261756897
  - 0.6366993188858032
  - 0.44735780358314514
  - 0.43195396661758423
  - 0.4901893734931946
  - 0.4042082130908966
  - 0.4057355523109436
  - 0.40683218836784363
  - 0.39704009890556335
  - 0.4583529829978943
  - 0.4139447808265686
  - 0.41556987166404724
  - 0.4019502103328705
  - 0.40843307971954346
  - 0.41718828678131104
  - 0.40256375074386597
loss_records_fold1:
  train_losses:
  - 6.552400135993958
  - 6.372476536035538
  - 6.38505394756794
  - 6.474403947591782
  - 6.749755546450615
  - 6.531566026806832
  - 6.4648958325386054
  - 6.420133370161057
  - 6.2355720728635795
  - 6.268351393938065
  - 6.159038379788399
  - 8.265023344755173
  - 14.082866442203523
  - 7.704680958390236
  - 7.102589568495751
  - 7.0543655306100845
  - 6.420608806610108
  - 6.850941514968873
  - 6.411591589450836
  - 6.3481993496418
  - 6.859747549891472
  - 6.454660964012146
  - 12.64112189412117
  - 7.607386696338654
  - 7.143737795948983
  - 6.255236884951592
  - 6.280409270524979
  - 6.521751222014427
  - 6.413561308383942
  - 6.270335578918457
  - 6.421447601914406
  - 6.286299407482147
  - 6.466376444697381
  - 6.274851939082146
  - 6.486428967118264
  - 6.383888202905656
  - 14.161881482601167
  - 7.795821982622147
  - 7.2500935912132265
  - 6.708673518896103
  - 6.69308517575264
  - 6.714816874265671
  - 6.6894113421440125
  - 10.233806625008583
  - 7.021498860418797
  - 6.538004025816917
  - 6.47954363822937
  - 6.720354801416398
  - 6.648225519061089
  - 6.182155275344849
  - 6.604124215245247
  - 6.383091473579407
  - 6.755979597568512
  - 6.634554693102837
  - 7.026365181803704
  - 6.54873351752758
  - 6.4393309414386755
  - 6.277771681547165
  - 6.506753605604172
  - 6.697630664706231
  - 6.687859648466111
  - 6.258875858783722
  - 6.5250324547290806
  - 6.367315208911896
  - 6.642344671487809
  - 6.474281531572342
  - 6.377441269159317
  - 6.2185282677412035
  - 6.429505994915963
  - 6.241486588120461
  - 6.494812229275704
  - 6.316253104805947
  - 6.28229324221611
  - 6.496851086616516
  - 6.277366524934769
  - 6.629774594306946
  - 6.026649001240731
  - 6.434745112061501
  - 6.251435369253159
  - 6.562712442874909
  - 6.3118478000164036
  - 6.827534314990044
  - 6.408686974644661
  - 6.446489050984383
  - 6.193541869521141
  - 6.1890199244022375
  - 6.085648459196091
  - 6.413363453745842
  - 6.308188879489899
  - 6.20380089879036
  - 5.998838114738465
  - 6.43414962887764
  - 6.280624666810036
  - 6.222800722718239
  - 6.120144253969193
  - 6.165872102975846
  - 6.264624819159508
  - 6.384879741072655
  - 6.109577268362045
  - 6.0728496462106705
  validation_losses:
  - 0.46704480051994324
  - 0.40737807750701904
  - 41.82379150390625
  - 0.44609570503234863
  - 180.53758239746094
  - 0.43181532621383667
  - 0.41042521595954895
  - 0.42313137650489807
  - 0.4053265154361725
  - 0.41546130180358887
  - 0.425901859998703
  - 53.228179931640625
  - 0.41973233222961426
  - 0.4155019223690033
  - 0.4208872616291046
  - 0.43353715538978577
  - 0.421724408864975
  - 0.43210190534591675
  - 0.42605650424957275
  - 0.44312676787376404
  - 0.4786222279071808
  - 0.47949692606925964
  - 0.5513581037521362
  - 0.4677245020866394
  - 0.4163081645965576
  - 0.44786980748176575
  - 0.419966459274292
  - 0.448054701089859
  - 0.43625468015670776
  - 0.46786755323410034
  - 0.44162824749946594
  - 0.46070775389671326
  - 0.4145369231700897
  - 1.8441646099090576
  - 0.4870520830154419
  - 33.991905212402344
  - 0.5158355832099915
  - 101.71292877197266
  - 18056742.0
  - 43675024.0
  - 160568416.0
  - 156823440.0
  - 84485.0
  - 0.47162723541259766
  - 0.4602063000202179
  - 0.3997853696346283
  - 0.46983084082603455
  - 0.5639054775238037
  - 0.446255087852478
  - 0.4064616858959198
  - 0.39433884620666504
  - 0.46369126439094543
  - 0.4038448929786682
  - 0.45950281620025635
  - 0.5008511543273926
  - 0.42771774530410767
  - 0.4235031306743622
  - 0.40005865693092346
  - 0.49871912598609924
  - 0.42795297503471375
  - 0.4002567231655121
  - 0.5790961384773254
  - 0.5033873915672302
  - 0.41386836767196655
  - 0.42149296402931213
  - 0.5395088791847229
  - 0.46625950932502747
  - 0.5034038424491882
  - 0.44982796907424927
  - 0.5920602679252625
  - 0.4547635018825531
  - 0.532454788684845
  - 0.4727671444416046
  - 0.4919043779373169
  - 0.47340843081474304
  - 0.5103684663772583
  - 0.40908578038215637
  - 0.6204956769943237
  - 0.4559410512447357
  - 0.6189176440238953
  - 0.42409998178482056
  - 0.47425907850265503
  - 0.4337586462497711
  - 0.5969900488853455
  - 0.4697956144809723
  - 0.5236125588417053
  - 0.5836949944496155
  - 0.48365986347198486
  - 0.48121824860572815
  - 0.47231626510620117
  - 0.6254986524581909
  - 0.5064036846160889
  - 0.4178972542285919
  - 0.5457992553710938
  - 0.5203976631164551
  - 0.4555373191833496
  - 0.44880953431129456
  - 0.45544737577438354
  - 0.4186941087245941
  - 0.44253912568092346
loss_records_fold2:
  train_losses:
  - 6.363204321265221
  - 6.418902066349983
  - 6.328613856434822
  - 6.4960362881422045
  - 6.496844831109048
  - 6.410107430815697
  - 6.207359084486962
  - 6.318861615657807
  - 6.3546653419733055
  - 6.3204750478267675
  - 6.627392649650574
  - 6.981888920068741
  - 6.786562582850457
  - 6.231756320595742
  - 6.425179201364518
  - 6.313744145631791
  - 6.4842006295919425
  - 6.353157016634942
  - 6.777901992201805
  - 6.739493623375893
  - 6.424466368556023
  - 6.240868537127972
  - 6.428058364987374
  - 6.569471138715745
  - 6.478946858644486
  - 6.307099255919457
  - 6.64583187699318
  - 6.40974977016449
  - 6.480306798219681
  - 6.369771358370781
  - 6.838411140441895
  - 9.265641689300537
  - 7.090413454174996
  - 6.63217306137085
  - 6.658927887678146
  - 6.26231923699379
  - 6.686832812428475
  - 6.589045634865761
  - 7.50958089530468
  - 8.17832305431366
  - 6.57425337433815
  - 6.435555532574654
  - 6.328449228405953
  - 6.4610227972269065
  - 6.253529381752014
  - 6.5055850595235825
  - 6.212356922030449
  - 6.491704481840134
  - 6.227240586280823
  - 6.267245981097222
  - 6.741644984483719
  - 6.639958381652832
  validation_losses:
  - 0.46411505341529846
  - 0.5560643076896667
  - 0.490299254655838
  - 0.6022485494613647
  - 0.45593440532684326
  - 0.4395742118358612
  - 0.40731051564216614
  - 0.3734888434410095
  - 0.5138959288597107
  - 0.4004873037338257
  - 0.49193456768989563
  - 0.41416993737220764
  - 0.3987368643283844
  - 0.40861281752586365
  - 0.43468543887138367
  - 0.4164401590824127
  - 0.39887282252311707
  - 0.4082610607147217
  - 0.4453580677509308
  - 0.4277592897415161
  - 0.3942599594593048
  - 0.39789626002311707
  - 0.4093114137649536
  - 0.4051531255245209
  - 0.39489203691482544
  - 0.409167617559433
  - 0.43078961968421936
  - 0.40255340933799744
  - 0.3892230987548828
  - 0.3887968361377716
  - 0.40211328864097595
  - 1.1833373308181763
  - 72519.8984375
  - 1950919.375
  - 3334.196044921875
  - 0.41292133927345276
  - 0.43501192331314087
  - 0.44278484582901
  - 0.5519843697547913
  - 0.40398135781288147
  - 8273598464.0
  - 0.40419596433639526
  - 0.4049517810344696
  - 0.4011443853378296
  - 0.4067404270172119
  - 0.4203054904937744
  - 0.4214210510253906
  - 0.41747963428497314
  - 0.40342846512794495
  - 0.403654545545578
  - 0.4062952399253845
  - 0.4070432186126709
loss_records_fold3:
  train_losses:
  - 6.267228776216507
  - 6.456707322597504
  - 6.409784060716629
  - 6.437496331334114
  - 6.675167626142502
  - 6.82577320933342
  - 6.461554366350175
  - 6.353196147084237
  - 7.762288425862789
  - 7.120826536417008
  - 7.491032695770264
  - 6.6909937232732775
  - 6.52819581925869
  - 6.484022197127342
  - 6.45140018761158
  - 6.439444729685784
  - 6.426163366436959
  - 6.417788776755334
  - 6.54520021378994
  - 6.603259921073914
  - 6.517275613546372
  - 6.47410075366497
  - 6.640512821078301
  - 6.52225253880024
  - 6.644493985176087
  - 6.370870471000671
  - 6.444394928216934
  - 6.413349163532257
  - 6.374905660748482
  - 6.267460227012634
  - 6.543637219071389
  - 6.329952254891396
  - 6.841537982225418
  - 6.546370753645897
  - 6.26942861378193
  - 6.566136154532433
  - 6.509765627980233
  - 6.392160922288895
  - 6.510676380991936
  - 6.243779644370079
  - 6.412105911970139
  - 6.419961839914322
  - 6.393956279754639
  - 6.657757326960564
  - 6.418316581845284
  - 6.313038036227226
  - 6.684791225194932
  - 6.3885815173387535
  - 6.368494129180909
  - 6.639812794327736
  - 6.308545020222664
  - 6.5206353098154075
  - 6.447157222032548
  - 6.565643155574799
  - 6.683678096532822
  - 6.617997017502785
  - 6.323923346400261
  - 6.309198102355004
  - 6.2594926238060005
  - 6.441108173131943
  - 6.571171313524246
  - 6.2906230032444
  - 6.254594102501869
  - 6.753694444894791
  - 6.588841453194618
  - 6.527758699655533
  - 6.329404973983765
  - 6.567579320073128
  - 6.401692804694176
  - 6.276545408368111
  - 6.440177834033967
  - 6.550038152933121
  - 6.47464229464531
  - 6.411729875206948
  - 6.390576136112213
  - 6.785686656832695
  - 6.183255612850189
  - 6.300742560625077
  - 6.281215626001359
  - 6.401391816139221
  - 6.528724738955498
  - 6.324758389592171
  - 6.467729076743126
  - 6.430700215697289
  - 6.742428082227708
  - 6.904888945817948
  - 6.4854497641325
  - 6.198357301950455
  - 6.312341183423996
  - 6.31538887321949
  - 6.262522312998772
  - 6.449530512094498
  - 6.503206399083138
  - 6.227627211809159
  - 6.770096173882485
  - 6.528687459230423
  - 6.307417261600495
  - 6.296375417709351
  - 6.405777332186699
  - 6.4864576935768135
  validation_losses:
  - 0.4277467727661133
  - 0.4288894534111023
  - 0.436115026473999
  - 0.4172564148902893
  - 0.4567447304725647
  - 0.42370542883872986
  - 0.41801750659942627
  - 0.41278311610221863
  - 0.505122721195221
  - 0.5494246482849121
  - 0.454243540763855
  - 0.3994430601596832
  - 0.4182364046573639
  - 0.41290223598480225
  - 0.42563575506210327
  - 0.4239968955516815
  - 0.41983017325401306
  - 0.5017827153205872
  - 0.39934593439102173
  - 0.4215845465660095
  - 0.4078734219074249
  - 0.44917166233062744
  - 0.40093427896499634
  - 0.44973453879356384
  - 5.7194719314575195
  - 95.9449234008789
  - 0.4343646168708801
  - 0.45261281728744507
  - 122.72627258300781
  - 123.5893325805664
  - 207.74920654296875
  - 0.4348280727863312
  - 0.4207613468170166
  - 0.4176141321659088
  - 2182.645263671875
  - 0.4329099655151367
  - 2.949476957321167
  - 90.10980987548828
  - 0.4060419797897339
  - 0.42183613777160645
  - 77.2408676147461
  - 0.42457616329193115
  - 0.40904495120048523
  - 0.4400114119052887
  - 0.4083941876888275
  - 0.406169056892395
  - 0.43172842264175415
  - 0.43317872285842896
  - 0.429695725440979
  - 0.40822023153305054
  - 0.42903435230255127
  - 0.4020766317844391
  - 0.414043128490448
  - 0.48311546444892883
  - 0.4384137690067291
  - 8531145.0
  - 36240636.0
  - 171149792.0
  - 944643584.0
  - 1262381440.0
  - 963136192.0
  - 56828059648.0
  - 4369709531136.0
  - 3081818341376.0
  - 25904695296.0
  - 11395675455488.0
  - 1134952841216.0
  - 4039629602816.0
  - 2164088504320.0
  - 808326201344.0
  - 6442746118144.0
  - 5741811335168.0
  - 8711191396352.0
  - 5944222679040.0
  - 13427858735104.0
  - 806646710272.0
  - 330364452864.0
  - 803914645504.0
  - 7226156646400.0
  - 867274063872.0
  - 304559620096.0
  - 1216276987904.0
  - 942266843136.0
  - 794603749376.0
  - 1112582520832.0
  - 1211935490048.0
  - 3512978374656.0
  - 3897984024576.0
  - 1121746550784.0
  - 973032259584.0
  - 2172611461120.0
  - 564385546240.0
  - 3137622507520.0
  - 759837753344.0
  - 127650643968.0
  - 1943809818624.0
  - 244727382016.0
  - 661482504192.0
  - 466844516352.0
  - 2312967290880.0
loss_records_fold4:
  train_losses:
  - 6.594842213392258
  - 6.6055712610483175
  - 6.399710687994958
  - 6.309945830702782
  - 6.437002244591714
  - 6.5654576420784
  - 6.25911717414856
  - 6.391294646263123
  - 7.029342091083527
  - 6.434981706738473
  - 6.5554279088974
  - 6.411306315660477
  - 6.324264040589333
  - 6.251155716180802
  - 6.238869598507882
  - 6.443380752205849
  - 6.408669921755791
  - 6.761261749267579
  - 6.697287046909333
  - 6.491862818598747
  - 6.310630202293396
  - 6.490212306380272
  - 6.415671223402024
  - 6.651350337266923
  - 6.417163842916489
  - 6.667883121967316
  - 6.6335368156433105
  - 6.399767905473709
  - 6.422707971930504
  - 6.350027829408646
  - 6.402728745341301
  - 6.344132435321808
  - 6.514015173912049
  - 6.355381578207016
  - 6.468184769153595
  - 6.3088975042104725
  - 6.3329380571842195
  - 6.549251627922058
  - 6.51500578224659
  - 6.488678735494614
  - 6.705629724264146
  - 6.552811372280122
  - 6.418866229057312
  - 6.562939476966858
  - 6.2536618471145635
  - 6.351466897130013
  - 6.317877122759819
  - 6.572945955395699
  - 6.417700028419495
  - 6.64690609574318
  - 6.3237331211566925
  - 6.593939465284348
  - 6.536225691437721
  - 6.241552460193635
  - 6.486866396665573
  - 6.438683161139489
  - 6.211484804749489
  - 6.426432716846467
  - 6.469199991226197
  - 6.845091825723649
  - 6.352622789144516
  - 6.401143354177475
  - 6.427116617560387
  - 6.5146556258201604
  - 6.604211923480034
  - 6.478670075535774
  - 6.673054111003876
  - 6.643875792622566
  - 6.262734296917916
  - 6.436855746805668
  - 6.6325142860412605
  - 6.51270775794983
  - 6.8088224619627
  - 6.235432228446007
  - 6.652091905474663
  - 6.322140535712243
  - 6.898278170824051
  - 6.346132749319077
  - 6.491524583101273
  - 6.304316139221192
  - 6.548867747187614
  - 6.679294845461846
  - 6.339580661058426
  - 6.3816598653793335
  - 6.38930750489235
  - 6.474199807643891
  - 6.448028403520585
  - 6.552835631370545
  - 6.3289338707923894
  - 6.610530725121499
  - 6.578423833847046
  - 6.524902367591858
  - 6.46680506169796
  - 6.370416247844696
  - 6.298071227967739
  - 6.717677360773087
  - 6.3560740709304815
  - 6.484155336022377
  - 6.473587146401406
  - 6.39080947637558
  validation_losses:
  - 166565642240.0
  - 138595844096.0
  - 399305637888.0
  - 294202769408.0
  - 370769035264.0
  - 439527800832.0
  - 63297662976.0
  - 207018131456.0
  - 549556977664.0
  - 0.41319596767425537
  - 0.41303449869155884
  - 0.42842140793800354
  - 0.40133053064346313
  - 0.4120027720928192
  - 0.41151508688926697
  - 0.4268830120563507
  - 0.4032844603061676
  - 0.4055491089820862
  - 0.4044278562068939
  - 0.41865018010139465
  - 0.41204434633255005
  - 0.4127463102340698
  - 0.4387672245502472
  - 0.42780452966690063
  - 0.40357905626296997
  - 0.4374375641345978
  - 0.43387290835380554
  - 0.454578161239624
  - 0.4045722484588623
  - 0.41561025381088257
  - 0.4109441936016083
  - 0.4124119281768799
  - 0.4000103175640106
  - 0.4453407824039459
  - 0.40430158376693726
  - 0.40518811345100403
  - 0.4011198580265045
  - 0.43708616495132446
  - 0.4247678816318512
  - 0.4045814573764801
  - 0.4731922149658203
  - 0.4485962390899658
  - 0.4140796959400177
  - 0.44838282465934753
  - 0.4303811192512512
  - 0.42579665780067444
  - 0.4024159014225006
  - 0.4564126133918762
  - 0.4183688461780548
  - 0.4248577356338501
  - 0.39673376083374023
  - 0.4562496542930603
  - 0.4230508804321289
  - 0.4053138196468353
  - 0.4381250739097595
  - 0.40747031569480896
  - 0.426766574382782
  - 0.43832266330718994
  - 0.41026824712753296
  - 0.4086431860923767
  - 0.4006490409374237
  - 0.44063472747802734
  - 0.469736784696579
  - 0.4214740991592407
  - 0.40433287620544434
  - 0.4031338393688202
  - 0.41907191276550293
  - 0.4203530550003052
  - 0.43053507804870605
  - 0.4164358079433441
  - 0.4077731668949127
  - 0.43360111117362976
  - 0.39123526215553284
  - 0.39525270462036133
  - 0.44301509857177734
  - 0.4096566438674927
  - 0.4129193425178528
  - 0.42907658219337463
  - 0.40644314885139465
  - 0.40582531690597534
  - 0.4215782582759857
  - 0.3999178111553192
  - 0.4145282804965973
  - 0.4034791588783264
  - 0.43029823899269104
  - 0.410847932100296
  - 0.4120682179927826
  - 0.4450652599334717
  - 0.4101208746433258
  - 0.41709959506988525
  - 0.4038980305194855
  - 0.4355294704437256
  - 0.4050811231136322
  - 0.4066693186759949
  - 0.4311290383338928
  - 0.4422050714492798
  - 0.45171433687210083
  - 0.4154564440250397
  - 0.45267048478126526
  - 0.417941153049469
training fold messages:
  fold 0 training message: stopped training due to stagnating improvement on validation
    loss after 91 epochs
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: stopped training due to stagnating improvement on validation
    loss after 52 epochs
  fold 3 training message: completed 100 epochs without stopping early
  fold 4 training message: completed 100 epochs without stopping early
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.855917667238422, 0.8593481989708405, 0.8593481989708405,
    0.8591065292096219]'
  fold_eval_f1: '[0.0, 0.0, 0.0, 0.0, 0.0]'
  mean_eval_accuracy: 0.8582707054988712
  mean_f1_accuracy: 0.0
  total_train_time: '0:32:53.456810'
