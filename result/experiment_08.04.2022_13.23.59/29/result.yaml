config:
  aggregation: sum
  batch_size: 128
  class_weights: false
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.5
  epochs: 100
  hidden_units:
  - 32
  - 32
  - 32
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.1
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: true
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-04 16:50:09.742420'
fold_0_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/29/fold_0_optim_dict.pt
fold_0_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/29/fold_0_state_dict.pt
fold_1_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/29/fold_1_optim_dict.pt
fold_1_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/29/fold_1_state_dict.pt
fold_2_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/29/fold_2_optim_dict.pt
fold_2_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/29/fold_2_state_dict.pt
fold_3_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/29/fold_3_optim_dict.pt
fold_3_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/29/fold_3_state_dict.pt
fold_4_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/29/fold_4_optim_dict.pt
fold_4_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/29/fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 152.45004999637604
  - 178.28034394979477
  - 14.331445872783661
  - 15.181435614824295
  - 10.483733922243118
  - 9.558938682079315
  - 8.866640836000443
  - 47.68334764242172
  - 25.47579464316368
  - 49.330117017030716
  - 15.487622439861298
  - 16.143181443214417
  - 10.613077521324158
  - 107.0987654030323
  - 42.88410210609436
  - 18.466272562742233
  - 19.322444438934326
  - 19.209255814552307
  - 14.254069358110428
  - 16.211026340723038
  - 13.304118275642395
  - 13.238067835569382
  - 8.765858471393585
  - 10.664811611175537
  - 11.368526041507721
  - 12.594261199235916
  - 14.829482972621918
  - 13.835161089897156
  - 9.250993430614471
  - 10.379884123802185
  - 10.046016484498978
  - 9.97661879658699
  - 11.867631375789642
  - 10.191798895597458
  - 9.164787977933884
  - 9.052301466464996
  - 10.544580847024918
  - 13.453429847955704
  - 13.348671972751617
  - 11.001841098070145
  - 9.340840846300125
  - 10.722276419401169
  - 9.06648451089859
  - 9.571883141994476
  - 8.787206798791885
  - 10.514288187026978
  - 10.505905717611313
  - 15.271563917398453
  - 10.576847523450851
  - 9.378469496965408
  - 9.436810940504074
  - 9.282795637845993
  - 9.912159383296967
  - 10.763001769781113
  - 9.928187757730484
  - 9.768792867660522
  - 9.169257253408432
  - 13.032749980688095
  - 12.598224133253098
  - 12.54162472486496
  - 13.955413281917572
  - 9.193319469690323
  - 10.349328815937042
  - 11.21311867237091
  - 16.164880841970444
  - 9.985463201999664
  - 10.742778986692429
  - 10.262962579727173
  - 8.880887746810913
  - 9.663457036018372
  - 12.076987087726593
  - 12.49229583144188
  - 8.910923600196838
  - 10.205699920654297
  - 8.356108754873276
  - 8.815793812274933
  - 11.059270575642586
  - 9.116527169942856
  - 18.012639462947845
  - 14.09868660569191
  - 12.044969826936722
  - 11.348466262221336
  - 10.308620601892471
  - 10.748999148607254
  - 9.83505728840828
  - 8.608053594827652
  - 8.459291815757751
  - 8.214011132717133
  - 9.695827960968018
  - 9.485455453395844
  - 8.948681890964508
  - 9.729024052619934
  - 9.823272705078125
  - 11.719878256320953
  - 10.453004747629166
  - 9.148393124341965
  - 9.240697264671326
  - 8.465958714485168
  - 10.043484061956406
  - 11.145307868719101
  validation_losses:
  - 15.798081398010254
  - 25.654939651489258
  - 1.5808085203170776
  - 0.48459726572036743
  - 0.5541209578514099
  - 0.510075032711029
  - 0.4401564598083496
  - 0.4959414303302765
  - 0.7636030316352844
  - 1.2175865173339844
  - 1.2145698070526123
  - 0.6673184037208557
  - 1.9872719049453735
  - 0.9427109360694885
  - 0.9755221009254456
  - 0.6089895367622375
  - 0.8768730759620667
  - 0.7913522124290466
  - 0.8162800073623657
  - 0.7088863253593445
  - 0.5601795315742493
  - 0.4598396122455597
  - 0.41079992055892944
  - 0.5685349106788635
  - 0.715720534324646
  - 0.6552851796150208
  - 0.4145296514034271
  - 0.5403875112533569
  - 0.524334192276001
  - 0.4743761420249939
  - 0.5140290856361389
  - 0.4556903839111328
  - 0.4794168770313263
  - 0.5950687527656555
  - 0.450819194316864
  - 0.5536567568778992
  - 718826.0
  - 1917783.375
  - 2084533.875
  - 1913561.25
  - 2074210.25
  - 1814462.125
  - 1761378.25
  - 1561185.75
  - 1903580.5
  - 1737112.375
  - 2170429.5
  - 1676280.125
  - 1727252.625
  - 1648263.0
  - 1462255.125
  - 1590164.0
  - 1510261.625
  - 1226582.125
  - 1191268.625
  - 1320324.375
  - 1370193.875
  - 1071037.625
  - 995408.8125
  - 1091466.375
  - 912594.875
  - 1008070.9375
  - 1002130.5625
  - 1008361.4375
  - 1099241.625
  - 1075901.25
  - 1097495.75
  - 1127043.75
  - 1031891.875
  - 1134283.875
  - 1124610.5
  - 1071293.0
  - 1065850.375
  - 1107263.875
  - 1127325.5
  - 1124848.5
  - 1009568.4375
  - 838475.625
  - 671553.9375
  - 799662.125
  - 609762.8125
  - 638736.6875
  - 697377.8125
  - 706958.5625
  - 728833.75
  - 638192.0
  - 650839.5625
  - 564788.25
  - 136322.390625
  - 400947.0625
  - 431407.625
  - 337872.75
  - 436593.78125
  - 354550.0625
  - 388657.84375
  - 442114.59375
  - 353683.40625
  - 335866.1875
  - 340834.28125
  - 321622.25
loss_records_fold1:
  train_losses:
  - 13.080755829811096
  - 13.152492016553879
  - 12.893266350030899
  - 10.621260046958923
  - 10.204582065343857
  - 14.129344761371613
  - 10.140736311674118
  - 10.279989093542099
  - 9.984504520893097
  - 9.119692355394363
  - 8.632833898067474
  - 10.248994141817093
  - 10.179941654205322
  - 10.41300368309021
  - 10.960439562797546
  - 9.687532901763916
  - 11.310644090175629
  - 13.366250991821289
  - 10.151391059160233
  - 11.391186714172363
  - 9.567240580916405
  - 9.159217327833176
  - 10.630070984363556
  - 13.039139777421951
  - 11.129843413829803
  - 9.662588477134705
  - 9.893463253974915
  - 11.010401427745819
  - 11.507444635033607
  - 13.4975805580616
  - 9.368425190448761
  - 9.527572929859161
  - 13.370682209730148
  - 16.546717882156372
  - 11.162830412387848
  - 10.309225708246231
  - 9.445635080337524
  - 10.101690411567688
  - 9.376592814922333
  - 8.79705986380577
  - 11.382974922657013
  - 10.137885183095932
  - 8.6250479221344
  - 9.196090966463089
  - 11.119301557540894
  - 10.893019050359726
  - 10.231088668107986
  - 9.125659495592117
  - 10.853394448757172
  - 9.279471978545189
  - 9.997148215770721
  - 8.56635531783104
  - 10.049546211957932
  - 15.183221220970154
  - 14.544834673404694
  - 12.203739553689957
  - 10.549540400505066
  - 9.732371896505356
  - 9.54802805185318
  - 8.750460863113403
  - 9.17543539404869
  - 9.862292677164078
  - 9.449757635593414
  - 11.78864198923111
  - 8.936852276325226
  - 10.180140554904938
  - 17.998899936676025
  - 12.877559751272202
  - 9.191671878099442
  - 9.823152929544449
  - 9.109097480773926
  - 13.088802605867386
  - 12.491429775953293
  - 9.176884174346924
  - 9.067053079605103
  - 8.486468702554703
  - 8.469005554914474
  - 8.338534086942673
  - 9.927558481693268
  - 9.30395621061325
  - 10.078673124313354
  - 9.583787351846695
  - 10.698027998209
  - 10.403876513242722
  - 8.856182932853699
  - 9.21720176935196
  - 11.330920279026031
  - 12.303979456424713
  - 14.738830596208572
  - 9.654815956950188
  - 8.693610429763794
  - 8.831783473491669
  - 13.11930501461029
  - 18.505484342575073
  - 10.149321794509888
  - 9.268319606781006
  - 17.560179829597473
  - 12.967455685138702
  - 15.285276353359222
  - 11.268949657678604
  validation_losses:
  - 408107.3125
  - 406280.625
  - 370085.40625
  - 256644.953125
  - 111359.2734375
  - 0.46643540263175964
  - 0.4929230809211731
  - 0.6337235569953918
  - 0.506777822971344
  - 0.4240573048591614
  - 0.4648684561252594
  - 0.6841606497764587
  - 0.6008351445198059
  - 842555.3125
  - 1444944.0
  - 1265354.625
  - 1217195.5
  - 1193532.25
  - 1325785.75
  - 1515268.375
  - 1372807.25
  - 1019679.1875
  - 1213506.375
  - 942189.8125
  - 1103432.625
  - 1.6908873319625854
  - 32.104957580566406
  - 322.34075927734375
  - 1878.660888671875
  - 1161.2789306640625
  - 27944.39453125
  - 22350.669921875
  - 1.5058900117874146
  - 561657.75
  - 1563143.5
  - 1368629.625
  - 1538464.375
  - 1334728.875
  - 0.5245237946510315
  - 0.5565847754478455
  - 0.5174328088760376
  - 0.42140787839889526
  - 0.5357626676559448
  - 0.7325045466423035
  - 0.4667156934738159
  - 215687.875
  - 1233204.125
  - 1414666.625
  - 0.5770339965820312
  - 0.543717086315155
  - 0.49197137355804443
  - 0.42645710706710815
  - 0.6265127062797546
  - 1.0683737993240356
  - 0.6221016049385071
  - 0.7452189922332764
  - 0.49955058097839355
  - 0.5745527744293213
  - 0.5454164147377014
  - 0.585320234298706
  - 0.4495752453804016
  - 0.5245660543441772
  - 785027.625
  - 1684383.125
  - 1736965.125
  - 1667392.125
  - 1443887.5
  - 1308907.875
  - 945891.375
  - 1122792.375
  - 1032480.5
  - 1022720.375
  - 1060290.375
  - 985584.875
  - 1059565.75
  - 980659.9375
  - 1041889.3125
  - 1013411.375
  - 989038.125
  - 1048692.0
  - 1050793.625
  - 848669.25
  - 1053847.125
  - 1074151.5
  - 1003805.875
  - 1074199.25
  - 1015893.3125
  - 1045351.6875
  - 907057.5
  - 877314.0625
  - 950165.5625
  - 742470.375
  - 627000.3125
  - 755994.0625
  - 658855.5625
  - 617200.625
  - 674873.1875
  - 675873.5625
  - 635781.625
  - 596232.0
loss_records_fold2:
  train_losses:
  - 15.835146516561508
  - 10.310969233512878
  - 9.078432828187943
  - 9.360799819231033
  - 9.614759594202042
  - 15.262608885765076
  - 16.909718215465546
  - 10.546572208404541
  - 10.055305033922195
  - 10.643435627222061
  - 9.782375454902649
  - 8.757504224777222
  - 9.219883173704147
  - 9.697923302650452
  - 9.13768145442009
  - 9.518241494894028
  - 10.666244447231293
  - 8.529471188783646
  - 10.27301561832428
  - 15.727920323610306
  - 15.20735079050064
  - 10.469858646392822
  - 9.158573061227798
  - 8.824916362762451
  - 8.629189670085907
  - 9.13443723320961
  - 10.022265762090683
  - 9.609547823667526
  - 12.369048297405243
  - 12.161029130220413
  - 14.389921307563782
  - 10.119705885648727
  - 10.065376281738281
  - 15.643666684627533
  - 13.723095566034317
  - 10.636216402053833
  - 11.481304407119751
  - 12.233332395553589
  - 9.53610834479332
  - 10.565519601106644
  - 10.979894191026688
  - 9.336803644895554
  - 8.978402018547058
  - 8.857332646846771
  - 11.392140865325928
  - 10.156381011009216
  - 12.812321871519089
  - 13.00797101855278
  - 9.725338727235794
  - 8.649073392152786
  - 9.079756140708923
  - 11.229425817728043
  - 16.03750628232956
  - 15.333983987569809
  - 11.786559522151947
  - 17.835856527090073
  - 14.22061538696289
  - 10.949007391929626
  - 13.403697788715363
  - 10.40963289141655
  - 8.90565076470375
  - 9.739355713129044
  - 9.582624018192291
  - 10.737377226352692
  - 9.540617138147354
  - 9.100563436746597
  - 9.214965283870697
  - 10.018870443105698
  - 17.737573713064194
  - 16.274266868829727
  - 13.654394000768661
  - 10.059084326028824
  - 10.099310487508774
  - 13.986297518014908
  - 10.606777936220169
  - 9.586490005254745
  - 9.881189227104187
  - 9.10216200351715
  - 8.709475934505463
  - 9.59362280368805
  - 12.445718884468079
  - 9.34717059135437
  - 8.905693769454956
  - 8.937917321920395
  - 10.305577412247658
  - 8.92203465104103
  - 9.53198492527008
  - 9.420386284589767
  - 11.63570162653923
  - 17.244170516729355
  - 10.58048877120018
  - 8.73878788948059
  - 9.493127226829529
  - 8.579805493354797
  - 8.290711790323257
  - 8.949681162834167
  - 8.618804603815079
  - 9.27682849764824
  - 11.724093675613403
  - 12.142076671123505
  validation_losses:
  - 590153.9375
  - 589120.0
  - 658250.5625
  - 571727.1875
  - 638868.8125
  - 266541.46875
  - 478472.5625
  - 418650.34375
  - 512449.4375
  - 479106.875
  - 422345.65625
  - 400975.28125
  - 166302.59375
  - 415047.25
  - 213468.1875
  - 382160.875
  - 265371.875
  - 363029.375
  - 0.809913158416748
  - 368327.03125
  - 409540.96875
  - 381050.125
  - 387483.90625
  - 376813.71875
  - 413280.65625
  - 118126.9609375
  - 188706.625
  - 314468.34375
  - 348395.4375
  - 402824.3125
  - 259491.90625
  - 340452.90625
  - 185179.890625
  - 331959.625
  - 400146.90625
  - 409161.78125
  - 171049.90625
  - 307647.71875
  - 305753.15625
  - 337333.46875
  - 278871.0
  - 312497.6875
  - 375374.0625
  - 311804.53125
  - 315941.59375
  - 280411.0
  - 118127.3984375
  - 384882.125
  - 184012.828125
  - 281882.53125
  - 332658.03125
  - 253572.453125
  - 155736.65625
  - 323640.84375
  - 245293.703125
  - 294884.9375
  - 235841.375
  - 119304.6875
  - 0.5551004409790039
  - 244133.796875
  - 193445.84375
  - 247660.140625
  - 56974.5
  - 36922.30078125
  - 11128.390625
  - 99286.6171875
  - 16583.783203125
  - 16583.849609375
  - 1.1948657035827637
  - 199332.375
  - 50.434532165527344
  - 214662.875
  - 0.6386804580688477
  - 41593.1796875
  - 139274.90625
  - 99286.640625
  - 220564.609375
  - 115768.375
  - 56974.64453125
  - 0.45405372977256775
  - 8000.94384765625
  - 116955.8828125
  - 123995.7734375
  - 156928.171875
  - 69926.203125
  - 173383.421875
  - 21064.607421875
  - 0.4549090564250946
  - 78136.4296875
  - 22196.8515625
  - 0.40487176179885864
  - 0.4084477424621582
  - 0.4459505081176758
  - 0.40329742431640625
  - 0.4477725923061371
  - 43936.671875
  - 5979.671875
  - 51021.17578125
  - 0.7615147829055786
  - 1.0554214715957642
loss_records_fold3:
  train_losses:
  - 12.67871105670929
  - 10.610191613435745
  - 10.470893293619156
  - 8.646063208580017
  - 16.42898055911064
  - 13.485692828893661
  - 10.302778571844101
  - 9.82993745803833
  - 9.620086699724197
  - 8.549598455429077
  - 10.290924042463303
  - 12.52967581152916
  - 15.909508094191551
  - 11.511117547750473
  - 14.207673013210297
  - 10.790906846523285
  - 8.943158775568008
  - 9.267951130867004
  - 9.683326542377472
  - 12.031679391860962
  - 20.236336022615433
  - 11.406138837337494
  - 10.112443089485168
  - 11.838358506560326
  - 13.75618201494217
  - 11.377821743488312
  - 15.797114491462708
  - 10.432431638240814
  - 9.492193087935448
  - 10.101793199777603
  - 11.167257487773895
  - 11.983503013849258
  - 14.454863727092743
  - 11.735837697982788
  - 8.715208560228348
  - 9.320458769798279
  - 8.79535686969757
  - 9.124845743179321
  - 9.884008347988129
  - 10.261508882045746
  - 10.233354657888412
  - 8.492731809616089
  - 8.87748783826828
  - 9.87660226225853
  - 11.52912950515747
  - 11.220041185617447
  - 12.868287682533264
  - 10.178081333637238
  - 8.773126512765884
  - 9.767614722251892
  - 9.109183520078659
  - 11.98846784234047
  - 13.555298179388046
  - 10.145796090364456
  - 10.075687557458878
  - 9.955532371997833
  - 12.697256535291672
  - 11.242062151432037
  - 11.537117958068848
  - 13.804250746965408
  - 9.386821657419205
  - 13.237723410129547
  - 9.758556634187698
  - 8.879446119070053
  - 9.842590898275375
  - 11.309822022914886
  - 13.093314588069916
  - 11.201720386743546
  - 10.624917805194855
  - 8.524998486042023
  - 10.347785621881485
  - 18.04616889357567
  - 14.896601676940918
  - 9.795550972223282
  - 10.660956770181656
  - 8.71630311012268
  - 8.68325799703598
  - 10.005599945783615
  - 13.07548475265503
  - 9.287674516439438
  - 10.591159254312515
  - 10.99856436252594
  - 17.120984464883804
  - 17.73465782403946
  - 13.196201860904694
  - 10.402102828025818
  - 10.278905659914017
  - 9.131024107336998
  - 8.698064118623734
  - 8.892197906970978
  - 11.094969153404236
  - 13.624437153339386
  - 13.58727741241455
  - 12.55283734202385
  - 10.22167655825615
  - 11.027212679386139
  - 9.83882388472557
  - 9.111074388027191
  - 9.306822657585144
  - 9.03681629896164
  validation_losses:
  - 0.5223885774612427
  - 0.5097728967666626
  - 0.5018128752708435
  - 0.48688843846321106
  - 0.5555651187896729
  - 102798.8203125
  - 0.7310457229614258
  - 0.4530712068080902
  - 0.46925675868988037
  - 0.5250438451766968
  - 0.40855643153190613
  - 0.46894797682762146
  - 0.6737073063850403
  - 0.7446711659431458
  - 0.5838538408279419
  - 0.46430689096450806
  - 0.42937618494033813
  - 0.5591632723808289
  - 0.42255258560180664
  - 1.3747179508209229
  - 0.7099094390869141
  - 0.5403960943222046
  - 0.6179612874984741
  - 0.8753648996353149
  - 0.5435330867767334
  - 1.0825729370117188
  - 0.8011105060577393
  - 0.4943646788597107
  - 0.6110443472862244
  - 0.510989785194397
  - 0.6477565765380859
  - 0.7954332232475281
  - 0.4744367003440857
  - 0.5256896615028381
  - 0.5047182440757751
  - 0.4584284722805023
  - 0.4531897008419037
  - 0.6359333992004395
  - 0.5496184229850769
  - 0.43409767746925354
  - 0.5334879755973816
  - 0.41622576117515564
  - 0.4732590317726135
  - 0.4527255594730377
  - 0.5964186191558838
  - 0.40864378213882446
  - 0.7362560629844666
  - 0.4459594488143921
  - 0.48013436794281006
  - 0.5194500088691711
  - 0.5038483738899231
  - 1.1167351007461548
  - 0.7550252676010132
  - 0.45843705534935
  - 0.4473479390144348
  - 0.7713160514831543
  - 0.7127611637115479
  - 0.5207149982452393
  - 0.41753849387168884
  - 0.469852089881897
  - 0.5097005367279053
  - 0.5296180248260498
  - 0.4328429400920868
  - 0.44635844230651855
  - 0.4708084464073181
  - 0.4868867099285126
  - 0.6483813524246216
  - 0.6328727602958679
  - 0.45781612396240234
  - 0.40760692954063416
  - 0.4985922873020172
  - 1.0245673656463623
  - 0.6929894089698792
  - 0.47428444027900696
  - 0.44925636053085327
  - 0.41968706250190735
  - 0.5544653534889221
  - 1.2822481393814087
  - 0.4590649902820587
  - 0.448748379945755
  - 0.6289048194885254
  - 0.7717278003692627
  - 0.7897775173187256
  - 0.9282163977622986
  - 0.4401332139968872
  - 0.5837109088897705
  - 0.5417004227638245
  - 0.4716106057167053
  - 0.5254982709884644
  - 0.48532599210739136
  - 0.6394394040107727
  - 0.8970589637756348
  - 0.8339791893959045
  - 0.6147571206092834
  - 0.4547862708568573
  - 0.5228497982025146
  - 0.4526154696941376
  - 0.46920961141586304
  - 0.4139464497566223
  - 0.8374177813529968
training fold messages:
  fold 0 training message: completed 100 epochs without stopping early
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: completed 100 epochs without stopping early
  fold 3 training message: completed 100 epochs without stopping early
  fold 4 training message: stopped training due to stagnating improvement on validation
    loss after 18 epochs
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.8576329331046312, 0.6861063464837049, 0.6106346483704974,
    0.8591065292096219]'
  fold_eval_f1: '[0.0, 0.0, 0.05181347150259067, 0.13688212927756654, 0.0]'
  mean_eval_accuracy: 0.7742226780546174
  mean_f1_accuracy: 0.03773912015603144
  total_train_time: '0:05:27.191245'
