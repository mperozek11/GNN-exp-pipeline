config:
  aggregation: sum
  batch_size: 32
  class_weights: false
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.5
  epochs: 100
  hidden_units:
  - 32
  - 32
  - 32
  - 32
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.1
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: false
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-05 03:49:15.032479'
fold_0_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/121/fold_0_optim_dict.pt
fold_0_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/121/fold_0_state_dict.pt
fold_1_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/121/fold_1_optim_dict.pt
fold_1_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/121/fold_1_state_dict.pt
fold_2_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/121/fold_2_optim_dict.pt
fold_2_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/121/fold_2_state_dict.pt
fold_3_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/121/fold_3_optim_dict.pt
fold_3_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/121/fold_3_state_dict.pt
fold_4_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/121/fold_4_optim_dict.pt
fold_4_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/121/fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 1317.1179496720433
  - 204.14851607382298
  - 153.1330873221159
  - 90.30118761956692
  - 58.74267494678497
  - 56.207723796367645
  - 45.02195729315281
  - 52.70383682847023
  - 43.47353346645832
  - 64.3469308912754
  - 64.5055589824915
  - 58.1082956045866
  - 70.35318966954947
  - 69.30983700603247
  - 48.6514046639204
  - 43.90635985136032
  - 50.13380751013756
  - 43.407265678048134
  - 45.7317536175251
  - 61.79274347424507
  - 78.48199680447578
  - 42.86222058534622
  - 71.87511649727821
  - 61.52194073796272
  - 49.61845597624779
  - 50.39698124304414
  - 53.65988132357597
  - 46.38583788275719
  - 54.65337581932545
  - 61.40617962181568
  - 61.93692389130592
  - 54.43108144402504
  - 60.5512977540493
  - 69.7492642775178
  - 62.319417744874954
  - 47.891315653920174
  - 51.55489347875118
  - 44.836653769016266
  - 57.62374138832092
  - 52.435099974274635
  - 44.04421930015087
  - 41.271264404058456
  - 46.73555168509483
  - 38.09019677340984
  - 72.73211526870728
  - 77.24835081398487
  - 43.93068391084671
  - 57.40783640742302
  - 53.46879795193672
  - 53.92198933660984
  - 42.48501078784466
  - 51.43644765019417
  - 79.0220597088337
  - 44.304280400276184
  - 60.44288797676563
  - 57.635966777801514
  - 79.8668375313282
  - 43.14129850268364
  - 40.02871969342232
  - 63.438671976327896
  - 38.431001394987106
  - 43.21379806101322
  - 56.71625213325024
  - 38.58548727631569
  - 52.78656580299139
  - 81.56899320334196
  - 66.64823964238167
  - 56.556517601013184
  - 48.75668051838875
  - 47.45793715119362
  - 45.42081733047962
  - 50.71625351905823
  - 62.98020097613335
  - 53.51319235563278
  - 64.09285590052605
  - 51.707219779491425
  - 53.79930570721626
  - 44.21295417845249
  - 45.5579139739275
  - 41.634616658091545
  - 45.954434126615524
  - 58.68496362864971
  - 52.97935611009598
  - 45.00576291978359
  - 39.05871716141701
  - 55.67838713526726
  - 63.351615235209465
  - 52.78292879462242
  - 60.09084667265415
  - 44.31839859485626
  - 51.04378151893616
  - 46.31877642869949
  - 59.0758191794157
  - 61.34862971305847
  - 76.83720734715462
  - 67.60376417636871
  - 50.2732672393322
  - 69.23988303542137
  - 54.64235480129719
  - 39.03896363079548
  validation_losses:
  - 2.3741354942321777
  - 0.5745777487754822
  - 0.5194437503814697
  - 0.6337927579879761
  - 0.4726579487323761
  - 0.7856045365333557
  - 0.975703239440918
  - 0.4121057391166687
  - 0.5531455874443054
  - 0.41737332940101624
  - 637.1677856445312
  - 324.4587097167969
  - 0.5385027527809143
  - 0.9033680558204651
  - 2179.858642578125
  - 2164185344.0
  - 0.4226587414741516
  - 1720704384.0
  - 787473408.0
  - 20399495168.0
  - 0.7887125611305237
  - 494693856.0
  - 218925088.0
  - 161856752.0
  - 0.9844843149185181
  - 1.0505074262619019
  - 0.5302995443344116
  - 0.630665123462677
  - 245146400.0
  - 390086144.0
  - 1978209664.0
  - 681230592.0
  - 243491648.0
  - 0.8943153023719788
  - 95970392.0
  - 177480928.0
  - 1.0062423944473267
  - 55777132.0
  - 105999464.0
  - 0.6662036776542664
  - 0.5251999497413635
  - 46751592.0
  - 0.5024271607398987
  - 0.4138824939727783
  - 1.2765949964523315
  - 0.5613864064216614
  - 0.9450846910476685
  - 0.46280384063720703
  - 0.4350631535053253
  - 0.5351759791374207
  - 0.4117087423801422
  - 0.6509302258491516
  - 0.5193686485290527
  - 0.4432615041732788
  - 1.0009770393371582
  - 1.0643880367279053
  - 0.4636356830596924
  - 0.5713631510734558
  - 0.7796212434768677
  - 0.6302077770233154
  - 0.9966736435890198
  - 0.4102374017238617
  - 0.6345489621162415
  - 0.7189485430717468
  - 0.699296772480011
  - 1.4550410509109497
  - 0.5597953200340271
  - 0.8883911371231079
  - 0.43618667125701904
  - 0.7056198120117188
  - 0.4855182468891144
  - 0.5045000910758972
  - 0.4272364675998688
  - 1.0811728239059448
  - 0.5567708015441895
  - 0.8827221989631653
  - 1.044661045074463
  - 0.5093274712562561
  - 0.45316967368125916
  - 0.4700169861316681
  - 1.0044894218444824
  - 0.7490487098693848
  - 0.8139892220497131
  - 0.5290676951408386
  - 0.9086892604827881
  - 1.213670253753662
  - 103789616.0
  - 1.0918906927108765
  - 0.6858765482902527
  - 0.42452359199523926
  - 0.6578813195228577
  - 1.3167413473129272
  - 0.9768831729888916
  - 1.1705068349838257
  - 0.4640393555164337
  - 0.5475375056266785
  - 0.5164058208465576
  - 0.4697634279727936
  - 0.6123568415641785
  - 0.8793185353279114
loss_records_fold1:
  train_losses:
  - 46.826446548104286
  - 59.28461556136608
  - 59.88626818358898
  - 49.46921060979366
  - 51.17612970620394
  - 41.949551686644554
  - 50.33437256515026
  - 45.45622868835926
  - 48.221903413534164
  - 48.64626035094261
  - 65.08801056444645
  - 47.53325167298317
  - 52.759084448218346
  - 61.35435375571251
  - 44.3763809800148
  - 55.58992213010788
  - 50.65493509173393
  - 42.13771568238735
  - 66.81562687456608
  - 65.99093882739544
  - 56.74698290228844
  - 57.72412787377834
  - 53.500291019678116
  - 48.31562161445618
  - 61.033003747463226
  - 49.9875091612339
  - 55.60999538004398
  - 53.32749758660793
  - 56.89446945488453
  - 45.14398568123579
  - 49.48828634619713
  - 45.21751029789448
  - 54.72292107343674
  - 56.435850501060486
  - 47.96407254040241
  - 48.61077907681465
  - 48.145177245140076
  - 41.37551665306091
  - 45.44920992851257
  - 58.07187932729721
  - 50.915561608970165
  - 55.04392705857754
  - 60.343955248594284
  - 57.17996517568827
  - 50.97967069596052
  - 53.43501349538565
  - 50.44920299947262
  - 51.413885712623596
  - 69.29205569624901
  - 49.92627950012684
  - 73.68233792483807
  - 48.56316959857941
  - 52.0318286716938
  - 62.822872176766396
  - 56.637863740324974
  - 55.907848447561264
  - 61.993176728487015
  - 56.09733195602894
  - 51.42385697364807
  - 61.18699337542057
  - 40.876067250967026
  - 47.8505302965641
  - 56.29940401017666
  - 49.95590761303902
  - 44.353089317679405
  - 71.46875795722008
  - 70.01481868326664
  - 58.328820049762726
  - 66.59696102142334
  - 61.847742542624474
  - 80.73277096450329
  - 63.58085339516401
  - 38.73826605081558
  - 42.25504168868065
  - 45.251066625118256
  - 44.65461292862892
  - 70.00204358994961
  - 51.82885283231735
  - 49.658104576170444
  - 63.260531932115555
  - 43.428667798638344
  - 51.223122999072075
  - 55.46527823805809
  - 55.764076232910156
  - 70.8339533507824
  - 71.00707709789276
  - 57.31507821381092
  - 47.92748761177063
  - 51.87601451575756
  - 43.50087629258633
  - 45.972549483180046
  - 43.53854362666607
  - 74.58405227959156
  - 56.5669722110033
  - 57.0904166996479
  - 57.71660378575325
  - 43.98547498881817
  - 62.23252069950104
  - 73.6809356212616
  - 54.50793273746967
  validation_losses:
  - 0.7557878494262695
  - 0.6401796340942383
  - 1.6658934354782104
  - 0.5974975824356079
  - 0.4819253385066986
  - 0.4469766318798065
  - 0.4779278039932251
  - 0.4759078621864319
  - 1.215714931488037
  - 0.8729045987129211
  - 0.4697546362876892
  - 0.7295159697532654
  - 0.5295143723487854
  - 0.5451962351799011
  - 0.5653238892555237
  - 0.470048725605011
  - 0.5832648873329163
  - 0.4704154431819916
  - 1.0252056121826172
  - 0.8386079668998718
  - 0.7971491813659668
  - 0.43436700105667114
  - 0.5068880915641785
  - 0.4443584084510803
  - 0.7452989816665649
  - 0.7970781326293945
  - 0.650702953338623
  - 0.7632834911346436
  - 0.5890763998031616
  - 0.551784336566925
  - 0.5005886554718018
  - 0.5107340216636658
  - 0.46119022369384766
  - 0.9606531858444214
  - 0.6368642449378967
  - 1.4057164192199707
  - 0.5898587107658386
  - 0.4779064357280731
  - 0.7886319160461426
  - 0.6030811071395874
  - 58270648.0
  - 0.6233870983123779
  - 28891762.0
  - 0.6528010368347168
  - 1.290334701538086
  - 0.5667422413825989
  - 0.6714068055152893
  - 1.131956934928894
  - 1.1701159477233887
  - 1.338728427886963
  - 0.968728244304657
  - 1.2053476572036743
  - 0.8361178040504456
  - 0.9024325609207153
  - 1.0872915983200073
  - 0.707661509513855
  - 0.43836283683776855
  - 0.4260409474372864
  - 0.7816177010536194
  - 0.42581772804260254
  - 0.4374828040599823
  - 0.8680009245872498
  - 0.5392978191375732
  - 0.6478873491287231
  - 1.2017121315002441
  - 0.7368326187133789
  - 13848840.0
  - 1.023263931274414
  - 1.958177089691162
  - 0.5026909112930298
  - 0.8387698531150818
  - 0.7298304438591003
  - 0.5373954176902771
  - 0.6957683563232422
  - 0.42461511492729187
  - 1.5380512475967407
  - 0.6828700304031372
  - 0.6670160889625549
  - 0.87986159324646
  - 1.1846396923065186
  - 0.6918447017669678
  - 0.6258552670478821
  - 0.6166737079620361
  - 0.6621741056442261
  - 0.5121946334838867
  - 1.9137606620788574
  - 0.8069543838500977
  - 0.678821325302124
  - 1.5013469457626343
  - 0.4303038716316223
  - 0.6368075609207153
  - 0.49648210406303406
  - 0.7276384234428406
  - 0.7119689583778381
  - 0.676482081413269
  - 0.5864336490631104
  - 1.1876600980758667
  - 0.8797193169593811
  - 1.3820667266845703
  - 0.7033535242080688
loss_records_fold2:
  train_losses:
  - 59.78321471810341
  - 68.31296129524708
  - 51.836063012480736
  - 56.69943377375603
  - 50.33313500881195
  - 49.05099758505821
  - 58.26109375059605
  - 48.03782930970192
  - 43.012665793299675
  - 49.873621582984924
  - 55.52057871222496
  - 53.8431980907917
  - 57.17290584743023
  - 63.67796233296394
  - 50.47272905707359
  - 57.496545657515526
  - 56.15838009119034
  - 58.91615438461304
  - 45.73544618487358
  - 48.031527668237686
  - 45.2430144995451
  - 44.11777251958847
  - 52.615977957844734
  - 48.76392996311188
  - 56.71070762723684
  - 44.61196857690811
  - 53.085596829652786
  - 45.30411332845688
  - 53.38655751943588
  - 63.120412830263376
  - 53.46364565193653
  - 52.08514903485775
  - 76.15026152879
  - 47.63493372499943
  - 47.01780951023102
  - 42.74229697883129
  - 65.95725086331367
  - 49.02206916362047
  - 44.37484572827816
  - 51.76473458111286
  - 57.82818339765072
  - 62.952185690402985
  - 81.15660384297371
  - 60.09494984149933
  - 51.91921502351761
  - 47.05566197633743
  - 59.611456997692585
  - 58.37669599801302
  - 48.34741571545601
  - 42.576417833566666
  - 45.408318765461445
  - 51.60090819001198
  - 53.039236441254616
  - 58.96160152554512
  - 62.707091346383095
  - 50.06872481107712
  - 50.708362981677055
  - 58.2897217720747
  - 62.07169145345688
  - 76.60961435735226
  - 51.87047415971756
  - 49.572341069579124
  - 53.507336631417274
  - 43.71202412247658
  - 47.341546297073364
  - 61.80131833255291
  - 62.28071682155132
  - 47.506269067525864
  - 53.95321637392044
  - 45.24899271130562
  - 47.55693618953228
  - 75.10666954517365
  - 50.35188107192516
  - 45.17626541852951
  - 48.67601543664932
  - 51.46427345275879
  - 62.90552940964699
  - 57.166481256484985
  - 63.82082583755255
  - 46.25265537947416
  - 68.82986752688885
  - 52.50635775923729
  - 48.13983133435249
  - 57.78426684439182
  - 48.01150646805763
  - 58.05914996564388
  - 40.26671144366264
  - 38.769202925264835
  - 38.207862839102745
  - 48.692542381584644
  - 69.41788899898529
  - 56.593194238841534
  - 42.40036281943321
  - 44.201718240976334
  - 50.213775649666786
  - 64.5782470703125
  - 52.82533456385136
  - 69.22671093046665
  - 49.23255583643913
  - 69.8641753718257
  validation_losses:
  - 0.687899649143219
  - 0.7504076957702637
  - 0.8203822374343872
  - 0.5792180895805359
  - 0.820720911026001
  - 0.6888841986656189
  - 0.45392128825187683
  - 0.9861372709274292
  - 0.45627716183662415
  - 0.46540722250938416
  - 0.48486506938934326
  - 0.8757925629615784
  - 0.6087507009506226
  - 0.4652811586856842
  - 1.1669038534164429
  - 0.7906456589698792
  - 0.6942223310470581
  - 0.5217315554618835
  - 0.8359460830688477
  - 0.5025234818458557
  - 0.49580711126327515
  - 0.9156636595726013
  - 0.40569937229156494
  - 0.5437407493591309
  - 0.6121381521224976
  - 0.5079752802848816
  - 0.5142375230789185
  - 0.9955883026123047
  - 0.49298933148384094
  - 0.5767945051193237
  - 0.5876814723014832
  - 0.8934908509254456
  - 0.6963129639625549
  - 0.7716627717018127
  - 0.436544269323349
  - 0.5193732976913452
  - 0.4187159836292267
  - 0.5810547471046448
  - 0.4784771203994751
  - 1.1974425315856934
  - 0.766535758972168
  - 1.7571293115615845
  - 0.7319458723068237
  - 0.7735012769699097
  - 0.6264119148254395
  - 0.9613220691680908
  - 0.7641506791114807
  - 0.48949509859085083
  - 0.7134139537811279
  - 0.43772414326667786
  - 0.6586317420005798
  - 0.5587038397789001
  - 0.8808161616325378
  - 0.7998864650726318
  - 0.8757364153862
  - 0.633516252040863
  - 0.8603039383888245
  - 0.6255655884742737
  - 54541572.0
  - 0.4651558995246887
  - 0.4686068892478943
  - 0.6540877819061279
  - 0.5452710390090942
  - 0.5081394910812378
  - 0.5269978642463684
  - 0.5141071677207947
  - 0.5698168277740479
  - 0.9737356305122375
  - 0.4047097861766815
  - 0.5891176462173462
  - 0.5162816643714905
  - 0.7804465889930725
  - 0.4572986364364624
  - 0.7538765668869019
  - 0.7289547920227051
  - 0.7316327691078186
  - 0.7184218764305115
  - 0.8974682092666626
  - 0.6389028429985046
  - 0.8871200680732727
  - 0.4605969488620758
  - 0.4530089199542999
  - 0.41307997703552246
  - 0.5486704707145691
  - 1.1618400812149048
  - 0.5367528200149536
  - 0.4964359998703003
  - 0.3978478014469147
  - 0.7184836864471436
  - 0.7183883190155029
  - 0.8410846590995789
  - 0.5630149841308594
  - 0.40910786390304565
  - 0.458292692899704
  - 0.4668939411640167
  - 0.4628327488899231
  - 0.9007114171981812
  - 0.6757939457893372
  - 0.8037375211715698
  - 1.3328698873519897
loss_records_fold3:
  train_losses:
  - 64.53763192147017
  - 54.13314101099968
  - 53.26208418607712
  - 52.04570892453194
  - 62.02484551072121
  - 58.418619744479656
  - 49.41266779601574
  - 45.84320145845413
  - 53.17830815911293
  - 45.931034073233604
  - 45.82258731126785
  - 67.43861044943333
  - 54.58779090642929
  - 66.09335293620825
  - 53.548784881830215
  - 57.095341861248016
  - 60.35377436876297
  - 47.88646738231182
  - 43.645963698625565
  - 52.41695334017277
  - 55.133253797888756
  - 37.564327999949455
  - 51.548638075590134
  - 52.11968043446541
  - 58.0461291372776
  - 42.8170221298933
  - 51.67644266784191
  - 73.67529283463955
  - 55.02842400968075
  - 46.99932359158993
  - 51.17876434326172
  - 45.38896848261356
  - 46.68838581442833
  - 65.27866579592228
  - 80.14777196198702
  - 58.68596179783344
  - 61.29507137835026
  - 62.93943214416504
  - 54.529701083898544
  - 55.29284222796559
  - 42.33253522217274
  - 39.245836436748505
  - 55.455845944583416
  - 45.129782646894455
  - 51.77243474125862
  - 58.61997666209936
  - 55.30875461176038
  - 47.85539053380489
  - 52.43109704554081
  - 40.78856559097767
  - 46.87929877638817
  - 62.175243735313416
  - 55.97027074173093
  - 48.66719238460064
  - 83.53610648214817
  - 52.32667241990566
  - 51.58368392288685
  - 51.278316125273705
  - 45.29390576481819
  - 49.004599541425705
  - 46.53305998444557
  - 52.45048455148935
  - 55.58478423953056
  - 47.37685614824295
  - 51.876795172691345
  - 50.64537271857262
  - 49.51185995340347
  - 60.213679149746895
  - 55.648416347801685
  - 64.17739626765251
  - 61.30274560302496
  - 61.08314488083124
  - 61.89918579161167
  - 61.60948467999697
  - 51.26756630837917
  - 49.25532823801041
  - 47.532258689403534
  - 64.52007785439491
  - 47.847657322883606
  - 54.2593499571085
  - 48.64434267580509
  - 58.46967655420303
  - 58.99780498445034
  - 56.523482501506805
  - 54.80099260807037
  - 83.60480029881
  - 75.23398662358522
  - 46.951487228274345
  - 83.34259650111198
  - 50.61018389463425
  - 47.68876637518406
  - 36.25102913379669
  - 38.47530582547188
  - 50.672065034508705
  - 53.479556649923325
  - 44.8753300011158
  - 51.37193125486374
  - 49.86089810729027
  - 98.99931306391954
  - 56.262408904731274
  validation_losses:
  - 0.5827077627182007
  - 2.0639967918395996
  - 0.4966854155063629
  - 0.6571164727210999
  - 0.8135724067687988
  - 1.1766488552093506
  - 0.7056217789649963
  - 67118504.0
  - 0.48035338521003723
  - 0.41825225949287415
  - 1.1379139423370361
  - 0.4645874798297882
  - 0.7141510248184204
  - 0.4436342418193817
  - 0.4249861240386963
  - 0.5085891485214233
  - 0.4417060911655426
  - 0.9071093201637268
  - 0.4204334020614624
  - 0.6210247874259949
  - 0.6388831734657288
  - 0.6147300004959106
  - 0.535292387008667
  - 1.1136958599090576
  - 0.5460825562477112
  - 0.9565569162368774
  - 0.9374909400939941
  - 0.6961537003517151
  - 0.4689192473888397
  - 1.0784493684768677
  - 0.4249210059642792
  - 0.5863543748855591
  - 1.3863682746887207
  - 0.9565513730049133
  - 0.9083681702613831
  - 0.6040109395980835
  - 0.7876860499382019
  - 0.8325950503349304
  - 1.273368239402771
  - 0.44359996914863586
  - 0.49905848503112793
  - 1.1696856021881104
  - 0.4466884732246399
  - 0.47357964515686035
  - 0.7340545654296875
  - 0.9623821377754211
  - 1.0148957967758179
  - 0.4661916196346283
  - 0.46847692131996155
  - 0.4228459596633911
  - 0.6361452341079712
  - 0.5325927734375
  - 0.6933424472808838
  - 0.5126738548278809
  - 0.7088115811347961
  - 0.9261353611946106
  - 0.4340146780014038
  - 0.45404091477394104
  - 0.478057861328125
  - 0.6279172301292419
  - 0.43929773569107056
  - 0.7068942189216614
  - 0.6728187203407288
  - 0.85892254114151
  - 0.7771145701408386
  - 0.6819362640380859
  - 1.038388967514038
  - 0.42303702235221863
  - 0.4686881899833679
  - 1.0730844736099243
  - 0.6313005685806274
  - 0.666793704032898
  - 1.1975924968719482
  - 0.716909646987915
  - 0.8334787487983704
  - 0.5891714096069336
  - 0.7711808085441589
  - 1.0145944356918335
  - 0.5845571756362915
  - 0.4370661675930023
  - 1.278807282447815
  - 0.6446841359138489
  - 1.2949273586273193
  - 0.5128476619720459
  - 1.5178155899047852
  - 1.1783684492111206
  - 0.587036669254303
  - 1.186458945274353
  - 0.41894373297691345
  - 0.8077290058135986
  - 0.438714861869812
  - 0.5567296147346497
  - 1.0295295715332031
  - 0.5495359897613525
  - 0.7061748504638672
  - 0.4385398328304291
  - 0.4821087121963501
  - 2.4110031127929688
  - 1.4980459213256836
  - 0.6377803683280945
loss_records_fold4:
  train_losses:
  - 50.54810646176338
  - 45.882227689027786
  - 37.2129342854023
  - 47.56451854109764
  - 54.651238575577736
  - 46.353040650486946
  - 45.599289029836655
  - 52.38354405760765
  - 63.887210458517075
  - 63.385966919362545
  - 52.842211470007896
  - 53.085281401872635
  - 46.001850351691246
  - 56.51530368626118
  - 39.28333431482315
  - 50.165942162275314
  - 63.47398068010807
  - 79.26008019596338
  - 50.635274201631546
  - 44.28673657774925
  - 70.47665071487427
  - 58.4686888307333
  - 53.64527836441994
  - 45.289638221263885
  - 45.346374318003654
  - 69.3484598994255
  - 59.37297186255455
  - 52.01365289837122
  - 40.36210846155882
  - 57.77547046542168
  - 41.022649988532066
  - 48.33049514889717
  - 58.603323608636856
  - 62.952739745378494
  - 76.90331721305847
  - 59.875508069992065
  - 46.153431951999664
  - 68.53246673941612
  - 65.69550840556622
  - 45.08461132645607
  - 69.32461865246296
  - 50.19041088223457
  - 67.50867696106434
  - 56.76220725476742
  - 49.46011835336685
  - 41.915917962789536
  - 38.28068520128727
  - 49.76471121609211
  - 55.01263001561165
  - 62.150935649871826
  - 49.67394694685936
  - 45.06538647413254
  - 51.22756923735142
  - 45.33420480787754
  - 57.55990095436573
  - 63.95461183786392
  - 59.52085579931736
  - 63.59176217019558
  - 47.78399467840791
  - 66.34267356991768
  - 39.18586425483227
  - 58.75550699606538
  - 68.4837978631258
  - 56.50399650633335
  - 49.94816176593304
  - 77.45427043735981
  - 45.024848863482475
  - 41.41740767657757
  - 38.99211621284485
  - 53.56624457240105
  - 73.48542305827141
  - 59.06272193789482
  - 51.83423130214214
  - 46.87683931738138
  - 59.93915082514286
  - 49.9050575196743
  - 72.70370618999004
  - 65.32221299409866
  - 59.48076577484608
  - 59.05330988764763
  - 89.5296493768692
  - 72.81400478631258
  - 77.00613577663898
  - 57.90292830020189
  - 53.981104865670204
  - 45.302015498280525
  - 52.87253034114838
  - 67.82720249891281
  - 44.683549240231514
  - 55.9083918184042
  - 48.04920472204685
  - 48.32151307165623
  - 47.946787133812904
  - 55.05799816548824
  - 58.235605239868164
  - 65.96331948041916
  - 47.5905539393425
  - 45.03293952345848
  - 76.80970969796181
  - 52.72102566063404
  validation_losses:
  - 0.6239901781082153
  - 0.4061402976512909
  - 0.4775620400905609
  - 0.5415893197059631
  - 0.5980744957923889
  - 0.6006366014480591
  - 0.5084523558616638
  - 0.7958002090454102
  - 0.7422700524330139
  - 1.283941388130188
  - 0.6407149434089661
  - 10088219.0
  - 0.9473506808280945
  - 0.576256275177002
  - 0.4754766821861267
  - 0.6110258102416992
  - 1.3971065282821655
  - 0.6100912094116211
  - 0.9709779024124146
  - 0.7105310559272766
  - 1.762709617614746
  - 0.6131638288497925
  - 62954304.0
  - 0.44381505250930786
  - 0.6176722049713135
  - 1.2795580625534058
  - 0.6917117238044739
  - 0.485626757144928
  - 0.6780182123184204
  - 0.6215133666992188
  - 0.48560771346092224
  - 1.2515454292297363
  - 62954304.0
  - 1.0072497129440308
  - 0.9249480366706848
  - 0.5709440112113953
  - 0.646243155002594
  - 0.5878556966781616
  - 0.5004070997238159
  - 0.5659682750701904
  - 0.6100636124610901
  - 0.6398446559906006
  - 0.5044867396354675
  - 0.9024447798728943
  - 0.4753013253211975
  - 0.39905551075935364
  - 0.9323842525482178
  - 0.8541107177734375
  - 0.5097234845161438
  - 1.3742603063583374
  - 0.8923027515411377
  - 0.5467675924301147
  - 0.5201439261436462
  - 0.659626841545105
  - 0.9306480288505554
  - 1.1125247478485107
  - 1.078131079673767
  - 0.8784171938896179
  - 0.8577568531036377
  - 0.47874340415000916
  - 0.4235653877258301
  - 0.9932845830917358
  - 0.9676159620285034
  - 0.699131429195404
  - 0.569441020488739
  - 0.5894687175750732
  - 0.5531929135322571
  - 0.534135103225708
  - 0.45639553666114807
  - 0.5699470043182373
  - 0.8124397397041321
  - 0.5547451972961426
  - 0.8101691007614136
  - 0.8192972540855408
  - 0.4941156804561615
  - 1.4013633728027344
  - 0.43308961391448975
  - 0.4531804919242859
  - 0.515742301940918
  - 1.427803635597229
  - 1.1798856258392334
  - 1.032615065574646
  - 0.6169893741607666
  - 0.46518856287002563
  - 0.6736600995063782
  - 0.6317224502563477
  - 1.4130096435546875
  - 0.6885777711868286
  - 0.7218407988548279
  - 0.8817233443260193
  - 0.4604986608028412
  - 0.4620216190814972
  - 0.47741296887397766
  - 0.7443810105323792
  - 0.5067896842956543
  - 0.6443097591400146
  - 0.5454780459403992
  - 0.4078960418701172
  - 0.5395652651786804
  - 1.1140732765197754
training fold messages:
  fold 0 training message: completed 100 epochs without stopping early
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: completed 100 epochs without stopping early
  fold 3 training message: completed 100 epochs without stopping early
  fold 4 training message: completed 100 epochs without stopping early
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.8576329331046312, 0.7238421955403087, 0.8593481989708405,
    0.8591065292096219]'
  fold_eval_f1: '[0.0, 0.0, 0.19900497512437812, 0.0, 0.0]'
  mean_eval_accuracy: 0.8315125579860065
  mean_f1_accuracy: 0.03980099502487562
  total_train_time: '0:23:18.187661'
