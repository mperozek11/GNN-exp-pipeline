config:
  aggregation: sum
  batch_size: 32
  class_weights: false
  data:
    dataset: WICO
    pre_filter: filter_5g_non
    pre_transform: wico_data_to_custom
    root: wico
  dataset: wico
  device: cuda
  dropout: 0.5
  epochs: 100
  hidden_units:
  - 64
  - 64
  - 64
  improvement_threshold: 0.01
  kfolds: 5
  loss_fn: CrossEntropyLoss
  lr: 0.1
  model: GIN
  optimizer: Adam
  patience: 7
  train_eps: true
  transform: wico_5g_vs_non_conspiracy
experiment_run_start: '2022-08-05 07:55:40.310983'
fold_0_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/153/fold_0_optim_dict.pt
fold_0_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/153/fold_0_state_dict.pt
fold_1_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/153/fold_1_optim_dict.pt
fold_1_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/153/fold_1_state_dict.pt
fold_2_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/153/fold_2_optim_dict.pt
fold_2_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/153/fold_2_state_dict.pt
fold_3_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/153/fold_3_optim_dict.pt
fold_3_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/153/fold_3_state_dict.pt
fold_4_optim_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/153/fold_4_optim_dict.pt
fold_4_state_dict: /home/maxpzk/GNN-exp-pipeline/result/experiment_08.04.2022_13.23.59/153/fold_4_state_dict.pt
loss_records_fold0:
  train_losses:
  - 1355.8324420452118
  - 682.5077980384231
  - 207.99580001831055
  - 131.9407847672701
  - 185.0672336667776
  - 215.04936403036118
  - 180.0521919131279
  - 164.0975970029831
  - 498.32119077444077
  - 86.60290786623955
  - 47.48159621655941
  - 58.29796189814806
  - 44.50162556767464
  - 47.22252747416496
  - 47.306080400943756
  - 51.14336805045605
  - 45.86734226346016
  - 50.84407576173544
  - 63.270080640912056
  - 377.46007968485355
  - 70.26176814734936
  - 55.370533779263496
  - 57.59097205102444
  - 49.39229337871075
  - 53.01298297941685
  - 42.92832863330841
  - 54.670565851032734
  - 63.015816405415535
  - 43.40071052312851
  - 50.16838809847832
  - 56.641565069556236
  - 45.794484347105026
  - 56.260940074920654
  - 43.565161138772964
  - 58.615708112716675
  - 64.9708523452282
  - 49.60896396636963
  - 61.26125578582287
  - 46.89057180285454
  - 72.63704335689545
  - 54.241188779473305
  - 47.9879679530859
  - 50.0217250585556
  - 45.49758853018284
  - 48.273828476667404
  - 77.35814197361469
  - 46.840058386325836
  - 54.61942118406296
  - 56.0795708745718
  - 70.28587652742863
  - 61.50749395787716
  - 45.66669565439224
  - 46.85923996567726
  - 47.24427376687527
  - 44.32929649949074
  - 35.86327551305294
  - 37.714454635977745
  - 38.27152393758297
  - 44.36256258189678
  - 69.11132177710533
  - 93.0928854495287
  - 60.58655811846256
  - 47.87319825589657
  - 52.3166074603796
  - 45.70836591720581
  - 39.68028102815151
  - 48.46164797991514
  - 45.284390196204185
  - 78.61057160794735
  - 44.846300199627876
  - 62.25488516129553
  - 51.76525191962719
  - 58.47162267565727
  - 47.20210348069668
  - 41.37506826967001
  - 51.97464910149574
  - 56.54954606294632
  - 46.657429590821266
  - 42.408957824110985
  - 53.60529938340187
  - 78.32102285325527
  - 38.867504596710205
  - 49.73590126633644
  - 65.01330798864365
  - 67.83386564254761
  - 63.066370114684105
  - 51.3021894544363
  - 62.48776361346245
  - 38.03563618659973
  - 52.64872997254133
  - 47.20810289680958
  - 48.89356006681919
  - 45.71794103085995
  - 53.68234808743
  - 37.97757466137409
  - 46.804743722081184
  - 61.87803228199482
  - 54.981143951416016
  - 64.2700617313385
  - 58.43369670212269
  validation_losses:
  - 0.6680735349655151
  - 1.7784924507141113
  - 0.41541922092437744
  - 0.6349155306816101
  - 0.7517523765563965
  - 2.404860496520996
  - 0.5580815076828003
  - 958.1591186523438
  - 2.4227004051208496
  - 1.0585607290267944
  - 0.4492715299129486
  - 0.4806891977787018
  - 0.9186809659004211
  - 0.4145788550376892
  - 0.4972764551639557
  - 1.096329927444458
  - 0.5497236847877502
  - 0.474677175283432
  - 0.8810924291610718
  - 0.7024397850036621
  - 862.5821533203125
  - 7506102.0
  - 147.95907592773438
  - 184.6107940673828
  - 36.361366271972656
  - 10893939.0
  - 16129845.0
  - 2374608.75
  - 74303744.0
  - 17400426.0
  - 28717500.0
  - 0.5726003646850586
  - 16.27757453918457
  - 1.0576611757278442
  - 11.273065567016602
  - 5.5365309715271
  - 0.7339223027229309
  - 4.999685287475586
  - 5.371188640594482
  - 8.02049732208252
  - 4.331523895263672
  - 6.260889053344727
  - 5.078812599182129
  - 0.493267297744751
  - 0.7890443801879883
  - 250124928.0
  - 6515076096.0
  - 7503461888.0
  - 6556823040.0
  - 7562750976.0
  - 981841472.0
  - 1695508480.0
  - 717690624.0
  - 1364735488.0
  - 38.647647857666016
  - 7.105584621429443
  - 633515136.0
  - 2.8937767358562304e+16
  - 1.283571914375168e+16
  - 485727936.0
  - 561191744.0
  - 3.905541752278221e+16
  - 5.306729735441613e+16
  - 2.256019833801933e+16
  - 21665558.0
  - 6427921.5
  - 1461949288153088.0
  - 5515304943747072.0
  - 6915378919768064.0
  - 5310990128250880.0
  - 3366041300238336.0
  - 4905662253367296.0
  - 5002820319182848.0
  - 5017896728133632.0
  - 3.1067988872528076
  - 5.422719478607178
  - 4.639582633972168
  - 12.732658386230469
  - 118155792.0
  - 1.6240404844284058
  - 5153631116460032.0
  - 608356213456896.0
  - 1.2110783425019904e+16
  - 6096375364190208.0
  - 1.5771568734994432e+16
  - 4967999408701440.0
  - 3862125592182784.0
  - 1.302384944873472e+16
  - 8946130188500992.0
  - 5763614719868928.0
  - 1359886369685504.0
  - 5.405653953552246
  - 0.667136549949646
  - 4065708921061376.0
  - 5698231895851008.0
  - 5.072423934936523
  - 7245121812692992.0
  - 1.2671658909237248e+16
  - 5.974902629852295
  - 1.1611112298512384e+16
loss_records_fold1:
  train_losses:
  - 54.87033639475703
  - 64.58830299973488
  - 49.71626168489456
  - 61.46117751300335
  - 38.879164308309555
  - 49.93428215384483
  - 57.19276624917984
  - 53.86192877590656
  - 54.05712874978781
  - 50.325685262680054
  - 54.98677909374237
  - 46.66244396567345
  - 60.82523766160011
  - 51.16964139044285
  - 52.592069923877716
  - 80.27982707321644
  - 61.12088952958584
  - 63.79236215353012
  - 40.9584044367075
  - 58.90056338906288
  - 50.38846142590046
  - 62.55299583077431
  - 43.187907710671425
  - 44.36416149139404
  - 58.38982807099819
  - 46.699030339717865
  - 72.03127934038639
  - 67.65942066907883
  - 61.332066625356674
  - 40.9875610768795
  - 45.13910995423794
  - 47.71424722671509
  - 50.566155791282654
  - 57.942935451865196
  - 52.62027698755264
  - 47.58271472901106
  - 53.17745818197727
  - 52.95046393573284
  - 61.318081721663475
  - 52.94247616827488
  - 56.39283727109432
  - 59.318588741123676
  - 55.43366160988808
  - 55.83667628467083
  - 69.68261778354645
  - 59.180546790361404
  - 51.612628467381
  - 56.14632514119148
  - 57.07023364305496
  - 62.62792590260506
  - 54.4552556425333
  - 69.7518282532692
  - 44.905950114130974
  - 47.8844323605299
  - 86.18766948580742
  - 76.92921474575996
  - 43.5965019762516
  - 53.43208368122578
  - 49.820081278681755
  - 51.750578969717026
  - 54.18409515917301
  - 45.89071486890316
  - 49.68535542488098
  - 48.921458065509796
  - 50.327322736382484
  - 46.5774562060833
  - 69.76456458866596
  - 50.76798942685127
  - 46.3171294182539
  - 45.479024678468704
  - 40.92231531441212
  - 55.342593759298325
  - 64.07771587371826
  - 44.183890864253044
  - 52.0596681535244
  - 53.46442931890488
  - 46.38610212504864
  - 57.53225928544998
  - 47.50160609185696
  - 54.87396402657032
  - 57.46092228591442
  - 51.354762613773346
  - 51.80635741353035
  - 50.08313010632992
  - 47.48050633072853
  - 50.175116792321205
  - 44.887465223670006
  - 40.49758222699165
  - 51.19308423995972
  - 64.07757644355297
  - 54.291986756026745
  - 46.67213687300682
  - 56.44588004052639
  - 59.78213919699192
  - 54.48437488079071
  - 77.03075249493122
  - 93.92735287547112
  - 48.23100205883384
  - 42.252335637807846
  - 63.99545571208
  validation_losses:
  - 7440126212833280.0
  - 3662000785719296.0
  - 5.838174343109131
  - 5841361144119296.0
  - 4299597539180544.0
  - 7.9894304275512695
  - 3189010801360896.0
  - 4703028380696576.0
  - 6109062160711680.0
  - 1.3913545608520508
  - 99117854359552.0
  - 7.395159721374512
  - 4.053246021270752
  - 3953257550446592.0
  - 11.92294692993164
  - 4265598041194496.0
  - 0.6870615482330322
  - 0.4367167353630066
  - 1.368413624598528e+16
  - 1.094501011554304e+16
  - 448196748771328.0
  - 4335320661229568.0
  - 3361703114833920.0
  - 1454190161297408.0
  - 447915596185600.0
  - 4987734783426560.0
  - 9417252667392000.0
  - 5970380887949312.0
  - 2.3057572841644287
  - 3892115201327104.0
  - 5003055468642304.0
  - 3571483544649728.0
  - 78376324825088.0
  - 1.1153421256097792e+16
  - 9882629553782784.0
  - 3875737954156544.0
  - 3985823066226688.0
  - 524292898947072.0
  - 1.3411965242179584e+16
  - 9565680294690816.0
  - 581407306940416.0
  - 3609970209718272.0
  - 3206690228928512.0
  - 4093920950616064.0
  - 129936509632512.0
  - 12.200313568115234
  - 1.5165163278579712
  - 4974700094554112.0
  - 3972558328168448.0
  - 287597351927808.0
  - 9071798784098304.0
  - 66101270544384.0
  - 4340252357427200.0
  - 12.624780654907227
  - 458783272730624.0
  - 526405821530112.0
  - 1.130112196018176e+16
  - 5096912852090880.0
  - 1073936104161280.0
  - 1.2548626349817856e+16
  - 3789333949579264.0
  - 1.0376103042482176e+16
  - 3156759623499776.0
  - 281226153820160.0
  - 4520697892175872.0
  - 4545806270988288.0
  - 3518277489786880.0
  - 3.187094211578369
  - 9.28372573852539
  - 0.4749020040035248
  - 0.8206296563148499
  - 746910528.0
  - 6506557440.0
  - 1.2733608443772928e+16
  - 1.069365789196288e+16
  - 4520742989332480.0
  - 4202859843289088.0
  - 9330838999138304.0
  - 2221867649728512.0
  - 6942241255849984.0
  - 3733579905368064.0
  - 6074983205830656.0
  - 107862432.0
  - 4648979438501888.0
  - 5685234.0
  - 8733455219163136.0
  - 28732257468416.0
  - 473276000.0
  - 32602818.0
  - 141704006991872.0
  - 1.218840314773504e+16
  - 615117632831488.0
  - 4443891260456960.0
  - 68748560.0
  - 28073988.0
  - 4464707624763392.0
  - 4564851766591488.0
  - 78617576.0
  - 9259353563463680.0
  - 833620738572288.0
loss_records_fold2:
  train_losses:
  - 73.3569378554821
  - 45.8756300508976
  - 45.461095333099365
  - 58.786976896226406
  - 52.50679537653923
  - 55.20960934460163
  - 73.20093719661236
  - 63.21543177962303
  - 61.267713993787766
  - 57.00385361909866
  - 68.32805143296719
  - 46.864728927612305
  - 50.68295869231224
  - 62.097647689282894
  - 71.422581538558
  - 58.115496546030045
  - 63.64824461936951
  - 39.77931326627731
  - 44.15858739614487
  - 60.134675070643425
  - 59.830335944890976
  - 79.15248377621174
  - 55.15110516920686
  - 45.45478090643883
  - 53.541377395391464
  - 61.59352594614029
  - 52.17864901572466
  - 56.24468877911568
  - 40.65401743352413
  - 54.36571457982063
  - 51.55894050002098
  - 43.026415050029755
  - 65.27185044437647
  - 54.25911274552345
  - 45.87897242605686
  - 47.476040467619896
  - 48.911611109972
  - 64.8371088206768
  - 63.71839403361082
  - 52.97292214632034
  - 51.518168076872826
  - 68.37096308171749
  - 50.70781844854355
  - 51.747484520077705
  - 50.740983322262764
  - 55.48225785791874
  - 47.023807629942894
  - 62.13472279906273
  - 67.51947771012783
  - 54.03571629524231
  - 58.321602158248425
  - 53.493313536047935
  - 48.74825508892536
  - 41.888410940766335
  - 61.98062399029732
  - 62.02728636562824
  - 52.75346040725708
  - 49.861869648098946
  - 59.36628668755293
  - 47.365111500024796
  - 58.52376952767372
  - 42.04391999542713
  - 39.340869769454
  - 54.38006031513214
  - 45.08910249173641
  - 60.67807610332966
  - 42.20976461470127
  - 59.62440177798271
  - 65.28550024330616
  - 63.12211358547211
  - 74.71457013487816
  - 61.305117413401604
  - 51.231448754668236
  - 52.82837277650833
  - 58.380319342017174
  - 43.61775356531143
  - 55.767618268728256
  - 61.13903987407684
  - 42.856474474072456
  - 69.840332724154
  - 48.76310870051384
  - 49.531425416469574
  - 65.5160551816225
  - 56.054509714245796
  - 53.62333995103836
  - 43.882790237665176
  - 39.988704055547714
  - 42.26162646710873
  - 64.74087183177471
  - 50.672244504094124
  - 66.78579733520746
  - 51.36453324556351
  - 58.95381362736225
  - 62.982723623514175
  - 56.61969491839409
  - 45.73573079705238
  - 55.732992216944695
  - 56.428551971912384
  - 49.311584144830704
  - 58.596540451049805
  validation_losses:
  - 238426304.0
  - 3178960309452800.0
  - 166119503560704.0
  - 7147606727720960.0
  - 73276784.0
  - 6536764667723776.0
  - 21447028.0
  - 3994902090219520.0
  - 4452172494274560.0
  - 1.374411546427392e+16
  - 1.1797248664928256e+16
  - 0.7628775238990784
  - 6122767401353216.0
  - 6727067152416768.0
  - 56772903567360.0
  - 1.6345381734449152e+16
  - 370125114966016.0
  - 1.870627693867827e+16
  - 3863872838565888.0
  - 6341179910127616.0
  - 1.2392882245730304e+16
  - 6629522539544576.0
  - 1.6463207006454468
  - 6335658192797696.0
  - 6510146071035904.0
  - 5069415934590976.0
  - 6290278642089984.0
  - 3710442916544512.0
  - 1742583525015552.0
  - 6764756564180992.0
  - 3.7958319187164307
  - 3.7996208667755127
  - 196131678060544.0
  - 4.680899143218994
  - 6608393984802816.0
  - 6409087101173760.0
  - 116183604920320.0
  - 1.2989326501609472e+16
  - 1.187542888087552e+16
  - 1.4924878209613824e+16
  - 1.3855815752482816e+16
  - 5973838336622592.0
  - 7886798516649984.0
  - 5495404749651968.0
  - 8477192749056.0
  - 444135018332160.0
  - 518282259988480.0
  - 4363843807477760.0
  - 1480030026727424.0
  - 7513234072403968.0
  - 4500367664480256.0
  - 4814098919325696.0
  - 5643736277057536.0
  - 6655004043640832.0
  - 8071515933245440.0
  - 5.446681976318359
  - 4020127775326208.0
  - 4458922840686592.0
  - 8686388283179008.0
  - 5782423455399936.0
  - 2.3722646236419678
  - 693323752800256.0
  - 1583400091648000.0
  - 393924233396224.0
  - 2870505153495040.0
  - 8578984036007936.0
  - 4779301094293504.0
  - 1.889907802059571e+16
  - 33127296663552.0
  - 1.8787694486224896e+16
  - 5461626979352576.0
  - 5368458401284096.0
  - 6295204969578496.0
  - 5555913859530752.0
  - 8.324759483337402
  - 1.6047938069331968e+16
  - 14.671319007873535
  - 11.039190292358398
  - 4841493294481408.0
  - 6449282626355200.0
  - 6536087136632832.0
  - 5.943961143493652
  - 846685760651264.0
  - 1.4938901277835264e+16
  - 1210711283859456.0
  - 751847111393280.0
  - 1.5232617985081344e+16
  - 4853563226324992.0
  - 6278366550294528.0
  - 6163639383883776.0
  - 8087417512787968.0
  - 3.4676647186279297
  - 6238596763746304.0
  - 5614015103369216.0
  - 843748539891712.0
  - 1.5761410063597568e+16
  - 6777231296692224.0
  - 7.207718372344971
  - 6391464850358272.0
  - 5308368050716672.0
loss_records_fold3:
  train_losses:
  - 46.94086064398289
  - 56.53105045855045
  - 54.34721574187279
  - 50.88618305325508
  - 57.47001597285271
  - 61.930743023753166
  - 45.71427944302559
  - 52.70727113634348
  - 75.02338771894574
  - 42.138699784874916
  - 38.115187749266624
  - 50.73942622542381
  - 73.81094249337912
  - 59.00034520030022
  - 42.210345670580864
  - 61.750958532094955
  - 67.04574363678694
  - 45.20403999090195
  - 58.868133559823036
  - 49.12100102007389
  - 45.02794501185417
  - 60.06245440244675
  - 57.23540087044239
  - 43.48589128255844
  - 65.06141655147076
  - 45.30694930255413
  - 42.436581924557686
  - 41.053575441241264
  - 55.192756965756416
  - 60.136020474135876
  - 49.79029643535614
  - 54.113241240382195
  - 56.80842439830303
  - 46.77109271287918
  - 51.14701119065285
  - 52.818589106202126
  - 59.08388406038284
  - 55.203949734568596
  - 41.9054334834218
  - 88.6370236761868
  - 42.26444225013256
  - 45.341936871409416
  - 56.750297501683235
  - 45.29657036066055
  - 52.37152634561062
  - 67.77525609731674
  - 41.99481798708439
  - 49.726606003940105
  - 50.81633070111275
  - 55.129541873931885
  - 52.036907494068146
  - 75.92851403355598
  - 73.53866688907146
  - 64.29880126565695
  - 59.93184030056
  - 42.806634932756424
  - 44.82633198797703
  - 46.08431380242109
  - 41.420311629772186
  - 46.29837466776371
  - 48.25996495783329
  - 51.8755639642477
  - 50.92927159368992
  - 49.54164199531078
  - 53.75933952629566
  - 82.37176494300365
  - 97.21666173636913
  - 79.25744031742215
  - 60.10566107183695
  - 58.124942898750305
  - 64.38301063328981
  - 39.25778213143349
  - 46.026037126779556
  - 78.3909759670496
  - 48.89652615785599
  - 48.02200283110142
  - 56.96661250293255
  - 59.215529300272465
  - 44.967930898070335
  - 54.23444555327296
  - 63.76298648118973
  - 60.57430413365364
  - 49.70653548836708
  - 54.83481493592262
  - 57.2152818441391
  - 47.58247557282448
  - 59.62694150209427
  - 52.149009972810745
  - 52.56631097197533
  - 55.11246786266565
  - 68.41630345582962
  - 43.05190293490887
  - 41.15699956566095
  - 38.69632562994957
  - 60.81795969605446
  - 74.12685576081276
  - 45.9445286244154
  - 51.30185906589031
  - 54.87594683468342
  - 51.93503038585186
  validation_losses:
  - 2.29676597379072e+16
  - 2.156439943302349e+16
  - 2378964668514304.0
  - 2.7897472592379904e+16
  - 279674580107264.0
  - 1.3443614856183808e+16
  - 8496273703305216.0
  - 5842734459912192.0
  - 2.12127361007616e+16
  - 695980726943744.0
  - 2.3298376514666496e+16
  - 2.5943077789106176e+16
  - 434759507378176.0
  - 9701608493416448.0
  - 567545165774848.0
  - 7508591212756992.0
  - 8932554333749248.0
  - 5.225362300872803
  - 6.705318927764893
  - 1.4618154193911808e+16
  - 4.210247039794922
  - 1.0276923657682944e+16
  - 2.0607903773753344e+16
  - 9304388443045888.0
  - 9144645724405760.0
  - 1705711230779392.0
  - 1593694322950144.0
  - 7116329165258752.0
  - 9646797194526720.0
  - 6055597870940160.0
  - 6.727913856506348
  - 1.0817072703471616e+16
  - 2.847292900085449
  - 680715674976256.0
  - 8210091979309056.0
  - 8517684652146688.0
  - 9398522315014144.0
  - 9742890645323776.0
  - 7464819590430720.0
  - 323939150594048.0
  - 1.1043792215867392e+16
  - 2.012541359017165e+16
  - 1.1107589660082176e+16
  - 80574660214784.0
  - 2.739917478166528e+16
  - 8649908441579520.0
  - 8214544786653184.0
  - 1.4219829263204352e+16
  - 1.4356329766322176e+16
  - 6415912877948928.0
  - 0.7535609006881714
  - 12.33458423614502
  - 1090141082877952.0
  - 6791677956063232.0
  - 9189592557158400.0
  - 0.4284523129463196
  - 9598057905651712.0
  - 1.746748703768576e+16
  - 1.0688264486780928e+16
  - 2.1331487651528704e+16
  - 7857561600524288.0
  - 8.989784240722656
  - 11.851107597351074
  - 1.4266908547219456e+16
  - 8431319302275072.0
  - 1.6377855982174208e+16
  - 2.6323246819311616e+16
  - 2.0221303030022144e+16
  - 1.1746618747711182
  - 1.951104858324992e+16
  - 7467540989083648.0
  - 9864492980633600.0
  - 7654871893278720.0
  - 2613247618318336.0
  - 9862753518878720.0
  - 1.0430546047926272e+16
  - 6581596073230336.0
  - 1732447267979264.0
  - 4.207607269287109
  - 762418233868288.0
  - 1.7256116664664064e+16
  - 9510208644579328.0
  - 1.342388270268416e+16
  - 7.582859039306641
  - 1.0171222365044736e+16
  - 1010383674408960.0
  - 1.6840029896704e+16
  - 8546605888176128.0
  - 2.467418124111053e+16
  - 1.6500697415548928e+16
  - 1.209506813968384e+16
  - 3.334381341934204
  - 6103099672363008.0
  - 1.8634772175650816e+16
  - 1183089678090240.0
  - 1.0810236189278208e+16
  - 1.1992991799443456e+16
  - 8263272264368128.0
  - 8.610776901245117
  - 1.314463466651648e+16
loss_records_fold4:
  train_losses:
  - 60.78133925795555
  - 46.397676318883896
  - 56.08952879905701
  - 66.54163974523544
  - 78.2582852691412
  - 57.56270918250084
  - 58.77283002436161
  - 48.01607569307089
  - 67.16378991305828
  - 43.110770881175995
  - 46.61576074361801
  - 46.7137586325407
  - 49.47582846879959
  - 49.54901356995106
  - 47.78535841405392
  - 47.8204260468483
  - 41.82962757349014
  - 67.58764234930277
  - 46.32075886428356
  - 52.38795764744282
  - 48.44216412305832
  - 78.80774848163128
  - 46.77829751372337
  - 60.42943808436394
  - 50.86355008929968
  - 46.89520429074764
  - 55.84088882803917
  - 48.595224261283875
  - 48.71796128153801
  - 63.347886711359024
  - 71.77394932508469
  - 53.739476293325424
  - 61.25373885035515
  - 174.64639273285866
  - 526.0519409626722
  - 1389.812319971621
  - 196.63635647296906
  - 409.0838754475117
  - 392.8333788663149
  - 158.02905018627644
  - 166.98087933659554
  - 68.44790294766426
  - 70.47787675261497
  - 46.234823167324066
  - 160.78064968436956
  - 67.07251815497875
  - 91.39298924803734
  - 55.41479501128197
  - 52.62052121758461
  - 74.4920156672597
  - 73.78825645148754
  - 69.95289927721024
  - 49.24120031297207
  - 53.87866470217705
  - 43.85551334917545
  - 43.09561923146248
  - 52.27547760307789
  - 53.82016637921333
  - 52.70933213829994
  - 61.701394468545914
  - 49.193167328834534
  - 49.765130050480366
  - 56.09043978154659
  - 48.08071833848953
  - 47.56911092996597
  - 39.11410431563854
  - 46.78415386378765
  - 46.84307576715946
  - 46.04865916073322
  - 51.2804546803236
  - 63.360985562205315
  - 41.874563328921795
  - 45.78465063869953
  - 56.50081071257591
  - 52.36798253655434
  - 51.574225693941116
  - 50.23826904594898
  - 46.241317100822926
  - 52.18033453822136
  - 62.272758185863495
  - 53.39057557284832
  - 71.51778351515532
  - 45.09240320324898
  - 46.186557814478874
  - 39.80242544412613
  - 63.0265156775713
  - 47.85795547068119
  - 51.00733356177807
  - 52.38499738276005
  - 48.604744136333466
  - 81.67774087190628
  - 54.09986898303032
  - 57.91710469126701
  - 81.07973153889179
  - 48.84754550457001
  - 53.59062057733536
  - 46.1474080234766
  - 43.90215364098549
  - 45.50867418944836
  - 57.8528603091836
  validation_losses:
  - 4011976195833856.0
  - 5096482818490368.0
  - 3549036434948096.0
  - 4294234735640576.0
  - 2.9887044429779053
  - 1.2070853114068992e+16
  - 3668757574582272.0
  - 825090061107200.0
  - 672033599913984.0
  - 1.6034270524978638
  - 4002346073849856.0
  - 3564001711620096.0
  - 6.4401631355285645
  - 277910774611968.0
  - 847594280452096.0
  - 1.4093207120895386
  - 5513715805847552.0
  - 3722663172243456.0
  - 4.2046027183532715
  - 584005023956992.0
  - 4.372805118560791
  - 1.1662583186587648e+16
  - 9.071704864501953
  - 4522520032051200.0
  - 4663796001931264.0
  - 3932443065188352.0
  - 4671545733545984.0
  - 4601276847357952.0
  - 9052783890137088.0
  - 3581665301495808.0
  - 3713497443598336.0
  - 7087126608871424.0
  - 9221223917551616.0
  - 22158.330078125
  - 1.0619969367980957
  - 6.398425102233887
  - 254.31832885742188
  - 5.4739909172058105
  - 0.6671521067619324
  - 0.636241614818573
  - 0.6643262505531311
  - 0.4684239625930786
  - 0.5546250343322754
  - 0.622604250907898
  - 0.5906969904899597
  - 0.4480673670768738
  - 136727.5
  - 0.4993631839752197
  - 1.1114270687103271
  - 1.111312985420227
  - 1.866199254989624
  - 0.49308720231056213
  - 0.9505642652511597
  - 0.5667469501495361
  - 201587104.0
  - 0.8817901015281677
  - 0.7088894248008728
  - 5489608192.0
  - 0.5498319864273071
  - 0.7021538019180298
  - 0.5912341475486755
  - 375169318912.0
  - 1130.2347412109375
  - 738.5806884765625
  - 0.5092467069625854
  - 0.6356461048126221
  - 3016436744192.0
  - 6516183138304.0
  - 7161331580928.0
  - 6833784750080.0
  - 7424074317824.0
  - 5604453122048.0
  - 8193716518912.0
  - 5634906914816.0
  - 5890108293120.0
  - 5872997105664.0
  - 8623506849792.0
  - 7804725755904.0
  - 6029210288128.0
  - 7150000668672.0
  - 7073507573760.0
  - 6912798097408.0
  - 9585164288000.0
  - 7405755170816.0
  - 0.6455932855606079
  - 47917600768.0
  - 2042888454144.0
  - 2325068382208.0
  - 2539326013440.0
  - 2181430640640.0
  - 1480230305792.0
  - 1990905036800.0
  - 1779911229440.0
  - 1713295458304.0
  - 2504571224064.0
  - 3100480634880.0
  - 902086000640.0
  - 1401779257344.0
  - 3171864805376.0
  - 1547188830208.0
training fold messages:
  fold 0 training message: completed 100 epochs without stopping early
  fold 1 training message: completed 100 epochs without stopping early
  fold 2 training message: completed 100 epochs without stopping early
  fold 3 training message: completed 100 epochs without stopping early
  fold 4 training message: completed 100 epochs without stopping early
training_metrics:
  fold_eval_accs: '[0.8576329331046312, 0.8576329331046312, 0.8593481989708405, 0.8593481989708405,
    0.8591065292096219]'
  fold_eval_f1: '[0.0, 0.0, 0.0, 0.0, 0.0]'
  mean_eval_accuracy: 0.858613758672113
  mean_f1_accuracy: 0.0
  total_train_time: '0:18:58.503455'
